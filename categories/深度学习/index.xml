<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>深度学习 - 分类 - Jiayao&#39;s blog</title>
        <link>http://shanjiayao.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</link>
        <description>深度学习 - 分类 - Jiayao&#39;s blog</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>shanjiayao97@gmail.com (jiayao)</managingEditor>
            <webMaster>shanjiayao97@gmail.com (jiayao)</webMaster><lastBuildDate>Wed, 27 Jan 2021 16:10:19 &#43;0000</lastBuildDate><atom:link href="http://shanjiayao.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="self" type="application/rss+xml" /><item>
    <title>Transformer之self-attention机制</title>
    <link>http://shanjiayao.com/transformer%E4%B9%8Bself-attention/</link>
    <pubDate>Wed, 27 Jan 2021 16:10:19 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://shanjiayao.com/transformer%E4%B9%8Bself-attention/</guid>
    <description><![CDATA[记录学习Transformer过程中的一些个人理解与思考 self-attention 1. 宏观理解 关于注意力机制，在此不做赘述，不过关于自注意力，可能还是先要从宏观上分析]]></description>
</item><item>
    <title>目标跟踪中的边界效应与余弦窗平滑</title>
    <link>http://shanjiayao.com/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/</link>
    <pubDate>Wed, 27 Jan 2021 16:10:19 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://shanjiayao.com/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/</guid>
    <description><![CDATA[本文主要介绍学习目标跟踪算法时遇到的关于边界效应以及余弦窗平滑的相关知识 1. 边界效应 1.1 背景 在目标跟踪算法中，边界效应最早在的出现，是在基于相关]]></description>
</item><item>
    <title>Pytorch中的Convolution layers</title>
    <link>http://shanjiayao.com/pytorch-conv1d/</link>
    <pubDate>Thu, 21 Jan 2021 16:10:19 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://shanjiayao.com/pytorch-conv1d/</guid>
    <description><![CDATA[互相关和卷积的区别 在CNN中，互相关和卷积都是使用filter/kernel对一张图像进行操作 互相关是从上到下，从左到右 卷积是从下到上，从右]]></description>
</item><item>
    <title>Pytorch-nn与functional的区别</title>
    <link>http://shanjiayao.com/pytorch-nn%E4%B8%8Efunctional%E7%9A%84%E5%8C%BA%E5%88%AB/</link>
    <pubDate>Wed, 13 Jan 2021 16:10:19 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://shanjiayao.com/pytorch-nn%E4%B8%8Efunctional%E7%9A%84%E5%8C%BA%E5%88%AB/</guid>
    <description><![CDATA[Pytorch中的 nn 与 nn.functional 这两者其实本质上功能是一致的，都是用于开发者调用pytorch中的接口以搭建自己的网络 有一点不同的是，nn继承于nn]]></description>
</item><item>
    <title>Pytorch中的矩阵乘法</title>
    <link>http://shanjiayao.com/pytorch%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95/</link>
    <pubDate>Wed, 13 Jan 2021 16:10:19 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://shanjiayao.com/pytorch%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95/</guid>
    <description><![CDATA[Pytorch 矩阵乘法 关于广播机制，参考 torch.mul 1 torch.mul(input, other, *, out=None) 按位相乘，对维度的要求是，两个张量尽量维度对齐，或者是可以遵循广播机制 比如： 1 2 3 4 5 6 7 8 9 10 11 12]]></description>
</item><item>
    <title>cuda常见名词解释</title>
    <link>http://shanjiayao.com/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/</link>
    <pubDate>Sun, 10 Jan 2021 12:42:39 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://shanjiayao.com/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/</guid>
    <description><![CDATA[常见名词 device device一般指GPU端，也叫设备端，一般以 __device__ 前缀修饰的函数，函数的调用以及执行都需要在设备端进行 host host指CPU，也叫主机端]]></description>
</item><item>
    <title>自定义C&#43;&#43;/CUDA扩展</title>
    <link>http://shanjiayao.com/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/</link>
    <pubDate>Wed, 06 Jan 2021 16:10:19 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://shanjiayao.com/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/</guid>
    <description><![CDATA[官网文档 [Pytorch 1.7] Custom C++ and CUDA Extensions - PyTorch Tutorials 1.7.1 documentation Custom C++ and CUDA Extensions - PyTorch Tutorials 1.7.1 documentation CN 自定义扩展的必要性 Pytorch虽然已经使用了NVIDIA cuDNN、Intel MKL]]></description>
</item><item>
    <title>SC3D论文&amp;代码阅读</title>
    <link>http://shanjiayao.com/sc3d/</link>
    <pubDate>Fri, 26 Jun 2020 16:10:19 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://shanjiayao.com/sc3d/</guid>
    <description><![CDATA[《Leveraging_Shape_Completion_for_3D_Siamese_Tracking》论文&amp;代码阅读 作者：Sil]]></description>
</item><item>
    <title>KITTI数据集点云图像的投影</title>
    <link>http://shanjiayao.com/kitti%E6%95%B0%E6%8D%AE%E9%9B%86%E7%82%B9%E4%BA%91%E6%8A%95%E5%BD%B1%E5%88%B0%E5%9B%BE%E5%83%8F/</link>
    <pubDate>Sun, 22 Mar 2020 12:10:19 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://shanjiayao.com/kitti%E6%95%B0%E6%8D%AE%E9%9B%86%E7%82%B9%E4%BA%91%E6%8A%95%E5%BD%B1%E5%88%B0%E5%9B%BE%E5%83%8F/</guid>
    <description><![CDATA[本文要完成的工作是将KITTI数据集中的点云信息投影到图像中，以达到信息融合的目的. 使用KITTI中的经过时钟同步和校准后的数据文件 raw_data 来进行]]></description>
</item></channel>
</rss>
