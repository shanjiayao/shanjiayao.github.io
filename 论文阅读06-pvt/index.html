<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>论文阅读06 PVT - Jiayao&#39;s blog</title><meta name="Description" content="jiayao&#39;s blog"><meta property="og:title" content="论文阅读06 PVT" />
<meta property="og:description" content="Transformer在CV任务中的应用已经得到了很多工作的验证，但是对于点云处理任务，Transformer的尝试还不是特别多，这篇文章就是以PVCNN为基础，将Transformer融入进来。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB06-pvt/" /><meta property="og:image" content="http://shanjiayao.com/logo.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-01-26T19:46:08+00:00" />
<meta property="article:modified_time" content="2022-01-26T19:46:08+00:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="http://shanjiayao.com/logo.png"/>

<meta name="twitter:title" content="论文阅读06 PVT"/>
<meta name="twitter:description" content="Transformer在CV任务中的应用已经得到了很多工作的验证，但是对于点云处理任务，Transformer的尝试还不是特别多，这篇文章就是以PVCNN为基础，将Transformer融入进来。"/>
<meta name="application-name" content="LoveIt">
<meta name="apple-mobile-web-app-title" content="LoveIt"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB06-pvt/" /><link rel="prev" href="http://shanjiayao.com/%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E6%80%BB%E7%BB%93/" /><link rel="next" href="http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB07-registration-benchmarks/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "论文阅读06 PVT",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/shanjiayao.com\/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB06-pvt\/"
        },"genre": "posts","keywords": "论文阅读","wordcount":  1722 ,
        "url": "http:\/\/shanjiayao.com\/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB06-pvt\/","datePublished": "2022-01-26T19:46:08+00:00","dateModified": "2022-01-26T19:46:08+00:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "jiayao"
            },"description": ""
    }
    </script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Jiayao&#39;s blog"></a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/"> 主页 </a><a class="menu-item" href="/posts/"> 归档 </a><a class="menu-item" href="/tags/"> 标签 </a><a class="menu-item" href="/categories/"> 分类 </a><a class="menu-item" href="/projects/"> 项目 </a><a class="menu-item" href="/collections/"> 收集 </a><a class="menu-item" href="/about/"> 关于 </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Jiayao&#39;s blog"></a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        取消
                    </a>
                </div><a class="menu-item" href="/" title="">主页</a><a class="menu-item" href="/posts/" title="">归档</a><a class="menu-item" href="/tags/" title="">标签</a><a class="menu-item" href="/categories/" title="">分类</a><a class="menu-item" href="/projects/" title="">项目</a><a class="menu-item" href="/collections/" title="">收集</a><a class="menu-item" href="/about/" title="">关于</a><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">目录</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">论文阅读06 PVT</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>jiayao</a></span>&nbsp;<span class="post-category">收录于 <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"><i class="far fa-folder fa-fw"></i>论文阅读</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2022-01-26">2022-01-26</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;约 1722 字&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;预计阅读 4 分钟&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="">
                <div class="details-summary toc-title">
                    <span>目录</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#简介">简介</a></li>
    <li><a href="#摘要">摘要</a></li>
    <li><a href="#主要贡献">主要贡献</a></li>
    <li><a href="#方法流程">方法流程</a>
      <ul>
        <li><a href="#网络总览">网络总览</a></li>
        <li><a href="#基于体素的分支">基于体素的分支</a></li>
        <li><a href="#基于点的分支">基于点的分支</a></li>
      </ul>
    </li>
    <li><a href="#实验">实验</a>
      <ul>
        <li><a href="#定量实验">定量实验</a></li>
        <li><a href="#定性实验">定性实验</a></li>
        <li><a href="#消融实验">消融实验</a></li>
      </ul>
    </li>
    <li><a href="#reference">Reference</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p>Transformer在CV任务中的应用已经得到了很多工作的验证，但是对于点云处理任务，Transformer的尝试还不是特别多，这篇文章就是以PVCNN为基础，将Transformer融入进来。</p>
<h2 id="简介">简介</h2>
<ul>
<li>论文：《PVT: Point-Voxel Transformer for Point Cloud Learning》</li>
<li>作者：<em>Zhang Cheng1*, Haocheng Wan1∗, Xinyi Shen2, Zizhao Wu1†</em></li>
<li>机构：<em>Hangzhou Dianzi University, University College London</em></li>
<li>论文水平：<em>Arxiv</em></li>
<li>关键词：<strong>point-voxel &amp;&amp; transformer</strong></li>
<li>论文链接：<a href="https://arxiv.org/abs/2108.06076" target="_blank" rel="noopener noreffer">paper</a></li>
</ul>
<h2 id="摘要">摘要</h2>
<p>与卷积神经网络相比，近期一些基于纯Transformer架构的工作在点云领域的评价基准上取得了令人惊叹的准确性。然而，现有的点云Transformer的计算成本很高，因为点云数据的不规则性浪费了大量时间。为了解决这个问题，我们提出了稀疏窗口注意（Sparse Window Attention）模块来从非空体素中收集粗糙的局部特征，这不仅避免了计算昂贵的不规则数据结构和无效的空体素，而且维持了线性的计算复杂度。同时，为了收集有关全局形状的细粒度特征，我们引入了相对注意力（Relative Attention）模块，其针对物体刚性变换设计了相对位置编码。配备 SWA 和 RA，我们构建了称为 PVT 的神经架构，将两个模块集成到点云学习的联合框架中。与以前的基于 Transformer 和基于注意力的模型相比，我们的方法在分类基准上达到了 94.0% 的最高准确率，平均推理速度提高了 10 倍。大量实验也验证了 PVT 在Part Segmentation和Semantic Segmentation任务上的有效性（分别为 86.6% 和 69.2% mIoU）。</p>
<h2 id="主要贡献">主要贡献</h2>
<ol>
<li>
<p>提出了PVT的框架，同时使用Transformer增强基于点的特征提取以及基于体素的特征体素方案。</p>
</li>
<li>
<p>提出了一种高效的局部注意力模块，名为SWA，结合了稀疏卷积以及Swin Transformer[1]中的shift window设计，使计算复杂度降低到线性。</p>
</li>
<li>
<p>针对点云的多视角变换问题，使用相对位置编码来计算相对注意力（RA），从而对不同视角下的点云输入鲁棒。</p>
</li>
<li>
<p>在点云分类、局部分割以及语义分割任务上均做了实验，证明方法的有效性。</p>
</li>
</ol>
<h2 id="方法流程">方法流程</h2>
<h3 id="网络总览">网络总览</h3>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195226.png"
        data-srcset="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195226.png, https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195226.png 1.5x, https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195226.png 2x"
        data-sizes="auto"
        alt="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195226.png"
        title="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195226.png" /></p>
<p>如上图所示，网络输入一帧点云数据，经过若干组PVT模块提取特征之后，后面接多尺度的特征融合以及对应任务的输出头。这里每个PVT模块都包含了两个分支，分别从原始点云以及体素化点云两种形式上学习点云特征。其中作者指出，由于体素结构是规则且连续的，所以基于体素化的分支可以学习到局部上下文信息。而基于点的分支则更侧重于提取全局的细粒度特征，最终两分支的信息融合，以实现一个PVT模块的特征学习。</p>
<h3 id="基于体素的分支">基于体素的分支</h3>
<p>体素化分支主要解决的问题有两个，其一是降低Transformer中自注意力机制的计算复杂度，其二是解决点云稀疏性带来的大量空体素的问题。</p>
<p>为了降低自注意力的计算复杂度，作者借鉴了Swin Transformer中划分window的思想，选择将三维体素网格划分为若干局部框，这样在每个局部框中计算自注意力，可以将计算复杂度降低到与体素数量呈线性关系的级别。复杂度的对比如下</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195416.png"
        data-srcset="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195416.png, https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195416.png 1.5x, https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195416.png 2x"
        data-sizes="auto"
        alt="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195416.png"
        title="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195416.png" /></p>
<p>式1表示全局的自注意力的计算复杂度，式2表示划分局部框之后的计算复杂度，总体来说，划分局部框之后，计算复杂度与体素数量R^3成线性关系。</p>
<p>为了解决点云稀疏性的问题，作者借鉴了Sparse Conv的思想，通过维护一个哈希表，来保留非空体素的索引，加快了计算效率。如下图所示：</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195431.png"
        data-srcset="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195431.png, https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195431.png 1.5x, https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195431.png 2x"
        data-sizes="auto"
        alt="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195431.png"
        title="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195431.png" /></p>
<p>此外，为了使不同的局部框之间进行信息交流，作者同样使用了Swin Transformer中的shift方案</p>
<h3 id="基于点的分支">基于点的分支</h3>
<p>这里使用了一个通用的transformer的自注意力框架，以获得全局的点云特征，自注意力计算公式如下</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195537.png"
        data-srcset="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195537.png, https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195537.png 1.5x, https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195537.png 2x"
        data-sizes="auto"
        alt="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195537.png"
        title="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195537.png" /></p>
<p>为了使网络与输入点云的角度以及位置信息解耦，作者使用了相对位置编码，对每个点云中的点，都计算其余所有点相对于当前点的曼哈顿距离，公式如下</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195600.png"
        data-srcset="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195600.png, https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195600.png 1.5x, https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195600.png 2x"
        data-sizes="auto"
        alt="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195600.png"
        title="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195600.png" /></p>
<h2 id="实验">实验</h2>
<h3 id="定量实验">定量实验</h3>
<p>作者在点云形状分类，局部分割以及语义分割任务上都做了实验，效果均达到了SOTA。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195647.png"
        data-srcset="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195647.png, https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195647.png 1.5x, https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195647.png 2x"
        data-sizes="auto"
        alt="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195647.png"
        title="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195647.png" /></p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195737.png"
        data-srcset="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195737.png, https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195737.png 1.5x, https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195737.png 2x"
        data-sizes="auto"
        alt="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195737.png"
        title="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195737.png" /></p>
<h3 id="定性实验">定性实验</h3>
<p>下面是S3DIS数据集上做的可视化定性分析</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195809.png"
        data-srcset="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195809.png, https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195809.png 1.5x, https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195809.png 2x"
        data-sizes="auto"
        alt="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195809.png"
        title="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195809.png" /></p>
<h3 id="消融实验">消融实验</h3>
<p>作者评估了基于点的分支(PB)、基于体素的分支(VB)、局部框平移操作(shifting)以及每个模块的重复次数(NPB)对模型精度的关系。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195852.png"
        data-srcset="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195852.png, https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195852.png 1.5x, https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195852.png 2x"
        data-sizes="auto"
        alt="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195852.png"
        title="https://pictures-1309138036.cos.ap-nanjing.myqcloud.com/img/20220323195852.png" /></p>
<h2 id="reference">Reference</h2>
<p>[1] Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., Lin, S., &amp; Guo, B. (n.d.). Swin Transformer: Hierarchical Vision Transformer using Shifted Windows. ICCV 2021.</p></div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>更新于 2022-01-26</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB06-pvt/index.md" target="_blank">阅读原始文档</a>
                        </span></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB06-pvt/" data-title="论文阅读06 PVT" data-hashtags="论文阅读"><i class="fab fa-twitter fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB06-pvt/" data-hashtag="论文阅读"><i class="fab fa-facebook-square fa-fw"></i></a><a href="javascript:void(0);" title="分享到 WhatsApp" data-sharer="whatsapp" data-url="http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB06-pvt/" data-title="论文阅读06 PVT" data-web><i class="fab fa-whatsapp fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Line" data-sharer="line" data-url="http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB06-pvt/" data-title="论文阅读06 PVT"><i data-svg-src="/lib/simple-icons/icons/line.min.svg"></i></a><a href="javascript:void(0);" title="分享到 Pocket" data-sharer="pocket" data-url="http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB06-pvt/"><i class="fab fa-get-pocket fa-fw"></i></a><a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB06-pvt/" data-title="论文阅读06 PVT"><i class="fab fa-weibo fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Myspace" data-sharer="myspace" data-url="http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB06-pvt/" data-title="论文阅读06 PVT" data-description=""><i data-svg-src="/lib/simple-icons/icons/myspace.min.svg"></i></a><a href="javascript:void(0);" title="分享到 Blogger" data-sharer="blogger" data-url="http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB06-pvt/" data-title="论文阅读06 PVT" data-description=""><i class="fab fa-blogger fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Evernote" data-sharer="evernote" data-url="http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB06-pvt/" data-title="论文阅读06 PVT"><i class="fab fa-evernote fa-fw"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E6%80%BB%E7%BB%93/" class="prev" rel="prev" title="算法刷题总结"><i class="fas fa-angle-left fa-fw"></i>算法刷题总结</a>
            <a href="/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB07-registration-benchmarks/" class="next" rel="next" title="论文阅读07 Registration Benchmarks">论文阅读07 Registration Benchmarks<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
<div id="comments"></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">年龄是时间的箭头，裹挟着我们，在匆匆的人世间，匆匆前行</div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2019 - 2022</span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="回到顶部">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="查看评论">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/katex/copy-tex.min.css"><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.stemmer.support.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.zh.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/mhchem.min.js"></script><script type="text/javascript" src="/lib/cookieconsent/cookieconsent.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":10},"comment":{},"cookieconsent":{"content":{"dismiss":"同意","link":"了解更多","message":"本网站使用 Cookies 来改善您的浏览体验."},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"$$","right":"$$"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"},{"display":false,"left":"$","right":"$"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","lunrLanguageCode":"zh","lunrSegmentitURL":"/lib/lunr/lunr.segmentit.js","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"lunr"}};</script><script type="text/javascript" src="/js/theme.min.js"></script><script type="text/javascript">
            window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());
            gtag('config', 'G-THB0NH45ZM', { 'anonymize_ip': true });
        </script><script type="text/javascript" src="https://www.googletagmanager.com/gtag/js?id=G-THB0NH45ZM" async></script></body>
</html>
