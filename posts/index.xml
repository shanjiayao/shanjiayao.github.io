<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>所有文章 - Jiayao&#39;s blog</title>
        <link>http://shanjiayao.com/posts/</link>
        <description>所有文章 | Jiayao&#39;s blog</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>shanjiayao97@gmail.com (jiayao)</managingEditor>
            <webMaster>shanjiayao97@gmail.com (jiayao)</webMaster><lastBuildDate>Tue, 01 Nov 2022 14:43:50 &#43;0000</lastBuildDate><atom:link href="http://shanjiayao.com/posts/" rel="self" type="application/rss+xml" /><item>
    <title>SLAM十四讲之第一讲 预备知识</title>
    <link>http://shanjiayao.com/slam%E5%8D%81%E5%9B%9B%E8%AE%B2%E4%B9%8B%E7%AC%AC%E4%B8%80%E8%AE%B2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/</link>
    <pubDate>Tue, 01 Nov 2022 14:43:50 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://shanjiayao.com/slam%E5%8D%81%E5%9B%9B%E8%AE%B2%E4%B9%8B%E7%AC%AC%E4%B8%80%E8%AE%B2-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/</guid>
    <description><![CDATA[<p>第一讲主要介绍了SLAM的定义以及十四讲的组织关系，并且做了公式以及代码等风格约定。本文参考的版本是视觉SLAM十四讲的第二版。</p>]]></description>
</item><item>
    <title>git lfs 大文件存储工具</title>
    <link>http://shanjiayao.com/git-lfs-%E5%A4%A7%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%B7%A5%E5%85%B7/</link>
    <pubDate>Sat, 23 Jul 2022 18:19:06 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://shanjiayao.com/git-lfs-%E5%A4%A7%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%B7%A5%E5%85%B7/</guid>
    <description><![CDATA[使用场景 在Git仓库中，对于非文本文件，如各种多媒体文件，软件制品文件，二进制文件等等，这些文件往往体积比较大，使用Git直接管理会导致仓库]]></description>
</item><item>
    <title>SSH学习笔记</title>
    <link>http://shanjiayao.com/ssh%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
    <pubDate>Sat, 23 Jul 2022 18:19:06 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://shanjiayao.com/ssh%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
    <description><![CDATA[<p>对于ssh，之前的认知大概只是停留在简单使用的层面，然而近期涉及到了一些较为深入的使用场景就很懵逼。因此，本文尝试理解有关ssh一些原理层面的东东~</p>]]></description>
</item><item>
    <title>git学习记录</title>
    <link>http://shanjiayao.com/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</link>
    <pubDate>Thu, 16 Jun 2022 16:10:19 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://shanjiayao.com/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</guid>
    <description><![CDATA[<p>重温git，并整理各个命令的用法。</p>]]></description>
</item><item>
    <title>论文阅读21 BEV感知系列-PETR</title>
    <link>http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB21-bev%E6%84%9F%E7%9F%A5%E7%B3%BB%E5%88%97-petr/</link>
    <pubDate>Thu, 05 May 2022 20:01:39 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB21-bev%E6%84%9F%E7%9F%A5%E7%B3%BB%E5%88%97-petr/</guid>
    <description><![CDATA[<p>本文是了解BEV感知系列的第八篇论文阅读，来自旷视，其主要针对DETR3D进行改进，优化其object query部分，通过Lift的方式编码3D的position encoding，进而联合object query共同学习目标信息。</p>]]></description>
</item><item>
    <title>论文阅读20 BEV感知系列-M^2 BEV</title>
    <link>http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB20-bev%E6%84%9F%E7%9F%A5%E7%B3%BB%E5%88%97-m2bev/</link>
    <pubDate>Tue, 03 May 2022 20:01:39 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB20-bev%E6%84%9F%E7%9F%A5%E7%B3%BB%E5%88%97-m2bev/</guid>
    <description><![CDATA[<p>本文是了解BEV感知系列的第七篇论文阅读，来自港大、Nvidia等多方联合的工作，其提出了一种BEV视角下的检测与分割的统一框架，使用共享的主干网络，利用Lift的思想将多视角图像lift到3D空间，并对速度做了优化，最终实现高实时性以及高精度的性能。</p>]]></description>
</item><item>
    <title>论文阅读19 BEV感知系列-DETR3D</title>
    <link>http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB19-bev%E6%84%9F%E7%9F%A5%E7%B3%BB%E5%88%97-detr3d/</link>
    <pubDate>Sun, 01 May 2022 20:01:39 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB19-bev%E6%84%9F%E7%9F%A5%E7%B3%BB%E5%88%97-detr3d/</guid>
    <description><![CDATA[<p>本文是了解BEV感知系列的第六篇论文阅读，是MIT, CMU, THU多家单位联合的工作，其基于DETR的二维检测工作，在多视角3D检测任务上开创了一种全新的方案，利用object queries隐式地编码了2D-3D的投影信息，从而避免了深度预测以及IPM类方法的投影误差。</p>]]></description>
</item><item>
    <title>论文阅读18 Focal SparseConv</title>
    <link>http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB18-focal-sparseconv/</link>
    <pubDate>Sun, 01 May 2022 08:01:39 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB18-focal-sparseconv/</guid>
    <description><![CDATA[<p>本文是CVPR2022的oral，也是旷视以及港中文贾佳亚老师团队的合作工作。主要是对稀疏卷积的改进，通过预测卷积核中每个位置的特征对输出的贡献程度，定义了一种重要性分数，然后利于阈值截取满足条件位置的特征。等同于标准稀疏卷积以及子流形稀疏卷积的中间版本。</p>]]></description>
</item><item>
    <title>论文阅读17 BEV感知系列-Cam2BEV</title>
    <link>http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB17-bev%E6%84%9F%E7%9F%A5%E7%B3%BB%E5%88%97-cam2bev/</link>
    <pubDate>Sat, 23 Apr 2022 20:01:39 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB17-bev%E6%84%9F%E7%9F%A5%E7%B3%BB%E5%88%97-cam2bev/</guid>
    <description><![CDATA[<p>本文是了解BEV感知系列的第五篇论文阅读，来自亚琛工大，其针对IPM投影算法中的前景前景遮挡问题进行探究，标注遮挡类别，让网络预测遮挡类别，代码已开源。</p>]]></description>
</item><item>
    <title>论文阅读16 BEV感知系列-LiftSplat</title>
    <link>http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB16-bev%E6%84%9F%E7%9F%A5%E7%B3%BB%E5%88%97-liftsplat/</link>
    <pubDate>Tue, 19 Apr 2022 20:01:39 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://shanjiayao.com/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB16-bev%E6%84%9F%E7%9F%A5%E7%B3%BB%E5%88%97-liftsplat/</guid>
    <description><![CDATA[<p>本文是了解BEV感知系列的第四篇论文阅读，来自Nvidia，Lift是指将相机表达提升到三维视锥，Splat指将各个相机的三维视锥通过外参以及PointPillar，拍平到BEV视角。通过独特的lift过程实现二维到三维的映射。</p>]]></description>
</item></channel>
</rss>
