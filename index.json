[{"categories":["学习笔记"],"content":"本文是对2022年3月23日将门创投的公开课分享的笔记记录，主讲人是赵行老师。 ","date":"2022-03-23","objectID":"/bev%E6%84%9F%E7%9F%A5%E5%85%AC%E5%BC%80%E8%AF%BE%E7%AC%94%E8%AE%B0/:0:0","tags":["赵行公开课"],"title":"BEV感知公开课笔记","uri":"/bev%E6%84%9F%E7%9F%A5%E5%85%AC%E5%BC%80%E8%AF%BE%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"简介 BEV感知的定义，是将原本透视视角的感知信息，投影到俯视视角（鸟瞰图，BEV），这里投影并不是结果级投影，而是多个传感器的中间特征投影到BEV，并且在BEV视图进行后续的感知。 关于BEV感知，之前小鹏汽车的技术分享会上，刘兰个川老师就已经指出过这个概念，并且其medium博客上专门介绍了相关的工作，其认为BEV感知会是以后自动驾驶感知的大一统方向，此外，Tesla的AI Day，也是表明了他们使用transformer取代原本的IPM，将多个相机的特征投影到vector space，这些都是BEV感知的例子。 本文主要介绍的就是，以视觉为中心的自动驾驶感知，BEV感知算法。 为什么以视觉为中心？ Under-explored 过往有大量的工作被提出，并且携带丰富的语义信息。 Scalable 视觉数据将会是自动驾驶积累最多的数据，并且其数据压缩、存储、传输等算法也较为完善。 过去的研究如何？ 为什么要用BEV感知? 自动驾驶本身就是一个2.5D的问题，其对高度方向上关注度不高，因为车辆默认被定义在地面上运动。 一些人为的通过参数标定的投影，会带有一些传感器级别的误差，导致感知结果不精准。 ","date":"2022-03-23","objectID":"/bev%E6%84%9F%E7%9F%A5%E5%85%AC%E5%BC%80%E8%AF%BE%E7%AC%94%E8%AE%B0/:1:0","tags":["赵行公开课"],"title":"BEV感知公开课笔记","uri":"/bev%E6%84%9F%E7%9F%A5%E5%85%AC%E5%BC%80%E8%AF%BE%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"介绍的主要工作 ","date":"2022-03-23","objectID":"/bev%E6%84%9F%E7%9F%A5%E5%85%AC%E5%BC%80%E8%AF%BE%E7%AC%94%E8%AE%B0/:2:0","tags":["赵行公开课"],"title":"BEV感知公开课笔记","uri":"/bev%E6%84%9F%E7%9F%A5%E5%85%AC%E5%BC%80%E8%AF%BE%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"HDMapNet Motivation 根据环视相机的数据，进行车周围的交通信息检测，比如车道线、路沿等。 对于传统的高精地图的构建，对应的pipeline如下，其需要数据采集车，搭载高线数的lidar、高精度的imu、rtk等，通过在实际道路场景进行数据采集之后，后处理将采集到的信息进行标注、拼接，以形成高精度地图。后面实际使用时，就可以加载高精地图进行定位了。 这样有三个主要的缺点： 整体的pipeline较为复杂 人力财力耗费严重，数据标注尤其明显 需要不断地进行地图维护和更新，循环往复 因此，以上就是HDMapNet地motivation，其希望将建图地过程转化为感知识别地过程，其将原本冗余地框架进行了简化，并且不需要人工标注，低成本且自动化，并且不需要进行地图更新和维护。 要注意，这里地高精地图并不是整个城市级别的，而是ego周边环境的高精地图的实时构建，是为了满足自动驾驶的需要。 Input/Output 总体而言，输入包括图像信息以及Lidar信息。输出则是矢量化的信息，如下图 Network 具体地HDMapNet的结构如下： 首先是encoder，使用一些轻量化的backbone对输入的图片做提取 然后是每个相机的视角转换，这里只是说用了一个神经网络，但是没有具体表明，Tesla使用的是Transformer，而毫末智行使用的是常用的卷积，所以这里应该不需要具体指定，实现功能即可。 接着是多相机投影，将多个相机的BEV图通过外参投影到一张BEV视图中。 最后接BEV的Decoder 如果是Lidar点云，则使用Pillar拍平，然后再使用Encoder-View Transform-Decoder。 具体的Decoder后面接不同的head，比如车道线的分割，实例的分割，以及线段的方向，最后对上述前两种信息进行后处理，得到instance mask，再结合方向，就可以拼凑成矢量化的局部高精地图。 结果 超过了IPM、Lift以及VPR，并且融合激光和相机的效果最优。 ","date":"2022-03-23","objectID":"/bev%E6%84%9F%E7%9F%A5%E5%85%AC%E5%BC%80%E8%AF%BE%E7%AC%94%E8%AE%B0/:2:1","tags":["赵行公开课"],"title":"BEV感知公开课笔记","uri":"/bev%E6%84%9F%E7%9F%A5%E5%85%AC%E5%BC%80%E8%AF%BE%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"DETR3D Related Work 伪Lidar 先预测深度，然后再进行3D的目标检测，两阶段，容易产生累计误差，也就是深度估计不准导致检测框不准 将3D检测投影到2D来做，速度快，但是没有利用到3D的几何信息。 Proposed Method 提出的DETR3D有以下几种优点 检测过程发生在3D，信息利用更充分 没有进行3D世界的预测和重建 避免了NMS等后处理的需求。 实验 相比于FCOS3D，有了很大提升，作者给出的原因是，在2D图像中，物体距离ego较近的话，物体大多会被框的边缘截断，所以在3D空间可以明显提升检测的性能。 ","date":"2022-03-23","objectID":"/bev%E6%84%9F%E7%9F%A5%E5%85%AC%E5%BC%80%E8%AF%BE%E7%AC%94%E8%AE%B0/:2:2","tags":["赵行公开课"],"title":"BEV感知公开课笔记","uri":"/bev%E6%84%9F%E7%9F%A5%E5%85%AC%E5%BC%80%E8%AF%BE%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"FUTR3D 针对多种传感器的融合，比如Radar、Lidar以及Camera，提出一种新的解决方案。 Related Work MV3D F-Pointnet 这些方案都比较依赖于我们对传感器的先验，那么是否有一种方案简单地实现多个传感器地融合呢？ Proposed Method 实验 FUTR3D可以有效地融合多传感器地优势 可以使用4线Lidar+camera达到不错地效果 ","date":"2022-03-23","objectID":"/bev%E6%84%9F%E7%9F%A5%E5%85%AC%E5%BC%80%E8%AF%BE%E7%AC%94%E8%AE%B0/:2:3","tags":["赵行公开课"],"title":"BEV感知公开课笔记","uri":"/bev%E6%84%9F%E7%9F%A5%E5%85%AC%E5%BC%80%E8%AF%BE%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"总结与思考 赵行老师从建图、感知静态目标、感知动态目标三个角度来介绍他们地工作，实际上，对于局部高精地图的构建，貌似Tesla、小鹏、毫末以及赵行老师讲到的，方案都大同小异。而对于静态和动态目标地感知，DETR3D的这种方案的确会有效克服近距离截断问题，尤其是在多挂卡车的感知任务上，而多传感器的感知结果融合统一也是之前的一个难点，现阶段貌似Tesla、包括学术界都给出了一些答案。总体来讲，以BEV为中心的感知，的确会相对lidar的感知更具影响力，不过最终到底是lidar量产速度快还是camera算法迭代速度快，就需要我们一起等待了。 ","date":"2022-03-23","objectID":"/bev%E6%84%9F%E7%9F%A5%E5%85%AC%E5%BC%80%E8%AF%BE%E7%AC%94%E8%AE%B0/:3:0","tags":["赵行公开课"],"title":"BEV感知公开课笔记","uri":"/bev%E6%84%9F%E7%9F%A5%E5%85%AC%E5%BC%80%E8%AF%BE%E7%AC%94%E8%AE%B0/"},{"categories":["学习笔记"],"content":"本文是深蓝学院多传感器融合感知课程的笔记，主要对用于建图定位的传感器进行原理梳理以及功能分析。 ","date":"2022-03-22","objectID":"/3.-%E7%94%A8%E4%BA%8E%E5%BB%BA%E5%9B%BE%E5%AE%9A%E4%BD%8D%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/:0:0","tags":["自动驾驶多传感器设计"],"title":"多传感器融合感知之用于建图定位的多传感器分析","uri":"/3.-%E7%94%A8%E4%BA%8E%E5%BB%BA%E5%9B%BE%E5%AE%9A%E4%BD%8D%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/"},{"categories":["学习笔记"],"content":"GNSS简介 ","date":"2022-03-22","objectID":"/3.-%E7%94%A8%E4%BA%8E%E5%BB%BA%E5%9B%BE%E5%AE%9A%E4%BD%8D%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/:1:0","tags":["自动驾驶多传感器设计"],"title":"多传感器融合感知之用于建图定位的多传感器分析","uri":"/3.-%E7%94%A8%E4%BA%8E%E5%BB%BA%E5%9B%BE%E5%AE%9A%E4%BD%8D%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/"},{"categories":["学习笔记"],"content":"GNSS的概念 GNSS，Global Navigation Satellite System，是所有导航定位卫星的总称，凡是可以通过捕获跟踪其卫星信号实现定位的系统，均可以算在GNSS系统的范围中。GNSS广泛应用于手机导航、车载导航、测绘、农业、航空以及最近兴起的无人驾驶领域。 ","date":"2022-03-22","objectID":"/3.-%E7%94%A8%E4%BA%8E%E5%BB%BA%E5%9B%BE%E5%AE%9A%E4%BD%8D%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/:1:1","tags":["自动驾驶多传感器设计"],"title":"多传感器融合感知之用于建图定位的多传感器分析","uri":"/3.-%E7%94%A8%E4%BA%8E%E5%BB%BA%E5%9B%BE%E5%AE%9A%E4%BD%8D%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/"},{"categories":["学习笔记"],"content":"GNSS的主要构成 GNSS的构成可以分为三部分，分别是全球卫星导航系统，区域导航系统，以及增强系统。 全球卫星导航系统，比如美国的GPS，欧洲的GALILEO(伽利略)，俄罗斯的GLONASS(格洛纳斯)以及我国的BDS(北斗)。这些系统均位于同一层级，都属于GNSS，并且可以覆盖地球的所有地区。 全球卫星导航系统一般是中美俄以及欧盟等用作全球战略储备而追求的，还有一些只在局部范围内提供的区域导航系统，比如我国的北斗一代和二代，其覆盖的面积就达不到全球的级别，只能算在区域性的导航系统。还有日本的准天顶系统(QZSS)，印度的IRNSS系统等。 除了以上两种，还有增强系统，顾名思义就是对前面的辅助以及增强，这里就涉及到具体需求具体强化了，相关的包括美国的WAAS。日本的MSAS，欧盟的EGNOS, 印度的GAGAN等。 综上，GNSS可以根据其覆盖范围以及功能侧重分为以上三种。 全球导航卫星系统 区域导航系统 增强系统 GPS QZSS WAAS GALILEO IRNSS MSAS GLONASS – EGNOS BDS – GAGAN ","date":"2022-03-22","objectID":"/3.-%E7%94%A8%E4%BA%8E%E5%BB%BA%E5%9B%BE%E5%AE%9A%E4%BD%8D%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/:1:2","tags":["自动驾驶多传感器设计"],"title":"多传感器融合感知之用于建图定位的多传感器分析","uri":"/3.-%E7%94%A8%E4%BA%8E%E5%BB%BA%E5%9B%BE%E5%AE%9A%E4%BD%8D%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/"},{"categories":["学习笔记"],"content":"GNSS的主要功能 GNSS的主要功能有三：定位、测速以及授时。 定位功能就是通过接收机，接收卫星的信息，我们可以对接收到的信号计算相位差，进而得到传播时间，乘以光速即为二倍的测量距离。如果我们同时接受三颗卫星的信号，那么以卫星为中心，距离微半径，就可以确定当前接收机所在的经纬度以及高度信息。但是由于我们做不到让接收设备的时间与卫星的时间完全一致没有误差，所以需要多用一颗卫星，来计算接收设备时间与卫星时间的误差，如果同时接收到四颗卫星的信号，那么就可以对原本模糊的时间观测进行精确求解，从而得到时间精准的位置信息。一般来讲，GNSS的定位误差在米级别，如果遇到高反射场景，比如城市峡谷，那么误差会由于信号的随机反射而加大，甚至会达到百米级别。 测速则是测量位置差以及朝向角。授时则用来做时间同步，GNSS可以实现高精度授时，达到纳秒量级。 ","date":"2022-03-22","objectID":"/3.-%E7%94%A8%E4%BA%8E%E5%BB%BA%E5%9B%BE%E5%AE%9A%E4%BD%8D%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/:1:3","tags":["自动驾驶多传感器设计"],"title":"多传感器融合感知之用于建图定位的多传感器分析","uri":"/3.-%E7%94%A8%E4%BA%8E%E5%BB%BA%E5%9B%BE%E5%AE%9A%E4%BD%8D%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/"},{"categories":["学习笔记"],"content":"GNSS的误差分析 以自动驾驶为例，如果无人车上面搭载了GNSS的接收机，通过实时接收GNSS信息来获取自身的绝对位置。那么此时GNSS定位的误差可能来自于以下方面： 信号的传输损失 由于信号在传输过程中，发生了折射，导致信息损失。主要发生在电离层以及对流层 时钟的不对齐 如果发射或者接收的时钟不一致，那么对于飞行时间的计算就会有偏差，导致测量误差变大，比如卫星时钟、接收机时钟 多路径与非视距 通常来说，我们将无线通信系统的传播条件分成视距(LOS)和非视距(NLOS)两种环境，在视距条件下，无线信号无遮挡地在发送端与接收端之间进行直线传播，这要求在第一菲涅尔区内不存在对无线电波造成遮挡的物体，如果不满足这一条件，信号强度就会产生明显下降，而这种利用以视距传播的无线电波进行信息传输的通信就是视距通信。 由于周围建筑物对卫星信号的反射与遮挡，导致了多路径效应和非视距信号，其中现有的多路径信号大部分可以通过好一点的接收机检测出来，或者其误差可以得到一定程度的抑制。然而非视距信号（也叫NLOS）就非常的危险，其非视距信号的观测量误差可以达到100米的级别，而且非视距信号基于传统的接收机技术很难完全检测出来。 为了解决以上误差，通用的做法是使用RTK(real - time kinematic)技术，高精度的gps测量必须采用载波相位观测值，rtk定位技术就是基于载波相位观测值的实时动态定位技术，它能够实时地提供测站点在指定坐标系中的三维定位结果，并达到厘米级精度。在rtk作业模式下，基准站通过数据链将其观测值和测站坐标信息一起传送给流动站。流动站不仅通过数据链接收来自基准站的数据，还要采集gps观测数据，并在系统内组成差分观测值进行实时处理，同时给出厘米级定位结果，历时不到一秒钟。 更详细的解决方案可以参考： https://zhuanlan.zhihu.com/p/416072448 ","date":"2022-03-22","objectID":"/3.-%E7%94%A8%E4%BA%8E%E5%BB%BA%E5%9B%BE%E5%AE%9A%E4%BD%8D%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/:1:4","tags":["自动驾驶多传感器设计"],"title":"多传感器融合感知之用于建图定位的多传感器分析","uri":"/3.-%E7%94%A8%E4%BA%8E%E5%BB%BA%E5%9B%BE%E5%AE%9A%E4%BD%8D%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/"},{"categories":["学习笔记"],"content":"GNSS相关的多传感器融合 虽然上述RTK的技术可以使定位达到厘米级别，但是对于自动驾驶而言，不是所有场景都有可用的RTK信号的，所以针对建图定位问题，我们还是需要使用多传感器融合的方法来使自动驾驶技术更加的鲁棒。 对于建图定位任务来说，涉及到的传感器有四种，GNSS+IMU、Lidar、Camera以及轮速计。通常我们会用GNSS(RTK)来获取全局位置，再加上vslam以及lidar slam辅助定位，克服在GNSS信号不好时定位信息丢失的问题。 如果以上方案再考虑上5G以及V2X车路协同，那么整体的方法框架如下： ","date":"2022-03-22","objectID":"/3.-%E7%94%A8%E4%BA%8E%E5%BB%BA%E5%9B%BE%E5%AE%9A%E4%BD%8D%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/:2:0","tags":["自动驾驶多传感器设计"],"title":"多传感器融合感知之用于建图定位的多传感器分析","uri":"/3.-%E7%94%A8%E4%BA%8E%E5%BB%BA%E5%9B%BE%E5%AE%9A%E4%BD%8D%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/"},{"categories":["学习笔记"],"content":"总结 定位系统的目标就是通过以上传感器的融合，打造全工况、全时段、高精度、高可靠性的定位能力，所以多传感器之间的融合是必不可少的。 ","date":"2022-03-22","objectID":"/3.-%E7%94%A8%E4%BA%8E%E5%BB%BA%E5%9B%BE%E5%AE%9A%E4%BD%8D%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/:3:0","tags":["自动驾驶多传感器设计"],"title":"多传感器融合感知之用于建图定位的多传感器分析","uri":"/3.-%E7%94%A8%E4%BA%8E%E5%BB%BA%E5%9B%BE%E5%AE%9A%E4%BD%8D%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/"},{"categories":["论文阅读"],"content":"简介 论文：《Not All Points Are Equal: Learning Highly Efficient Point-based Detectors for 3D LiDAR Point Clouds》 作者：Yifan Zhang, Qingyong Hu, Guoquan Xu, Yanxin Ma, Jianwei Wan, Yulan Guo 机构：National University of Defense Technology, § University of Oxford 论文水平：CVPR2022 关键词：lidar segmentation 论文链接：paper ","date":"2022-03-21","objectID":"/10-ia-ssd/:1:0","tags":["论文阅读"],"title":"10 IA-SSD","uri":"/10-ia-ssd/"},{"categories":["论文阅读"],"content":"摘要 本工作中，我们研究了 3D LiDAR 点云的有效目标检测问题。现有的基于原始点的算法框架，为了降低内存和计算成本，通常采用与任务无关的随机采样或最远点采样来对输入点云进行逐步的下采样，但并非所有点对目标检测任务都同等重要。特别地，对于目标检测器，前景点本质上比背景点更重要。受此启发，我们在本文中提出了一种高效的单阶段地基于点的 3D 检测器，称为 IA-SSD。我们方法的关键是利用两种可学习的、面向任务的、实例感知的下采样策略来分层选择属于感兴趣对象的前景点。此外，我们还引入了上下文质心感知模块来进一步估计精确的实例中心。最后，我们按照仅包含编码器的框架来构建我们的 IA-SSD 以提高效率。在几个大规模检测数据集上进行的实验证明了我们的 IA-SSD 的性能具有竞争力。由于低内存占用和高度并行性，它使用单个 RTX2080Ti GPU 在 KITTI 数据集上实现了每秒 80+ 帧的卓越速度。该代码可在 https://github.com/yifanzhang713/IA-SSD 获得。 ","date":"2022-03-21","objectID":"/10-ia-ssd/:2:0","tags":["论文阅读"],"title":"10 IA-SSD","uri":"/10-ia-ssd/"},{"categories":["论文阅读"],"content":"主要贡献 确定了现有基于点的检测器中的采样问题，并通过引入两种基于学习的实例感知下采样策略，提出了一种有效的基于点的 3D 检测器。 所提出的 IA-SSD 是高效的，并且能够使用一个模型检测 LiDAR 点云上的多类对象。 我们还提供了详细的内存占用与推理速度分析，以进一步验证所提出方法的优越性。 在多个大规模数据集上进行的大量实验证明了所提出方法的卓越效率和准确检测性能。 ","date":"2022-03-21","objectID":"/10-ia-ssd/:3:0","tags":["论文阅读"],"title":"10 IA-SSD","uri":"/10-ia-ssd/"},{"categories":["论文阅读"],"content":"方法流程 ","date":"2022-03-21","objectID":"/10-ia-ssd/:4:0","tags":["论文阅读"],"title":"10 IA-SSD","uri":"/10-ia-ssd/"},{"categories":["论文阅读"],"content":"网络总览 我们的 IA-SSD 遵循 [1] 中使用的轻量级的，仅包含编码器的架构以提高效率。 输入的 LiDAR 点云首先被输入网络以提取逐点特征，然后是提出的实例感知下采样以逐步降低计算成本，同时保留信息前景点。 学习到的潜在特征进一步输入到上下文质心感知模块，以生成实例建议并回归最终的边界框。 ","date":"2022-03-21","objectID":"/10-ia-ssd/:4:1","tags":["论文阅读"],"title":"10 IA-SSD","uri":"/10-ia-ssd/"},{"categories":["论文阅读"],"content":"可学习的下采样策略设计 对于高效的 3D 对象检测，必须通过渐进式下采样来降低内存和计算成本，尤其是对于大规模 3D 点云。 然而，大尺度下采样可能会丢失大部分前景目标的信息。 总体而言，目前尚不清楚如何在计算效率和前景点保留之间实现理想的权衡。 为此，我们首先进行实证研究，定量评估不同的抽样方法。 特别是，我们遵循常用的编码架构（即具有 4 个编码层的 PointNet++ [2]），并在下表中报告了不同采样方法的每层的 Instance Recall（即采样后保留的实例的比率）。方法包括随机点采样[3]、基于欧几里得距离（D-FPS）[2]和特征距离（Feat-FPS）[1]的FPS。 可以看出基于实例的采样方法可以很好地保留前景信息。下面介绍本文所设计的可学习的基于实例的下采样方案。 Class-aware Sampling 这种采样策略旨在学习每个点的语义，从而实现选择性下采样。 为了实现这一点，我们引入了额外的分支来利用潜在特征中的丰富语义。 具体做法就是，使用两个 MLP 层预测逐点的类别信息，Loss计算如下： 在推理阶段，取Top K个分数较高的点作为下采样的结果。 Centroid-aware Sampling 考虑到实例中心估计是最终目标检测的关键，我们进一步提出了一种质心感知下采样策略，为更接近实例质心的点赋予更高的权重。对中心度编码的公式如下 这种方式平滑了训练阶段的ground truth，通过计算中心度进行了加权。 在推理阶段，同样取Top K个分数较高的点作为下采样的结果。 ","date":"2022-03-21","objectID":"/10-ia-ssd/:4:2","tags":["论文阅读"],"title":"10 IA-SSD","uri":"/10-ia-ssd/"},{"categories":["论文阅读"],"content":"利用上下文信息预测实例中心点 主要包含中心点预测、中心点聚合、候选框生成三部分。 Contextual Centroid Prediction 我们尝试利用边界框周围的上下文线索来进行质心预测。通过每个实例表面以及周围的点云信息，对当前实例的中心进行预测，loss如下： Centroid-based Instance Aggregation 对于投票得到的的代表（质心）点，我们进一步利用 PointNet++ 模块来学习每个实例的潜在表示。 具体来说，我们将相邻点转换为局部规范坐标系，然后通过共享 MLP 和对称函数聚合点特征。 Proposal Generation Head 对上述的聚合特征进行处理，我们将候选框编码为中心点位置、尺寸和方向的多维表示。 最后，所有候选框都通过具有特定 IoU 阈值的 3D-NMS 后处理进行过滤。 ","date":"2022-03-21","objectID":"/10-ia-ssd/:4:3","tags":["论文阅读"],"title":"10 IA-SSD","uri":"/10-ia-ssd/"},{"categories":["论文阅读"],"content":"实验结果 ","date":"2022-03-21","objectID":"/10-ia-ssd/:5:0","tags":["论文阅读"],"title":"10 IA-SSD","uri":"/10-ia-ssd/"},{"categories":["论文阅读"],"content":"定量实验 作者在Kitti数据集上与现有方法进行了对比。 此外，还在Waymo和ONCE数据集上进行了实验。 ","date":"2022-03-21","objectID":"/10-ia-ssd/:5:1","tags":["论文阅读"],"title":"10 IA-SSD","uri":"/10-ia-ssd/"},{"categories":["论文阅读"],"content":"定性实验 ","date":"2022-03-21","objectID":"/10-ia-ssd/:5:2","tags":["论文阅读"],"title":"10 IA-SSD","uri":"/10-ia-ssd/"},{"categories":["论文阅读"],"content":"消融实验 作者评估了不同采样方式以及不同上下文中心点感知策略对模型精度的关系。 ","date":"2022-03-21","objectID":"/10-ia-ssd/:5:3","tags":["论文阅读"],"title":"10 IA-SSD","uri":"/10-ia-ssd/"},{"categories":["论文阅读"],"content":"Reference [1] Zetong Yang, Yanan Sun, Shu Liu, and Jiaya Jia. 3dssd: Point-based 3D single stage object detector. In CVPR, pages 11040–11048, 2020. [2] Charles Ruizhongtai Qi, Li Yi, Hao Su, and Leonidas J Guibas. Pointnet++: Deep hierarchical feature learning on point sets in a metric space. In NeurIPS, pages 5099–5108, 2017. [3] Qingyong Hu, Bo Yang, Linhai Xie, Stefano Rosa, Yulan Guo, Zhihua Wang, Niki Trigoni, and Andrew Markham. Randla-net: Efficient semantic segmentation of large-scale point clouds. In CVPR, pages 11108–11117, 2020. ","date":"2022-03-21","objectID":"/10-ia-ssd/:6:0","tags":["论文阅读"],"title":"10 IA-SSD","uri":"/10-ia-ssd/"},{"categories":["论文阅读"],"content":"本文提出了一种圆柱化的3D卷积方案，有效针对lidar的数据特性设计网络。 ","date":"2022-03-19","objectID":"/09-cylinder3d/:0:0","tags":["论文阅读"],"title":"09 Cylinder3D","uri":"/09-cylinder3d/"},{"categories":["论文阅读"],"content":"简介 论文：《Cylindrical and Asymmetrical 3D Convolution Networks for LiDAR Segmentation》 作者：Xinge Zhu,Hui Zhou,Tai Wang,Fangzhou Hong, Yuexin Ma, Wei Li, Hongsheng Li, Dahua Lin 机构：Chinese University of Hong Kong, § ShanghaiTech University 论文水平：CVPR2021 关键词：lidar segmentation 论文链接：paper ","date":"2022-03-19","objectID":"/09-cylinder3d/:1:0","tags":["论文阅读"],"title":"09 Cylinder3D","uri":"/09-cylinder3d/"},{"categories":["论文阅读"],"content":"摘要 大场景下的点云分割领域SOTA方法经常将点云投影到2D空间然后使用2D的卷积网络处理他们，这样虽然取得了具有竞争力的精度，但是不可避免地改变或者放弃了三维拓扑和几何关系。一种解决方案就是3D体素化和3D卷积网络，但是我们发现，这种方法在室外场景下的性能提升非常有限，很重要的原因就是室外场景下的点云具有稀疏性和密度可变性。 受到这项调查的启发，我们提出了一个全新的室外Lidar分割的框架，其使用圆柱型的区域划分方式以及设计了非对称的3D卷积网络，在保留点云固有属性的同时，探索3D几何信息。此外，我们还引入了逐点细化模块，以减轻受损的基于体素的标签编码的影响 我们在两个大场景数据集上评测了我们的模型，分别是SemanticKITTI和nuScenes。结果表明，我们的模型在SemanticKITTI数据集上达到了第一的性能，并且在nuScenes数据集上超越了现有算法较为明显的精度，约4%。此外提出的框架同样适用于点云全景分割以及点云3D检测 ","date":"2022-03-19","objectID":"/09-cylinder3d/:2:0","tags":["论文阅读"],"title":"09 Cylinder3D","uri":"/09-cylinder3d/"},{"categories":["论文阅读"],"content":"主要贡献 重新将Lidar分割问题的关注点从2D投影的方案转移到了3D表达上，并且探究了一些室外场景的挑战性问题，比如点云稀疏和随距离变化的密度. 提出了一个全新的框架，通过圆柱化分区以及非对称3D卷积网络，一定程度上解决了上述挑战 提出的方法在SemanticKITTI以及nuScenes两个数据集上，实现了SOTA，并且在点云目标检测以及点云全景分割两个任务上同样表现出优异的性能，说明方法具有极强的泛化性。 ","date":"2022-03-19","objectID":"/09-cylinder3d/:3:0","tags":["论文阅读"],"title":"09 Cylinder3D","uri":"/09-cylinder3d/"},{"categories":["论文阅读"],"content":"方法流程 ","date":"2022-03-19","objectID":"/09-cylinder3d/:4:0","tags":["论文阅读"],"title":"09 Cylinder3D","uri":"/09-cylinder3d/"},{"categories":["论文阅读"],"content":"概览 为了解决室外场景中的点云稀疏以及密度变化这两个困难，本文的框架针对性的使用了圆柱化以及非对称卷积，圆柱化的划分方式可以较好的适应变化的密度，对于输入的点云数据，首先将其按照圆柱的方式进行划分（类似体素化），进而使用非对称卷积学习每个Voxel级别的特征，最终，为了解决体素化带来的训练过程中的loss损失，本文还提出了一个point-wise的编码模块，用来调整loss，加入逐点的损失信息，所以最终的网络输出有两部分，分别voxel-wise的损失以及point-wise的损失。 ","date":"2022-03-19","objectID":"/09-cylinder3d/:4:1","tags":["论文阅读"],"title":"09 Cylinder3D","uri":"/09-cylinder3d/"},{"categories":["论文阅读"],"content":"圆柱区域划分(Cylindrical Partition) 第一行是range image的方案，其使用2D卷积，但是丢失了部分点云信息。 第二行是体素网格，第三行是圆柱网格，相比于体素，圆柱式的分区方式使点云分布更加均匀，89%对比61%。 此外，文中还给出了使用2D投影的以及基于体素网格的方法与本文方法的精度对比。可以看到polarnet等蓝色方法精度偏低。 圆柱化分区的优势在于，其可以很好的适应点云的密度变化，进而在较远的场景中，每个voxel中的点也是相对较于均匀分布的，对于提取特征的网络来说，点云在每个voxel中的均匀分布可以使网络更好的捕捉点云特征。 原始点云输入，进行坐标系的变换，将笛卡尔坐标系变换到polar坐标系，得到的三个坐标分别代表当前点到x-y平面坐标原点的距离，从x轴到y轴的角度以及高度。 另一边，使用MLP学习原始点云特征，进而将其整定到圆柱分区中，得到圆柱点云特征。 最终得到的特征张量的维度应该是 C x H x W x L，C表示特征维度，H表示圆柱的半径，W表示倾角，L表示高度。后续的非对称卷积会在这个张量上进行操作，以学习特征。 值得注意的是，随着距离边远，圆柱网格划分时会自动扩大网格体积，以维持较为均衡的点云，在远距离时与体素网格的效果对比明显，本文给出了详细的对比数据。见下表： ","date":"2022-03-19","objectID":"/09-cylinder3d/:4:2","tags":["论文阅读"],"title":"09 Cylinder3D","uri":"/09-cylinder3d/"},{"categories":["论文阅读"],"content":"非对称3D卷积(Asymmetrical 3D Convolution Network) 这里的非对称3D卷积网络，借鉴了前人的一些工作[1]，本文将原有2D的非对称卷积扩展到了3D。非对称卷积的作用就是，其可以增强水平和竖直方向上的响应，通过屏蔽原有3x3x3卷积核的某些维度，可以达到3x3x1或者3x1x3或者1x3x3的效果，因为这些卷积核不是对称的，所以叫做非对称卷积，这样在一定程度上增加了模型对翻转和旋转的鲁棒性。 对于非对称卷积，本文还使用了残差的结构，并且做了对应的消融实验来验证方案的有效性。在非对称残差卷积的基础上，本文提出的网络框架中，还利用非对称残差卷积实现了下采样以及上采样的模块。也就是网络框架中的AD以及AU模块。 ","date":"2022-03-19","objectID":"/09-cylinder3d/:4:3","tags":["论文阅读"],"title":"09 Cylinder3D","uri":"/09-cylinder3d/"},{"categories":["论文阅读"],"content":"点级别的特征细化模块(Point-wise Refinement Module) 虽然分区可以很有效地处理大规模地点云，但是却很难保留细粒化的点云信息。对于本文这类将点云分区的方法，无论是将点云划分成体素，还是扇形的分区，在网络预测时通常会每个分区预测一个标签，因此在计算每个分区的label时，都会存在精度上的损失。比如每个分区中的点可能属于不同的类别，所以我们可能需要采用众数投票的思想来获取当前分区的label，编码的损失就发生在这个阶段，换句话说就是一些点的类别信息被忽略了。为了解决这个问题，本文提出了点级别的优化模块，具体的操作方法就是通过圆柱化过程中的点到分区的映射关系，将高维度的分区特征再映射回每个点，然后再将每个点的原始特征与对应的分区特征聚合在一起，通过MLP学习对应的映射关系，最终输出的就是点级别的损失信息了。 ","date":"2022-03-19","objectID":"/09-cylinder3d/:4:4","tags":["论文阅读"],"title":"09 Cylinder3D","uri":"/09-cylinder3d/"},{"categories":["论文阅读"],"content":"实验结果 ","date":"2022-03-19","objectID":"/09-cylinder3d/:5:0","tags":["论文阅读"],"title":"09 Cylinder3D","uri":"/09-cylinder3d/"},{"categories":["论文阅读"],"content":"定量实验 分别在SemanticKITTI以及nuSence上进行的定量实验，对比点云语义分割的精度，评价指标是mIOU。 ","date":"2022-03-19","objectID":"/09-cylinder3d/:5:1","tags":["论文阅读"],"title":"09 Cylinder3D","uri":"/09-cylinder3d/"},{"categories":["论文阅读"],"content":"消融实验 分别探究了网络的不同模块的作用，以及非对称残差卷积的结构的有效性。 ","date":"2022-03-19","objectID":"/09-cylinder3d/:5:2","tags":["论文阅读"],"title":"09 Cylinder3D","uri":"/09-cylinder3d/"},{"categories":["论文阅读"],"content":"泛化性实验 本文的网络，在点云全景分割以及目标检测上，也表现了很好的性能。 ","date":"2022-03-19","objectID":"/09-cylinder3d/:5:3","tags":["论文阅读"],"title":"09 Cylinder3D","uri":"/09-cylinder3d/"},{"categories":["论文阅读"],"content":"Reference [1] X. DIng, Y. Guo, G. DIng, and J. Han, “ACNet: Strengthening the kernel skeletons for powerful CNN via asymmetric convolution blocks,” Proc. IEEE Int. Conf. Comput. Vis., vol. 2019-October, pp. 1911–1920, 2019. ","date":"2022-03-19","objectID":"/09-cylinder3d/:6:0","tags":["论文阅读"],"title":"09 Cylinder3D","uri":"/09-cylinder3d/"},{"categories":["学习笔记"],"content":"本文记录了深蓝课程学习过程，主要是关于camera、lidar、radar等传感器的原理分析以及相关知识。 ","date":"2022-03-17","objectID":"/2.-%E7%94%A8%E4%BA%8E%E6%84%9F%E7%9F%A5%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/:0:0","tags":["自动驾驶多传感器设计"],"title":"多传感器融合感知之用于感知的多传感器分析","uri":"/2.-%E7%94%A8%E4%BA%8E%E6%84%9F%E7%9F%A5%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/"},{"categories":["学习笔记"],"content":"一、传感器概述 常见的自动驾驶感知传感器，一般包括 lidar，camera，radar以及ultrasonic。 思考，为什么使用以上传感器来做感知任务？从人的角度分析，无非就是一些感官信息，触摸、看见、听见。所以从机器人的角度来看，上述传感器便能让机器人感知周边环境。 总的来看，激光使用激光束，camera使用可见光，radar使用毫米波，这三种都可以成为电磁波。 radar到camera到lidar，波长逐渐变小，我们都知道短波检测精度高，但是易受干扰，而长波传播距离远，抗干扰能力强。所以我们可以使用毫米波和激光波来互补。 此外，还有声波，比如超声波，这是一种机械波，其有一定透视能力，但是衰减快。 关于机械波与电磁波，机械波是由于周期性扰动产生的，并且传播需要介质。而电磁波则是电磁振荡的传播，不需要介质。以人类为例子，我们看到的都是电磁波，听到的都是机械波。其他形式的波还包括引力波、物质波等，但是均不太合适用作自动驾驶。 ","date":"2022-03-17","objectID":"/2.-%E7%94%A8%E4%BA%8E%E6%84%9F%E7%9F%A5%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/:1:0","tags":["自动驾驶多传感器设计"],"title":"多传感器融合感知之用于感知的多传感器分析","uri":"/2.-%E7%94%A8%E4%BA%8E%E6%84%9F%E7%9F%A5%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/"},{"categories":["学习笔记"],"content":"二、传感器原理分析 ","date":"2022-03-17","objectID":"/2.-%E7%94%A8%E4%BA%8E%E6%84%9F%E7%9F%A5%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/:2:0","tags":["自动驾驶多传感器设计"],"title":"多传感器融合感知之用于感知的多传感器分析","uri":"/2.-%E7%94%A8%E4%BA%8E%E6%84%9F%E7%9F%A5%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/"},{"categories":["学习笔记"],"content":"2.1 camera 2.1.1 成像原理 针孔(pin-hole)相机为例，小孔成像原理 相机是一种被动式传感器，依靠外界的光源（比如太阳）反射成像。因此对光照条件敏感。 将三维映射为二维，丢失了尺度信息。 清晰成像时需要满足像距、物距以及焦距之间的相对关系，假设焦距是f，像距是v，物距是u，那么应该满足，1/f = 1/u + 1/v，且像距应该大于一倍焦距小于二倍焦距，才可以呈现清晰的像。 此外，相机传感器由于小孔成像的原理，存在一定的视场角，且视角由像距和传感器尺寸共同决定。此处可以通过相似三角形，求解水平和竖直的视角，如下图，视角之前的区域就是相机的盲区 一般来讲，像距和焦距相差不大，在一些场景中可以认为像距等于焦距。并且焦距越大，视角越小，长焦看的远，短焦看得全，这也就是我们所说的长焦与短焦镜头的区别。 2.1.2 成像过程 景物在光源的照射下，产生的光学图像投射到相机中 镜头（LENS） 图像传感器，将光学信号转化为电信号，以及进一步通过AD转换器将模拟量转化为数字量。这里的光电转换传感器包含两种，分别是CCD以及CMOS，二者的差异在于信号的读出过程不同 CCD仅能输出模拟电信号，集成度低，而 CMOS将图像信号放大器、信号读取电路、AD转换等集成到一块芯片上，集成度高 CCD成本较高，工艺复杂，CMOS相对而言成本就低很多 CMOS一般输出频率可以很高，500FPS以上频率输出的相机都是使用CMOS的 DSP，数字信号经过DSP(Digital Signal Processing)进行加工处理，DSP包括ISP(Image Signal Processor)以及JPEG编码器等组成，DSP的功能就是对原始的图像数据进行过滤和筛选，最终将处理好的信号传递下去 IO，负责与其他设备进行通信，目前主流的IO接口包括USB以及以太网等。 2.1.3 相机选型 对于感知任务来说，需要使用相机同时检测近距离和远距离的目标，且车辆覆盖的像素不少于30个，红绿灯覆盖的像素不少于10个，而在焦距固定时，相机是无法满足同时这个要求的，因此需要不同的焦距。使用长焦感知远距离，短焦感知近距离。 常见的相机传感器供应商有 Sony、Onsemi（安森美）以及OmniVision（豪威）等。 相机传感器的一些核心指标包括像素尺寸、感光范围、输出帧率等。 2.1.4 成像方式 分为两种，卷帘快门(rolloing shutter)和全局快门(global shutter)。 自动驾驶场景中，一般使用rolling shutter，因为其制作工艺简单，成本低。 但是卷帘快门导致行与行之间成像时间有误差，进而存在两点问题 行之间时间戳不一致，一般取中间行的时间戳作为整张图片的时间戳。 行与行之间的成像有形变，这也叫做果冻效应，如下图 2.1.5 小结 相机是一种被动式的传感器，依靠可见光感知目标，感知结果稠密且连续，但丢失尺度，视野范围依靠镜头焦距调节，卷帘快门出发，时间戳有误差，成本百元级别，量产方案成熟。 ","date":"2022-03-17","objectID":"/2.-%E7%94%A8%E4%BA%8E%E6%84%9F%E7%9F%A5%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/:2:1","tags":["自动驾驶多传感器设计"],"title":"多传感器融合感知之用于感知的多传感器分析","uri":"/2.-%E7%94%A8%E4%BA%8E%E6%84%9F%E7%9F%A5%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/"},{"categories":["学习笔记"],"content":"2.2 lidar 2.2.1 成像原理 首先，关于lidar的基本原理，参考以下视频 https://www.youtube.com/watch?v=NZKvf1cX 简要来说，激光雷达通过TOF原理，自己发射光波来测量环境中障碍物的距离，多线的激光雷达可以通过旋转式的扫描方式来获取周边环境的点云信息。常见的激光雷达不仅可以返回目标表面点相对于自身的距离，还可以测量表面材质、颜色等信息，作为额外的每个点的属性（intensity、timestamp、elongation等）。 如上述简图所示，多个激光头并排旋转发射激光束，以构成周围环境的点云，其中，最上面激光头与最下面激光头的夹角叫做FOV，表示激光雷达竖直方向探测的角度范围。一般来讲， 可以通过修改激光雷达驱动文件，来配置线束之间的夹角，以达到下图的效果。 此外，激光雷达有一个很显然的特性，就是距离远近的同一目标，其覆盖的点云数量不同，越远越少，因为角度决定密度，进而决定感知距离。 对于检测任务，理论上车辆表面不少于30个点，行人表面不少于10个点。 2.2.2 常见的激光雷达类型以及核心参数 目前可以分为三类，分别是机械式、混合固态以及纯固态。 机械式，通过并列排列若干个激光头来产生多个线束，并且使用旋转平台来完成360度的水平fov，通常来讲机械式雷达较为精密，应该避免磕碰，一旦机械结构发生形变，就会影响测量结果，所以其寿命通常不可控。常见品牌有velodyne、何塞、镭神、速腾等。 混合固态，取消旋转平台，只用一个激光头，通过微振镜来产生不同的角度，但是并没有360度，水平和竖直都是确定的FOV，这种雷达使其有了过车规的可能，所以有一些无人驾驶公司会使用他们作为量产的解决方案。常见品牌有Innovution、DJI的livox等。 固态，进一步去掉微振镜的结构，完全通过固态电路板来产生点云，成本会更低，但是现在技术还不是特别成熟，需要进一步发展。 通常来讲，我们会关注lidar的线束、波长、测量精度、探测距离、视角以及分辨率、旋转频率等参数。 2.2.3 小结 Lidar是一种主动式传感器，通过自己发射激光束来对周边环境进行测距，生成的数据天然稀疏、但是测量距离精度高，且可以用来描述周边三维环境，其触发方式是逐点的，成像时间无误差，但是目前成本仍然是量产的一道阻碍。 ","date":"2022-03-17","objectID":"/2.-%E7%94%A8%E4%BA%8E%E6%84%9F%E7%9F%A5%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/:2:2","tags":["自动驾驶多传感器设计"],"title":"多传感器融合感知之用于感知的多传感器分析","uri":"/2.-%E7%94%A8%E4%BA%8E%E6%84%9F%E7%9F%A5%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/"},{"categories":["学习笔记"],"content":"2.3 radar 毫米波雷达是工作在毫米波波段的，电磁波频率大概是30 GHz ~ 300 GHz，波长介于1~10mm的雷达。毫米波雷达相对于激光雷达和camera，属于长波长，其对天气的鲁棒性更强。与lidar类似，毫米波雷达通过天线发射特定频率的电磁波，并计算发射和接收的差异性，进而获取目标的径向运动速度、飞行时间、径向距离等信息。 2.3.1 成像原理 毫米波雷达依靠多普勒效应，多普勒效应本质上说明了速度变化会引起波的发送和接收两者之间的频率差异。波源靠近接收者，那么频率升高，反之频率降低。 radar可以探测的物理量有三个，速度、距离、方位。 测速 其中测速是根据多普勒原理，测量得到的是相对且径向的速度，以FMCW调频连续波的radar为例，测速原理是，发射调频正弦波，通过计算发射和接收的频率变化，就可以计算相对速度。 推理过程如下 （毫米波是电磁波，空气中传播速度是c） 测距 除了测速，通过相位差计算频率的变化以及飞行时间t，还可以计算出径向的距离信息D，类似TOF原理 D=c·t/2。 测方位 radar内部通常设置1个发射天线，两个接收天线，通过计算反射波的相位差，可以计算出径向距离的差值，根据两个接收天线之间的距离l，以及径向距离之差Δd，可以大概估算出目标的方位角，推理过程如下图，这种估计会随着实际的θ角增加而误差变大。 其他信息 除了以上测量值，radar还可以拿到较为准确的timestamp以及粗略估计切向速度。由于自身测量的原理基于TOF，所以相对来讲时间戳信息是较为准确的。但是切向速度的估计通常误差较大。 2.3.2 radar的分类以及关键参数指标 按感知距离划分 短距离radar：探测范围大，但是距离较短 （15-30m），频段为24.0GHz 到 24.25GHz，窄带带宽 250 MHz，波长大于 1cm，严格来讲属于厘米波雷达。 中长距离radar：探测范围窄，但是距离较长（100-200m），最长可以长达250m，频段为76-77GHz，该频段有等效同性各向辐射功率的优势，同时满足高传输功率和宽工作带宽，可以同时做到长距离探测和高距离分辨率。波长更短所以收发天线面积大幅减小，雷达体积更小。 按电磁波辐射方式 可以分为脉冲和连续波两种方式，详见下图，其中FMCW是最常用的方式。 2.3.3 radar常见的问题 由于radar在处理原始数据时，为了计算发送与接收波之间的频率差，通常是将原始数据转换为频域处理，因为相对速度与频率差成正比，所以只要对频率差做阈值化，就可以得到想要的速度区间，实现测速的目的。但是这样其实对于理解传感器而言，并不是十分直观，如下图，颜色鲜艳的地方表示频率差比较大，也就代表着相对速度较大。 为什么好多人说radar误检比较多？ 在频域的阈值化过程中，需要人工设定参数来对频率差做筛选，这就会导致低阈值时噪声多，但是为了保证recall，提高信噪比，阈值不能设定太低。比如德尔福的rader阈值比较低，希望给用户更多的信息，但是conti的radar则是更倾向于保证结果的置信度，所以阈值较高。 所以归根结底，radar的结果与阈值设置有关系。 radar为什么没有高度信息 对于常见的radar来说，因为早期只感知BEV平面是够用的，所以不带有高度信息。但是近些年4D的radar有很多厂商在做，这是加入了高度信息的。 2.3.4 小结 Radar类似于Lidar，是一种主动式传感器，但是成像稀疏，并且在频域处理，成像通常在2.5D(无高度)-4D(有高度)，探测距离远近皆可，触发方式较为精准，时间戳无误差，价格在千元级别，成熟量产。 ","date":"2022-03-17","objectID":"/2.-%E7%94%A8%E4%BA%8E%E6%84%9F%E7%9F%A5%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/:2:3","tags":["自动驾驶多传感器设计"],"title":"多传感器融合感知之用于感知的多传感器分析","uri":"/2.-%E7%94%A8%E4%BA%8E%E6%84%9F%E7%9F%A5%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/"},{"categories":["学习笔记"],"content":"2.4 ultrasonic 超声波，是指传播速率大于20000Hz的机械波，正常声波的速度大概是340m/s，人耳可以听到的频率是20Hz-20000Hz之间，而超声波是大于这个区间的。 超声波的测距原理还是TOF，探测角一般是80-120°，近距离10cm之内会有盲区。一般超声波会被用于近距离，小于10m的障碍物感知。此外，超声波无法确定目标的方位，也就是说，在其感知范围内的障碍，超声波只能给出距离，而不能给出方位角的信息。 最终的超声波输出包含两个，分别是精准的时间戳以及0-1的障碍信息（粗略的距离值）。超声波有一个很好的特性就是抗干扰能力强，防水防尘能力好。 超声波的一些缺点如下： 对温度敏感 频率高，速度低，受自身速度影响较大（多普勒效应，自车速度大于相对速度时） 无法测量方位角 小结 超声波雷达是一种主动式传感器，感知结果可以近似为一种阶跃的物理量，由于无法感知方位角，所以大多会用来测量其感知范围内是否存在障碍。成本较低，小于1K，量产成熟。 ","date":"2022-03-17","objectID":"/2.-%E7%94%A8%E4%BA%8E%E6%84%9F%E7%9F%A5%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/:2:4","tags":["自动驾驶多传感器设计"],"title":"多传感器融合感知之用于感知的多传感器分析","uri":"/2.-%E7%94%A8%E4%BA%8E%E6%84%9F%E7%9F%A5%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/"},{"categories":["学习笔记"],"content":"三、自动驾驶车辆上的传感器 ","date":"2022-03-17","objectID":"/2.-%E7%94%A8%E4%BA%8E%E6%84%9F%E7%9F%A5%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/:3:0","tags":["自动驾驶多传感器设计"],"title":"多传感器融合感知之用于感知的多传感器分析","uri":"/2.-%E7%94%A8%E4%BA%8E%E6%84%9F%E7%9F%A5%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/"},{"categories":["学习笔记"],"content":"3.1 各传感器横向对比 总体而言，三种传感器各有优劣，所以目前主张多传感器融合的方案会想要集大家之长，但是激光雷达的量产化还有一段时间的路要走。 ","date":"2022-03-17","objectID":"/2.-%E7%94%A8%E4%BA%8E%E6%84%9F%E7%9F%A5%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/:3:1","tags":["自动驾驶多传感器设计"],"title":"多传感器融合感知之用于感知的多传感器分析","uri":"/2.-%E7%94%A8%E4%BA%8E%E6%84%9F%E7%9F%A5%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/"},{"categories":["学习笔记"],"content":"3.2 车载配置 现有的自动驾驶方案中，可以分为L2和L4两种。 一般L2或L2.5级别的自动驾驶，由于考虑了量产的需求，需要压缩成本，所以大多使用camera和radar，lidar一般均考虑半固态式，比如DJI的livox。而L4级别的自动驾驶则是会在早期的方案设计中加入机械式旋转的激光雷达。 所以，个人认为，自动驾驶传感器配置，现在就有了两种主流的方案，一种是极端主义者，代表就是Tesla，申明不使用激光雷达，并且也的确在近两年的FSD更新中逐步优化，甚至还提出了要使用camera代替radar的作用。另外一种就是多传感器融合，并且坚信lidar的量产成熟化会逐步加快，最终可以成熟地应用在自动驾驶中。 常见的用于感知的传感器配置可以参考下图 ","date":"2022-03-17","objectID":"/2.-%E7%94%A8%E4%BA%8E%E6%84%9F%E7%9F%A5%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/:3:2","tags":["自动驾驶多传感器设计"],"title":"多传感器融合感知之用于感知的多传感器分析","uri":"/2.-%E7%94%A8%E4%BA%8E%E6%84%9F%E7%9F%A5%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/"},{"categories":["学习笔记"],"content":"四、总结 对于自动驾驶任务来说，需要cover的场景因天气、光照、目标等因素而变得特别繁多，所以直观的想法就是将各种传感器的优势融合起来，比如多种电磁波与机械波的结合，被动传感器与主动传感器的结合，2D和3D的感知结合等等，这些都可以帮助我们解决困难的场景带来的挑战。 但是与此同时，一点不得不提的就是，成本控制，量产必然会经历成本的打磨，以及满足车规的要求。Lidar虽然相对量产化落后一些，但是发展很快，相信不久的以后就会成为量产的选择。 ","date":"2022-03-17","objectID":"/2.-%E7%94%A8%E4%BA%8E%E6%84%9F%E7%9F%A5%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/:4:0","tags":["自动驾驶多传感器设计"],"title":"多传感器融合感知之用于感知的多传感器分析","uri":"/2.-%E7%94%A8%E4%BA%8E%E6%84%9F%E7%9F%A5%E7%9A%84%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%88%86%E6%9E%90/"},{"categories":["论文阅读"],"content":"现有的3D sceneflow方法大多是自监督，因为flow的gt太难获得，而本文是一篇关于sceneflow弱监督的工作，发表在CVPR2021。 ","date":"2022-03-16","objectID":"/08-rigid3dsceneflow/:0:0","tags":["论文阅读"],"title":"08 Rigid3DSceneFlow","uri":"/08-rigid3dsceneflow/"},{"categories":["论文阅读"],"content":"简介 论文：《Weakly Supervised Learning of Rigid 3D Scene Flow》 作者：Zan Gojcic,Litany Andreas,Wieser Leonidas,J. Guibas, Tolga Birdal 机构：ETH Zurich, Stanford University, NVIDIA 论文水平：CVPR2021 关键词：sceneflow \u0026\u0026 weakly supervised 论文链接：paper ","date":"2022-03-16","objectID":"/08-rigid3dsceneflow/:1:0","tags":["论文阅读"],"title":"08 Rigid3DSceneFlow","uri":"/08-rigid3dsceneflow/"},{"categories":["论文阅读"],"content":"摘要 本文中，利用很多3D场景都能被表示成若干运动刚体运动这一观测，我们提出了一种数据驱动的scene flow估计算法。我们方法的核心在于能够通过考虑 3D 场景流与其他 3D 任务的结合在对象级别进行推理的深层架构。这种对象级抽象，使我们能够通过更简单的前背景分割和车辆自身运动来放宽对密集场景流监督信息的要求。使我们的方法非常适合最近发布的不包含密集的场景流注释的自动驾驶数据集。 作为输出，我们的模型提供了低级线索（如逐点的sceneflow）和高级线索（如刚性对象级别的整体场景理解）。 我们进一步提出了一个测试阶段的优化来改进预测的刚性场景流。 我们展示了我们的方法在四个不同的自动驾驶数据集上的有效性和泛化能力。代码开源，链接为：github.com/zgojcic/Rigid3DSceneFlow. ","date":"2022-03-16","objectID":"/08-rigid3dsceneflow/:2:0","tags":["论文阅读"],"title":"08 Rigid3DSceneFlow","uri":"/08-rigid3dsceneflow/"},{"categories":["论文阅读"],"content":"主要贡献 本工作提出一种弱监督方案，利用刚体假设，将场景流物体转换为刚体运动的变换矩阵求解问题。这带来的优点就是，我们只需要前景和背景的分割信息以及传感器自身的运动变化信息，而不用稠密的逐点级别的对场景流做真值标注。 基于数据驱动的方案，本工作取代了以往方法在点级别(point-wise)的场景流预测，而是先进行前景-背景分割，进而在实例级别对运动物体的场景流进行估计。此外，还在测试阶段提出了一种优化方案。 我们的方法是一种新颖且灵活的主干网络，可以基于此网络来拓展各种下游任务。 ","date":"2022-03-16","objectID":"/08-rigid3dsceneflow/:3:0","tags":["论文阅读"],"title":"08 Rigid3DSceneFlow","uri":"/08-rigid3dsceneflow/"},{"categories":["论文阅读"],"content":"相关工作 本文总结了现有的一些场景流预测的方法，根据监督信号的类型，可以分为两大类，自监督和无监督。 此外，本文还总结了现有方法的两大缺点： 无约束的点级别的场景流预测容易产生较大的误差，比如同一辆车上面的点，可能会有不同的场景流预测大小。 有监督的方法需要大量的、稠密的标注数据，需要对点云中每个点都标注场景流真值才能训练出较好的结果。 ","date":"2022-03-16","objectID":"/08-rigid3dsceneflow/:4:0","tags":["论文阅读"],"title":"08 Rigid3DSceneFlow","uri":"/08-rigid3dsceneflow/"},{"categories":["论文阅读"],"content":"方法流程 ","date":"2022-03-16","objectID":"/08-rigid3dsceneflow/:5:0","tags":["论文阅读"],"title":"08 Rigid3DSceneFlow","uri":"/08-rigid3dsceneflow/"},{"categories":["论文阅读"],"content":"问题定义 给定来自同一观测传感器的连续的两帧点云数据，对应的时刻分别是T0和T1，根据刚体运动的假设，本文将室外场景中的运动目标都认定为刚体，那么场景流的估计任务是估计逐点的运动速度。对应地，这个问题就可以转化为估计每个刚体的刚体变换矩阵，矩阵由平移和旋转两部分得到，如下式： 同理，由于传感器观测自身导致的静止/背景点的运动，同样可以通过对自身的刚体变换矩阵求解得到，对应地就是计算Tego。 ","date":"2022-03-16","objectID":"/08-rigid3dsceneflow/:5:1","tags":["论文阅读"],"title":"08 Rigid3DSceneFlow","uri":"/08-rigid3dsceneflow/"},{"categories":["论文阅读"],"content":"方法概览 本文通过先分割，再分别求解前景和背景的刚体变换，来实现场景流预测的目的。其中前景需要先进行聚类，以得到单独运动的实例的点云，再估计变换矩阵。背景则是降采样后对两帧点云直接估计变换矩阵。网络结构如下： 算法的整体流程为： 输入两帧连续的点云，然后均经过前景背景分割网络，分别得到前景点云和背景点云。 Instance cluster head，对得到的前景点云进行聚类，得到若干个运动的实例。 Ego motion head，对得到的两帧背景点云进行自身刚体变换矩阵的估计。 Scene flow head，根据两帧点云经过Encoder之后的相似性特征直接预测场景流信息。 最后，根据场景流估计的值以及对聚类得到的每个实例进行刚体变换的矩阵估计。 Loss部分，通过传感器自身的位姿变换以及前景背景分割的真值作为监督信息，计算对应的损失，迭代优化。 ","date":"2022-03-16","objectID":"/08-rigid3dsceneflow/:5:2","tags":["论文阅读"],"title":"08 Rigid3DSceneFlow","uri":"/08-rigid3dsceneflow/"},{"categories":["论文阅读"],"content":"损失函数 整体的损失函数分为三部分，分别是前背景分割损失、自身运动估计损失以及前景实例运动估计损失，分述如下： 1. 前背景分类损失 由于使用了逐点的分割监督信息，所以直接使用分类较为常见的二元交叉熵损失 2. 自身运动估计损失 由于背景点数量较大，所以为了减少计算量，需要先对两帧点云的背景点做下采样处理，采样点数为N=1024 运动估计损失的衡量是针对于刚体变换的矩阵，其中包括旋转Rego和平移矩阵tego，优化的目的如下式： 其中x表示第一帧点云中的点，Y表示第二帧点云，函数Φ表示在点集Y中找到和x匹配的点。对于变换矩阵T，可以使用Kabsch算法得出，对应的损失为 3. 前景实例运动估计损失 对于分割得到的前景点，先使用DBSCAN聚类算法，得到若干实例级别的点云簇C，然后根据scene flow head输出的场景流预测V，来优化Kabsch算法得到的变换矩阵T，公式如下： ","date":"2022-03-16","objectID":"/08-rigid3dsceneflow/:5:3","tags":["论文阅读"],"title":"08 Rigid3DSceneFlow","uri":"/08-rigid3dsceneflow/"},{"categories":["论文阅读"],"content":"实验结果 ","date":"2022-03-16","objectID":"/08-rigid3dsceneflow/:6:0","tags":["论文阅读"],"title":"08 Rigid3DSceneFlow","uri":"/08-rigid3dsceneflow/"},{"categories":["论文阅读"],"content":"定量实验 作者为了验证backbone主干网络以及scene flow head部分的网络结构的有效性，先仅使用这部分网络做监督学习，对应的性能对比如下 第二部分，使用了弱监督方法的性能对比如下 ","date":"2022-03-16","objectID":"/08-rigid3dsceneflow/:6:1","tags":["论文阅读"],"title":"08 Rigid3DSceneFlow","uri":"/08-rigid3dsceneflow/"},{"categories":["论文阅读"],"content":"消融实验 分别探究了网络的不同loss的作用，以及前背景分割和背景运动估计任务的作用。 ","date":"2022-03-16","objectID":"/08-rigid3dsceneflow/:6:2","tags":["论文阅读"],"title":"08 Rigid3DSceneFlow","uri":"/08-rigid3dsceneflow/"},{"categories":["论文阅读"],"content":"定性实验 ","date":"2022-03-16","objectID":"/08-rigid3dsceneflow/:6:3","tags":["论文阅读"],"title":"08 Rigid3DSceneFlow","uri":"/08-rigid3dsceneflow/"},{"categories":["学习笔记"],"content":"需求概述 自动驾驶的本质是解决出行问题，那么出行涉及到的问题包括 我在哪？要去哪？ 建图定位问题 SLAM 如何去？ 规划控制问题 路况如何？ 环境感知问题 ","date":"2022-03-10","objectID":"/1.-%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E4%BC%A0%E6%84%9F%E5%99%A8%E9%9C%80%E6%B1%82/:1:0","tags":["自动驾驶多传感器设计"],"title":"多传感器融合感知之自动驾驶传感器需求","uri":"/1.-%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E4%BC%A0%E6%84%9F%E5%99%A8%E9%9C%80%E6%B1%82/"},{"categories":["学习笔记"],"content":"传感器概述 首先，要实现上述功能需要各种传感器，结合不同传感器的特性才可以使算法更加鲁棒。那么自动驾驶涉及到的传感器如下： 上图的传感器包括： 激光雷达 （Light Detection And Ranging） 相机 （Camera） 毫米波雷达 （Radio Detection And Ranging） 超声波雷达 （ultrasonic Radar） 全球卫星定位系统 （Global Navigation Satellite System以及 Real-Time Kinematic） 惯性传感器 （Inertial Measurement Unit） 轮速记 （Wheel Speedometer） 上述传感器可以分为两类： 运动感知类-侧重于感知自身，解决建图定位 GNSS IMU 轮速计 Lidar Camera 环境感知类-侧重于感知环境，解决环境感知 Lidar Camera Radar 超声波 ","date":"2022-03-10","objectID":"/1.-%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E4%BC%A0%E6%84%9F%E5%99%A8%E9%9C%80%E6%B1%82/:2:0","tags":["自动驾驶多传感器设计"],"title":"多传感器融合感知之自动驾驶传感器需求","uri":"/1.-%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E4%BC%A0%E6%84%9F%E5%99%A8%E9%9C%80%E6%B1%82/"},{"categories":["学习笔记"],"content":"需求具体分析 从需求侧分析，传感器需要帮助自动驾驶车辆解决各种各样的corner case，覆盖的场景包括 从供给侧分析，各种传感器由于其物体特性不同，各有优劣 camera 颜色细节丰富，但缺乏尺度，且无主动光源 lidar 三维距离准确，但成本高，量产难度大，且对雨雾敏感 radar 可以感知速度，量产成熟，但高度和角度精度低，静止感知能力弱 所以，综上分析，我们才需要多传感器融合在一起。 ","date":"2022-03-10","objectID":"/1.-%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E4%BC%A0%E6%84%9F%E5%99%A8%E9%9C%80%E6%B1%82/:3:0","tags":["自动驾驶多传感器设计"],"title":"多传感器融合感知之自动驾驶传感器需求","uri":"/1.-%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E4%BC%A0%E6%84%9F%E5%99%A8%E9%9C%80%E6%B1%82/"},{"categories":["论文阅读"],"content":"本文是对Simon Lucey组一篇IROS2021工作的解读，其目标是评价lidar2map的配准方法在压缩地图上的性能。 ","date":"2022-03-06","objectID":"/07-registration-benchmarks/:0:0","tags":["论文阅读"],"title":"07 Registration Benchmarks","uri":"/07-registration-benchmarks/"},{"categories":["论文阅读"],"content":"简介 论文：《Map Compressibility Assessment for LiDAR Registration》 作者：Ming-Fang Chang, Wei Dong, Joshua Mangelson, Michael Kaess, and Simon Lucey 机构：CMU 论文水平：IROS2021 关键词：lidar2map \u0026\u0026 Registration 论文链接：paper ","date":"2022-03-06","objectID":"/07-registration-benchmarks/:1:0","tags":["论文阅读"],"title":"07 Registration Benchmarks","uri":"/07-registration-benchmarks/"},{"categories":["论文阅读"],"content":"摘要 本工作的目标是评估lidar-to-map的配准在压缩地图上的性能。现代自动驾驶汽车利用预先构建的 HD（高精度）地图来执行传感器到地图的配准，从而在位姿估计失败的场景进行重定位并减少大规模环境中的漂移。 然而，传感器到地图的配准通常是通过将传感器配准到一个密集的3D模型来实现的，对于高清地图而言,这会占用大量的存储空间，需要大量的数据处理开销。因此使用压缩地图进行配准是一个可行的方案，但具体使用哪种地图压缩方式才能保证点云拥有最佳配准性能，目前仍未有人探索这一问题。 综上所述，本工作提出了一种新颖且具有挑战性的基准，从三个角度评估现有的 LiDAR 到地图配准方法：地图可压缩性、鲁棒性和精度。我们比较了各种地图格式，包括原始点云、分层 GMM 和特征点，并在真实场景下的 LiDAR 数据集：KITTI odometry数据集和 Argoverse 跟踪数据集上展示了它们在可压缩性和鲁棒性之间的性能权衡。基准测试表明，当允许的地图尺寸上限很高时，最先进的基于深度特征点的方法明显优于传统方法。然而，当地图大小预算较低时，由于空间覆盖率差，在Argoverse 跟踪数据集中, 深度方法的性能低于使用更简单模型的传统方法。 ","date":"2022-03-06","objectID":"/07-registration-benchmarks/:2:0","tags":["论文阅读"],"title":"07 Registration Benchmarks","uri":"/07-registration-benchmarks/"},{"categories":["论文阅读"],"content":"Motivation 地图对于现代自动驾驶系统至关重要。 具有丰富先验知识的地图提供了在线传感器无法观察到的有价值的离线精炼信息，从而提高了系统性能。 现代地图，例如自动驾驶汽车使用的高精地图，大多包含高质量的密集 3D 模型和语义标签。然而，这些密集的 3D 模型需要巨大的存储空间并导致额外的在线数据处理开销。 密集的 3D 模型主要用于实现传感器到地图的精确配准，这是自动驾驶车辆在姿态估计失败时重新定位地图的关键任务，同时也减少了大规模场景下的姿态漂移误差。在实践中，除了重新定位之外，对于自动驾驶中的基本任务来说，密集的 3D 模型是不必要的。例如，运动规划、运动预测、目标跟踪和避障只需要传感器输入和带有粗略 3D 信息的语义地图标签，例如车道方向和交通灯的边界框。由于高清地图中的其他信息尺寸要小得多，因此在点云配准的过程中如果可以消除对稠密的3D模型的依赖会显著减少高精地图的尺寸大小。 虽然消除对密集 3D 模型的需求是可取的，但大多数现有的点云配准研究仅关注配准具有相似数据分布的两次扫描的准确性和速度，而传感器扫描和地图的数据分布则大不相同。相关基准通过重建精度而不是传感器到地图的配准精度来评估点云压缩性能 [1]。事实上，如果可以使用较轻量化的地图实现准确的传感器到地图配准，则无需加载完美重建的稠密3D模型。尽管一些工作已经针对所提出的特定数据格式针对地图压缩率评估了传感器到地图的配准，但没有通用标准可用于在不同压缩地图格式之间进行公平的定量比较[2], [3]. 在本文中，我们关注一个通用的设置——将 3D LiDAR 点云帧注册到 3D 地图，这是现代自动驾驶汽车执行传感器到地图注册的最常见配置。这种情况下的原始地图是离线构建的高质量、密集、大规模的点云。我们建议传感器到地图配准算法应该直接在某种压缩地图格式上运行，而不是原始点云，以消除存储和处理原始大比例点云的需要。我们在下面将此过程称为压缩注册。如图 1所示，所提出的压缩配准管道与使用原始点云图的方法相比有几个优点： 1）地图特征可以离线预先计算，因为它不需要任何在线输入。 2) 如果需要，在线地图数据解压缩花费的时间更少，因为它不需要恢复密集的 3D 地图。 3) 占用更少的存储空间和数据传输时间。 ","date":"2022-03-06","objectID":"/07-registration-benchmarks/:3:0","tags":["论文阅读"],"title":"07 Registration Benchmarks","uri":"/07-registration-benchmarks/"},{"categories":["论文阅读"],"content":"主要贡献 提出了第一个压缩式的 LiDAR-to-map的点云注册基准. 从三个角度评估现有的 LiDAR 到地图配准方法：地图可压缩性、鲁棒性和精度 评估了最近的基于深度学习的和经典的点云配准方法，包括基于原始点、基于 GMM 和基于特征点的方法。 定量结果揭示了不同方法的优劣，并为未来的研究提供了有价值的参考。 将向社区发布基准，以便将来方便地评估更多方法。 ","date":"2022-03-06","objectID":"/07-registration-benchmarks/:4:0","tags":["论文阅读"],"title":"07 Registration Benchmarks","uri":"/07-registration-benchmarks/"},{"categories":["论文阅读"],"content":"相关工作 参与对比的方法如下 其中，Map type表示了注册算法处理的数据格式。Data dimension表示使用的数据所拥有的特征维度。Deep表示是否使用深度学习。Global表示此方法是否需要一个较好的初始位姿。Scalable表示注册算法能否适应大场景的map。 ","date":"2022-03-06","objectID":"/07-registration-benchmarks/:5:0","tags":["论文阅读"],"title":"07 Registration Benchmarks","uri":"/07-registration-benchmarks/"},{"categories":["论文阅读"],"content":"方法流程 ","date":"2022-03-06","objectID":"/07-registration-benchmarks/:6:0","tags":["论文阅读"],"title":"07 Registration Benchmarks","uri":"/07-registration-benchmarks/"},{"categories":["论文阅读"],"content":"Overview 我们为各种压缩地图格式提出了一个用于压缩传感器到地图注册的通用基准。 提出的压缩配准管道如图 1 所示。在管道中，我们首先执行离线地图特征计算和压缩，使用嘈杂的初始姿势裁剪局部地图，然后将输入 LiDAR 扫描注册到裁剪后的压缩地图。 LiDAR 扫描被转换为评估配准方法中使用的相应格式，例如特征点或 GMM。 设 P 为输入 LiDAR 扫描，Q 为局部地图，T ∈ SE(3) 为包含旋转矩阵和平移的变换矩阵。 点云配准问题可以定义为： 其中f表示点云变换函数, L表示损失函数. 损失函数 L 因不同方法而异。 例如，点对点 ICP 使用选定点对之间的欧几里德距离，而点对平面 ICP 使用从点到成对局部平面块的平方距离。 对于在其他格式而不是原始点云上操作的方法，将 φ(.) 表示为一般特征提取函数，等式(1) 变成 其中φp(.) 和 φq(.) 不一定相同。例如，可以将原始点云注册到 GMM 模型。 ","date":"2022-03-06","objectID":"/07-registration-benchmarks/:6:1","tags":["论文阅读"],"title":"07 Registration Benchmarks","uri":"/07-registration-benchmarks/"},{"categories":["论文阅读"],"content":"Benchmark构建 本工作提出的benchmark与已有工作的不同之处在于，**要匹配的两部分数据是不对称的。**lidar scan更加稀疏, 携带噪声以及包含了运动目标。然而map更加稠密，并且离线构建好的,经历了去噪了移除运动物体等操作。 为了模拟实际场景中的初始位姿误差，本工作应用了随机均匀噪声。在xyz三个方向上的误差区间为[-10, 10]m，在roll pitch yaw三个角度上的误差区间为[-10, 10]度。这样的随机误差可以再现现实场景中的绝大多数可能的初始误差。 为了评估图一中的pipeline，本工作使用了KITTI Odometry以及Argoverse Tracking数据集。大概的流程是先将数据集预处理成若干数据对，每一对数据中包含局部地图以及lidar的点云帧。其中局部地图被裁剪为初始位姿周围40m的范围大小，接着被压缩成对应的形式， 点云压缩的实例如下图所示: 对于数据的预处理，我们对多帧lidar的点云进行聚合，以形成稠密的地图。由于KITTI中的真值噪声较多，我们使用SLAM替代了真值。而Argoverse中则是使用真值，对于移动物体的剔除，两个数据集同样存在差异。KITTI使用PVRCNN，Argoverse则是直接裁剪到可通行区域来移除车辆点。 ","date":"2022-03-06","objectID":"/07-registration-benchmarks/:6:2","tags":["论文阅读"],"title":"07 Registration Benchmarks","uri":"/07-registration-benchmarks/"},{"categories":["论文阅读"],"content":"Evaluation Metrics 1. Precision 该项主要评估平移和旋转的误差，令 R ∈ SO(3) 是一个旋转矩阵，t ∈ R3 是一个来自 T 的平移向量。我们通过以下方式测量精度： 2. Success Rate (SR) 平移和旋转误差都低于指定的阈值的数据对所占总数据对的比例。 我们选择平移误差阈值为 2m, 旋转误差阈值为 5° ","date":"2022-03-06","objectID":"/07-registration-benchmarks/:6:3","tags":["论文阅读"],"title":"07 Registration Benchmarks","uri":"/07-registration-benchmarks/"},{"categories":["论文阅读"],"content":"结果讨论 在我们的实验中，我们使用裁剪的地图作为目标，使用 LiDAR 扫描作为源。 对于非对称方法，切换源和目标可能会影响结果。 在我们评估的非对称方法中，我们使用从 GICP 和点到平面 ICP 的地图计算出的法线，因为地图更密集且噪声更少。 对于 HGMR，我们在地图上构建 GMM 树，因为 GMM 树的压缩比比对原始点进行下采样更重要。 我们还为 FilterReg 交换了源和目标，发现它的性能比当前配置差 对于基于点的方法，如果配准方法未提供分数，我们会随机对点进行下采样。 还可以将其他下采样技术与评估方法一起应用以提高性能。 我们基于特征点的方法的结果表明，特征提取和对应过滤方法对于最终性能都至关重要。 TEASER++ 通常优于经典的 RANSAC，但只有在我们的地图大小预算下与深度描述符一起使用时才能发挥最佳效果。 我们还注意到，当地图尺寸较小时，基于深度学习的方法失败主要是因为目标地图是基于特征点的，并且在密集下采样后过于稀疏。 基于深度形状模型的方法可能会增加下采样地图的空间覆盖范围并提高性能。 在不牺牲全局特征匹配精度的情况下进一步降低特征维度也值得更多研究。 ","date":"2022-03-06","objectID":"/07-registration-benchmarks/:7:0","tags":["论文阅读"],"title":"07 Registration Benchmarks","uri":"/07-registration-benchmarks/"},{"categories":["论文阅读"],"content":"定量实验 下面两个表格是分别在KITTI以及Argoverse数据集上的定量结果。SR表示成功率，TE表示平移误差，RE表示旋转误差。SR10 是指在给地图大小预算 10 字节/平方米的情况下测得的成功率。其他同理。 下表是成功率曲线。 我们观察到，在 KITTI 和 Argoverse 中，在地图大小 = 1 字节/平方米的情况下，FCGF (TEASER++) 和 HGMR (L2) 的表现优于所有其他方法。 ","date":"2022-03-06","objectID":"/07-registration-benchmarks/:7:1","tags":["论文阅读"],"title":"07 Registration Benchmarks","uri":"/07-registration-benchmarks/"},{"categories":["论文阅读"],"content":"Reference [1] Cao, C., Preda, M., \u0026 Zaharia, T. (2019). 3D point cloud compression: A survey. Proceedings - Web3D 2019: 24th International ACM Conference on 3D Web Technology. https://doi.org/10.1145/3329714.3338130 [2] Bai, X., Luo, Z., Zhou, L., Fu, H., Quan, L., \u0026 Tai, C. L. (2020). D3Feat: Joint learning of dense detection and description of 3D local features. Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition. https://doi.org/10.1109/CVPR42600.2020.00639 [3] Yin, H., Wang, Y., Tang, L., Ding, X., Huang, S., \u0026 Xiong, R. (2021). 3D LiDAR Map Compression for Efficient Localization on Resource Constrained Vehicles. IEEE Transactions on Intelligent Transportation Systems. https://doi.org/10.1109/TITS.2019.2961120 ","date":"2022-03-06","objectID":"/07-registration-benchmarks/:8:0","tags":["论文阅读"],"title":"07 Registration Benchmarks","uri":"/07-registration-benchmarks/"},{"categories":["论文阅读"],"content":"Transformer在CV任务中的应用已经得到了很多工作的验证，但是对于点云处理任务，Transformer的尝试还不是特别多，这篇文章就是以PVCNN为基础，将Transformer融入进来。 ","date":"2022-01-26","objectID":"/06-pvt/:0:0","tags":["论文阅读"],"title":"论文阅读06 PVT","uri":"/06-pvt/"},{"categories":["论文阅读"],"content":"简介 论文：《PVT: Point-Voxel Transformer for Point Cloud Learning》 作者：Zhang Cheng1*, Haocheng Wan1∗, Xinyi Shen2, Zizhao Wu1† 机构：Hangzhou Dianzi University, University College London 论文水平：Arxiv 关键词：point-voxel \u0026\u0026 transformer 论文链接：paper ","date":"2022-01-26","objectID":"/06-pvt/:1:0","tags":["论文阅读"],"title":"论文阅读06 PVT","uri":"/06-pvt/"},{"categories":["论文阅读"],"content":"摘要 与卷积神经网络相比，近期一些基于纯Transformer架构的工作在点云领域的评价基准上取得了令人惊叹的准确性。然而，现有的点云Transformer的计算成本很高，因为点云数据的不规则性浪费了大量时间。为了解决这个问题，我们提出了稀疏窗口注意（Sparse Window Attention）模块来从非空体素中收集粗糙的局部特征，这不仅避免了计算昂贵的不规则数据结构和无效的空体素，而且维持了线性的计算复杂度。同时，为了收集有关全局形状的细粒度特征，我们引入了相对注意力（Relative Attention）模块，其针对物体刚性变换设计了相对位置编码。配备 SWA 和 RA，我们构建了称为 PVT 的神经架构，将两个模块集成到点云学习的联合框架中。与以前的基于 Transformer 和基于注意力的模型相比，我们的方法在分类基准上达到了 94.0% 的最高准确率，平均推理速度提高了 10 倍。大量实验也验证了 PVT 在Part Segmentation和Semantic Segmentation任务上的有效性（分别为 86.6% 和 69.2% mIoU）。 ","date":"2022-01-26","objectID":"/06-pvt/:2:0","tags":["论文阅读"],"title":"论文阅读06 PVT","uri":"/06-pvt/"},{"categories":["论文阅读"],"content":"主要贡献 提出了PVT的框架，同时使用Transformer增强基于点的特征提取以及基于体素的特征体素方案。 提出了一种高效的局部注意力模块，名为SWA，结合了稀疏卷积以及Swin Transformer[1]中的shift window设计，使计算复杂度降低到线性。 针对点云的多视角变换问题，使用相对位置编码来计算相对注意力（RA），从而对不同视角下的点云输入鲁棒。 在点云分类、局部分割以及语义分割任务上均做了实验，证明方法的有效性。 ","date":"2022-01-26","objectID":"/06-pvt/:3:0","tags":["论文阅读"],"title":"论文阅读06 PVT","uri":"/06-pvt/"},{"categories":["论文阅读"],"content":"方法流程 ","date":"2022-01-26","objectID":"/06-pvt/:4:0","tags":["论文阅读"],"title":"论文阅读06 PVT","uri":"/06-pvt/"},{"categories":["论文阅读"],"content":"网络总览 如上图所示，网络输入一帧点云数据，经过若干组PVT模块提取特征之后，后面接多尺度的特征融合以及对应任务的输出头。这里每个PVT模块都包含了两个分支，分别从原始点云以及体素化点云两种形式上学习点云特征。其中作者指出，由于体素结构是规则且连续的，所以基于体素化的分支可以学习到局部上下文信息。而基于点的分支则更侧重于提取全局的细粒度特征，最终两分支的信息融合，以实现一个PVT模块的特征学习。 ","date":"2022-01-26","objectID":"/06-pvt/:4:1","tags":["论文阅读"],"title":"论文阅读06 PVT","uri":"/06-pvt/"},{"categories":["论文阅读"],"content":"基于体素的分支 体素化分支主要解决的问题有两个，其一是降低Transformer中自注意力机制的计算复杂度，其二是解决点云稀疏性带来的大量空体素的问题。 为了降低自注意力的计算复杂度，作者借鉴了Swin Transformer中划分window的思想，选择将三维体素网格划分为若干局部框，这样在每个局部框中计算自注意力，可以将计算复杂度降低到与体素数量呈线性关系的级别。复杂度的对比如下 式1表示全局的自注意力的计算复杂度，式2表示划分局部框之后的计算复杂度，总体来说，划分局部框之后，计算复杂度与体素数量R^3成线性关系。 为了解决点云稀疏性的问题，作者借鉴了Sparse Conv的思想，通过维护一个哈希表，来保留非空体素的索引，加快了计算效率。如下图所示： 此外，为了使不同的局部框之间进行信息交流，作者同样使用了Swin Transformer中的shift方案 ","date":"2022-01-26","objectID":"/06-pvt/:4:2","tags":["论文阅读"],"title":"论文阅读06 PVT","uri":"/06-pvt/"},{"categories":["论文阅读"],"content":"基于点的分支 这里使用了一个通用的transformer的自注意力框架，以获得全局的点云特征，自注意力计算公式如下 为了使网络与输入点云的角度以及位置信息解耦，作者使用了相对位置编码，对每个点云中的点，都计算其余所有点相对于当前点的曼哈顿距离，公式如下 ","date":"2022-01-26","objectID":"/06-pvt/:4:3","tags":["论文阅读"],"title":"论文阅读06 PVT","uri":"/06-pvt/"},{"categories":["论文阅读"],"content":"实验 ","date":"2022-01-26","objectID":"/06-pvt/:5:0","tags":["论文阅读"],"title":"论文阅读06 PVT","uri":"/06-pvt/"},{"categories":["论文阅读"],"content":"定量实验 作者在点云形状分类，局部分割以及语义分割任务上都做了实验，效果均达到了SOTA。 ","date":"2022-01-26","objectID":"/06-pvt/:5:1","tags":["论文阅读"],"title":"论文阅读06 PVT","uri":"/06-pvt/"},{"categories":["论文阅读"],"content":"定性实验 下面是S3DIS数据集上做的可视化定性分析 ","date":"2022-01-26","objectID":"/06-pvt/:5:2","tags":["论文阅读"],"title":"论文阅读06 PVT","uri":"/06-pvt/"},{"categories":["论文阅读"],"content":"消融实验 作者评估了基于点的分支(PB)、基于体素的分支(VB)、局部框平移操作(shifting)以及每个模块的重复次数(NPB)对模型精度的关系。 ","date":"2022-01-26","objectID":"/06-pvt/:5:3","tags":["论文阅读"],"title":"论文阅读06 PVT","uri":"/06-pvt/"},{"categories":["论文阅读"],"content":"Reference [1] Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., Lin, S., \u0026 Guo, B. (n.d.). Swin Transformer: Hierarchical Vision Transformer using Shifted Windows. ICCV 2021. ","date":"2022-01-26","objectID":"/06-pvt/:6:0","tags":["论文阅读"],"title":"论文阅读06 PVT","uri":"/06-pvt/"},{"categories":["系统装机"],"content":"由于之前的conda版本比较低，且环境较为混乱，可能是误删了什么东西，丢失了base环境，综合考虑以上种种因素，决定重装conda~ ","date":"2022-01-14","objectID":"/%E9%87%8D%E8%A3%85conda/:0:0","tags":["代码环境"],"title":"重装Conda","uri":"/%E9%87%8D%E8%A3%85conda/"},{"categories":["系统装机"],"content":"1. 卸载 找到conda的文件夹 sudo rm -rf your_dir 注释掉conda的环境配置 sudo gedit ~/.bashrc ","date":"2022-01-14","objectID":"/%E9%87%8D%E8%A3%85conda/:1:0","tags":["代码环境"],"title":"重装Conda","uri":"/%E9%87%8D%E8%A3%85conda/"},{"categories":["系统装机"],"content":"2. 重新安装 下载conda官网 点击下载, 选 64-Bit (x86) Installer (550 MB) 下载好之后, 找到目录 给权限, 运行 sudo chmod 777 Anaconda3-2020.07-Linux-x86_64.sh bash Anaconda3-2020.07-Linux-x86_64.sh 安装过程中, 在安装目录处修改目录, 第二个问题选yes ","date":"2022-01-14","objectID":"/%E9%87%8D%E8%A3%85conda/:2:0","tags":["代码环境"],"title":"重装Conda","uri":"/%E9%87%8D%E8%A3%85conda/"},{"categories":["系统装机"],"content":"3. 环境配置 配置conda环境有几种方式 ","date":"2022-01-14","objectID":"/%E9%87%8D%E8%A3%85conda/:3:0","tags":["代码环境"],"title":"重装Conda","uri":"/%E9%87%8D%E8%A3%85conda/"},{"categories":["系统装机"],"content":"私人使用 首先第一种,刚刚安装时第二个问题选yes的话, 默认应该已经配置好了, 在~/.bashrc下.应该已经有conda的配置了, 如下: __conda_setup=\"$('/usr/local/conda/anaconda3/bin/conda' 'shell.bash' 'hook' 2\u003e /dev/null)\" if [ $? -eq 0 ]; then eval \"$__conda_setup\" else if [ -f \"/usr/local/conda/anaconda3/etc/profile.d/conda.sh\" ]; then . \"/usr/local/conda/anaconda3/etc/profile.d/conda.sh\" else export PATH=\"/usr/local/conda/anaconda3/bin:$PATH\" fi fi unset __conda_setup 这时conda就已经可以使用了 ","date":"2022-01-14","objectID":"/%E9%87%8D%E8%A3%85conda/:3:1","tags":["代码环境"],"title":"重装Conda","uri":"/%E9%87%8D%E8%A3%85conda/"},{"categories":["系统装机"],"content":"公共使用 那因为我刚刚安装到根目录下了,这种安装方式适用于服务器等多用户, 安装到根目录下之后就可以多用户一起使用conda, 这时可以直接配置profile文件, 这样在其他用户下就可以共享conda的环境了,如下: sudo gedit /etc/profile export PATH=/usr/local/conda/anaconda3/bin:$PATH # 注意路径 source /etc/profile 不过我自己的电脑只需要自己用,而且平时我需要使用ros,所以需要系统的python, 如果不是需要, 我不会启动conda的环境, 那么这时我们可以取消第一种和第二种的配置, 直接更改自己的bashrc文件 如下: alias de='conda deactivate' alias base='. /usr/local/conda/anaconda3/etc/profile.d/conda.sh \u0026\u0026 conda activate base' 更改之后重启或者重新打开终端即可 ","date":"2022-01-14","objectID":"/%E9%87%8D%E8%A3%85conda/:3:2","tags":["代码环境"],"title":"重装Conda","uri":"/%E9%87%8D%E8%A3%85conda/"},{"categories":["学习笔记"],"content":"最近要使用nuScenes数据集进行实验，学习过程中的笔记如下。 ","date":"2022-01-12","objectID":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/:0:0","tags":["Dataset"],"title":"NuScenes数据集笔记","uri":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/"},{"categories":["学习笔记"],"content":"数据集简介 nuScenes数据集是由Motional（以前为nuTonomy）的团队开发的用于自动驾驶的公共大型数据集，其中，Motional是由现代汽车集团(Hyundai Motor Group)和Aptiv PLC的合资企业，在2020年成立后，将原有的nuTonomy团队进行了扩展。哦对，这个团队还是PointPainting以及PointPillars的作者。 数据集部分，目前全部的nuScenes数据集包含四部分，分别是nuPlan、nuScenes、nuImages以及nuReality，其中nuReality是用作VR(Virtual Reality)的数据集。 对于nuScenes这部分三维场景的数据集来说， 2019 年 3 月，发布了包含全部 1000 个场景的完整 nuScenes 数据集，其数据量大概是KITTI数据集的7倍左右。 2020 年 7 月，发布了 nuScenes-lidarseg。在 nuScenes-lidarseg 中，共有 32 种语义标签（即激光雷达语义分割）对 nuScenes 中关键帧中的每个激光雷达点进行注释。因此，nuScenes-lidarseg 在 40,000 个点云和 1000 个场景（850 个用于训练和验证的场景，以及 150 个用于测试的场景）中包含 14 亿个注释点。 ","date":"2022-01-12","objectID":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/:1:0","tags":["Dataset"],"title":"NuScenes数据集笔记","uri":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/"},{"categories":["学习笔记"],"content":"Features 这里只关注数据集中一些三维数据的feature，更多信息可以自行查阅官网. 传感器部署 lidar x 1 20Hz 32 channels 水平FOV360° , 竖直FOV +10° 到 -30° 点云范围在 80m-100m左右, 最远70m左右仍可以保证点云具有 ± 2 cm 的精度 每秒点云最多 ~139万个点 radar x 5 77GHz的波频 13Hz 采样频率 最远可测250m 测速精度大概 ±0.1 km/h camera x 6 12Hz 采样频率 1/1.8'' CMOS，1600x1200 分辨率 像素编码格式为 Bayer8 imu x 1 gps x 1 数据量信息 1000个场景，每个场景20s，地点在波士顿和新加坡这两个城市；20s时长以显示各种驾驶操作，交通状况和意外行为 140万帧相机的图片 39万帧lidar点云 覆盖23种类别的目标以及1.4M的手动标注的3D bounding boxes 覆盖了32种类别以及1.1B个手动标注的lidar points 各传感器时间同步 为了在 LIDAR 和摄像头之间实现良好的跨模态数据对齐，当顶部 LIDAR 扫过摄像头 FOV 的中心时，会触发摄像头的曝光。图像的时间戳为曝光触发时间；而激光雷达扫描的时间戳是当前激光雷达帧实现全旋转的时间。鉴于相机的曝光时间几乎是瞬时的，这种方法通常会产生良好的数据对齐。请注意，相机以 12Hz 运行，而 LIDAR 以 20Hz 运行。12 次相机曝光尽可能均匀地分布在 20 次激光雷达扫描中，因此并非所有激光雷达扫描都有相应的相机帧。 ","date":"2022-01-12","objectID":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/:1:1","tags":["Dataset"],"title":"NuScenes数据集笔记","uri":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/"},{"categories":["学习笔记"],"content":"Benchmarks 由于NuScenes包含了时序信息，所以除了常见的检测跟踪分割任务，还有一些轨迹预测以及规划的任务benchmarks，具体包括：detection、tracking、prediction、lidar segmentation、panoptic、planning ","date":"2022-01-12","objectID":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/:1:2","tags":["Dataset"],"title":"NuScenes数据集笔记","uri":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/"},{"categories":["学习笔记"],"content":"数据集下载 需要注册账号并登陆后才可下载，界面如下： ","date":"2022-01-12","objectID":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/:2:0","tags":["Dataset"],"title":"NuScenes数据集笔记","uri":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/"},{"categories":["学习笔记"],"content":"数据集使用以及devkit说明 官方给了非常详细的使用教程，具体可以参考github上的devkit ","date":"2022-01-12","objectID":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/:3:0","tags":["Dataset"],"title":"NuScenes数据集笔记","uri":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/"},{"categories":["学习笔记"],"content":"数据集文件结构 我这里只下载了nuScenes部分的数据集，下载好的目录结构如下： /data/sets/nuscenes samples - 关键帧的传感器数据. sweeps - 所有帧的传感器数据. maps - 地图相关文件. v1.0-* - trainval对应的元数据以及标注文件，json格式 值得注意的是，nuScenes采用了token的方式，将传感器、时间戳、帧id等都抽象成token，对应地，上述目录结构中，sweeps以及samples中也是根据不同传感器的名称来存放的，如下所示。 . ├── CAM_BACK ├── CAM_BACK_LEFT ├── CAM_BACK_RIGHT ├── CAM_FRONT ├── CAM_FRONT_LEFT ├── CAM_FRONT_RIGHT ├── LIDAR_TOP ├── RADAR_BACK_LEFT ├── RADAR_BACK_RIGHT ├── RADAR_FRONT ├── RADAR_FRONT_LEFT └── RADAR_FRONT_RIGHT ","date":"2022-01-12","objectID":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/:3:1","tags":["Dataset"],"title":"NuScenes数据集笔记","uri":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/"},{"categories":["学习笔记"],"content":"架构中的基础概念 此外，nuScenes中的一些基础概念如下： log - Log information from which the data was extracted. scene - 20 second snippet of a car’s journey. sample - An annotated snapshot of a scene at a particular timestamp. sample_data - Data collected from a particular sensor. ego_pose - Ego vehicle poses at a particular timestamp. sensor - A specific sensor type. calibrated sensor - Definition of a particular sensor as calibrated on a particular vehicle. instance - Enumeration of all object instance we observed. category - Taxonomy of object categories (e.g. vehicle, human). attribute - Property of an instance that can change while the category remains the same. visibility - Fraction of pixels visible in all the images collected from 6 different cameras. sample_annotation - An annotated instance of an object within our interest. map - Map data that is stored as binary semantic masks from a top-down view. ","date":"2022-01-12","objectID":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/:3:2","tags":["Dataset"],"title":"NuScenes数据集笔记","uri":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/"},{"categories":["学习笔记"],"content":"架构示意图解析 nuScenes数据集中的架构是基于token的机制，将上述13个概念连接起来，如下图所示： 首先，我们可以从左到右看，采集数据的车在运行时会直接记录一些实时的信息，比如车辆编号，地点，日期，地图文件名，传感器之间的内外参等。 接着，我们可以对采集到的数据做解析，将所有数据分成一个又一个的scene，每个场景20s。场景之下是sample，表示的是某个特定时间戳在场景中的关键帧，它是有标注的（注意，在nuScenes中对每个scene，只以2hz的频率标注，也就是说，20Hz的lidar，10Hz只有一帧是有label的）。与sample对应的是sample data，其关联了底层的传感器数据源文件以及一些标定数据和ego的位姿信息。 最后，就是对数据的整理和标注，对于一个scene中不同帧之间相同的object，其表示为一个instance。此外还会有一些属性、类别和可见性的表达。注意，可见程度是根据目标在6个相机视野中的状态来衡量的。 ","date":"2022-01-12","objectID":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/:3:3","tags":["Dataset"],"title":"NuScenes数据集笔记","uri":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/"},{"categories":["学习笔记"],"content":"数据集中类别定义 ","date":"2022-01-12","objectID":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/:3:4","tags":["Dataset"],"title":"NuScenes数据集笔记","uri":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/"},{"categories":["学习笔记"],"content":"Tutorial示例（超详细） https://www.nuscenes.org/nuscenes?tutorial=nuscenes ","date":"2022-01-12","objectID":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/:3:5","tags":["Dataset"],"title":"NuScenes数据集笔记","uri":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/"},{"categories":["踩坑尝试"],"content":"出于对新鲜实物的好奇，我曾经探索过很多版本的主题样式，比如fluid以及butterfly，他们都是基于hexo框架的主题，其功能大多异常丰富，让初始者观之眼花缭乱。但使用过一段时间后，还是觉得自己需求的是一款简洁为主的主题，因此有了这款loveit主题的尝试，特此记录如下。 ","date":"2022-01-11","objectID":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/:0:0","tags":["Misc"],"title":"基于hugo的Loveit主题博客搭建记录","uri":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/"},{"categories":["踩坑尝试"],"content":"明确自己的需求喜好 既然想换主题，那么明确自己需求的主题样式很重要，所以我找了大量的博客以及网页推荐，主要渠道来源于以下几个方面： 知乎等平台的总结推荐 github直接搜索主题字样 寻找一些关注度较高的博客网站， 查看他们的友链；或者是在诸如butterfly这种主题主页会有一些博客的展示 那么看过了大多数的主题之后，我越发确定自己想要的就是偏简洁风的样式。在这期间，我还尝试过使用Notion搭配一些软件或者是网站直接创建博客，但是相关的生态不是很多，仅有的几种方案列举如下： nobelium 界面较为简洁, 使用vercel托管github的项目，可以与notion联动, 自动更新同步notion中的内容 Potion 看起来不错，但是使用就需要付费 Super 使用较为简单, 可以自己定义很多css代码块, 以定义header navbar等，但是稍微高级一点的功能就需要付费 看起来唯一可行的就是nobelium这个项目，我也在少数派上发现了对应的文章教程，大概尝试了之后发现还是有很多bug需要改进的，所以最终不得不放弃了使用Notion这个想法~ 放两个我觉得还算不错的博客主题: https://geekplux.com/posts https://hugoloveit.com/posts/ 所以初步选定loveit作为要配置的主题样式~ ","date":"2022-01-11","objectID":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/:1:0","tags":["Misc"],"title":"基于hugo的Loveit主题博客搭建记录","uri":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/"},{"categories":["踩坑尝试"],"content":"配置过程记录 ","date":"2022-01-11","objectID":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/:2:0","tags":["Misc"],"title":"基于hugo的Loveit主题博客搭建记录","uri":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/"},{"categories":["踩坑尝试"],"content":"下载hugo 因为loveit是基于hugo的，所以需要先下载，这里考虑到一些拓展功能，建议下载extend版本。 sudo dpkg -i xxx.deb ","date":"2022-01-11","objectID":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/:2:1","tags":["Misc"],"title":"基于hugo的Loveit主题博客搭建记录","uri":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/"},{"categories":["踩坑尝试"],"content":"使用hugo创建自己的博客文件夹 安装之后，在终端敲hugo 就可以有以下的输出了 \u003e hugo Error: Unable to locate config file or config directory. Perhaps you need to create a new site. Run `hugo help new` for details. Total in 4 ms 接下来就是按照loveit的主题教程操作，使用以下命令新建博客文件夹 hugo new site my_website cd my_website ","date":"2022-01-11","objectID":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/:2:2","tags":["Misc"],"title":"基于hugo的Loveit主题博客搭建记录","uri":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/"},{"categories":["踩坑尝试"],"content":"安装主题 git clone https://github.com/dillonzq/LoveIt.git themes/LoveIt 关于主题的配置，自行参考教程即可。 ","date":"2022-01-11","objectID":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/:2:3","tags":["Misc"],"title":"基于hugo的Loveit主题博客搭建记录","uri":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/"},{"categories":["踩坑尝试"],"content":"创建博客 这部分在my_website目录下的content下面，可以自行创建，或使用hugo命令在终端创建。 hugo new posts/first_post.md 此外，我们还可以创建自己的专属内容，比如定义一个收藏页面，那就在content目录下创建一个collections的文件夹，再在其中创建一个index.md文件，这部分可以通过自定义manu bar的方式，将这个index对应的网页链接到导航栏。 我的改动如下： 改动config.toml，添加以下内容： [[menu.main]] identifier = \"collections\" pre = \"\" post = \"\" name = \"收集\" url = \"/collections/\" title = \"\" weight = 5 对应地，需要在content目录下创建collections文件夹，这样我们就完成了导航栏到自定义页面的链接。 综上，具体的config配置我就不记录太多了，各凭喜好~ ","date":"2022-01-11","objectID":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/:2:4","tags":["Misc"],"title":"基于hugo的Loveit主题博客搭建记录","uri":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/"},{"categories":["思考总结"],"content":"在平时的学习生活中，工具软件是我们必不可少的，我个人也热衷于探究各种新奇的软件APP，在这里总结一下平时学习生活涉及到的软件以及工作流。 ","date":"2022-01-10","objectID":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/:0:0","tags":["工作流","效率"],"title":"工作流总结","uri":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/"},{"categories":["思考总结"],"content":"工作流的不同阶段 我个人喜欢将学习生活的工作流分为四个阶段，分别是：信息输入 -\u003e 信息整理 -\u003e 回顾总结 -\u003e 创作输出。 ","date":"2022-01-10","objectID":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/:1:0","tags":["工作流","效率"],"title":"工作流总结","uri":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/"},{"categories":["思考总结"],"content":"信息输入 其中，信息输出包括从各种能接触到的信息源中获取的自身感兴趣的知识点，比如平时阅读论文的笔记以及看网课的笔记等，我会选择在Notion中编辑他们，这样方便各个设备之间同步。 除了笔记、论文等较为集中的信息摄入外，一般会涉及到一个概念就是稍后阅读 。我一般会将微信公众号的推送、medium以及知乎等博文的推送等碎片化的知识点整理到一个临时存储平台中，这里就是pocket，然后定期清理一波，将他们划线批注，提取其中较为重点且易忘的部分。为了减少手动操作，我使用Readwise软件，绑定pocket以及我的知识库Notion，这样我在pocket中的阅读结果就可以自动同步到Notion中。 ","date":"2022-01-10","objectID":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/:1:1","tags":["工作流","效率"],"title":"工作流总结","uri":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/"},{"categories":["思考总结"],"content":"信息整理 接下来就是较为重量的软件，Notion，我对它的定位是一个知识库，我会将形形色色的内容放在其中，并且分门别类，定期整理一次。 此外，为了更好地对学过的内容做总结和回顾，我还会在Notion中做一些初步的内容收集以及内容整理。比如想要确定深度学习中BN相关的知识点，我会先在Notion中创建一个page，然后根据BN涉及到的内容，创建不同的标题，每一部分标题对应的资料则是靠平时的浏览学习进行收集。最终，资料内容丰富到一定程度或者个人理解到达一定程度后，我会对这些内容进行初步的整理，以实现个人学习的内容输出。 ","date":"2022-01-10","objectID":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/:1:2","tags":["工作流","效率"],"title":"工作流总结","uri":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/"},{"categories":["思考总结"],"content":"回顾总结 经过Notion做初步的收集和整理之后，我选择使用Obsidian这款软件做我的内容回顾与总结。其实对我个人来说，从功能上来看，Notion与Obsidian存在很多重合的地方，比如Obsidian中的日记功能在Notion中也可以通过Calendar实现。但是考虑到Notion自身的同步以及对各种网址和文件等较为友好，在很多功能方面我都选择了Notion，唯独回顾总结这里我选择了使用Obsidian，原因在于其本地化的设定正好可以与我的个人博客相关联，这样我就不需要在Notion中写一遍总结之后为了博客再将其导出到单独的Markdown文件中。 因此，我对于Obsidian的定义更加纯粹，就是单纯的内容整理以及总结的平台，其附带的关系图谱也可以帮我较好地管理输出的内容。 ","date":"2022-01-10","objectID":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/:1:3","tags":["工作流","效率"],"title":"工作流总结","uri":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/"},{"categories":["思考总结"],"content":"创作输出 其实这部分已经在回顾总结的阶段做好了，由于Obsidian的本地化以及各种强大的插件，可以让我很简单地将Obsidian中的笔记应用到博客的发布上。举个例子，我会将Obsidian中的内容按照类别分类，然后放入不同的路径中，再通过超链接关联到博客发布时要读取的路径。接下来在编辑时，借助Templater这些插件，保证Obsidian中的样式与博客需求的一致即可。 而说到博客，我使用github进行版本管理，使用hugo将Markdown文件编译成静态的网页内容，主题则是选用LoveIt（这是我对比各种主题风格之后唯一较为喜爱的），然后使用github pages的功能，将生成的静态网页文件上传到远端之后，对应地就可以通过 xxx.github.io来访问到我的博客内容，为了使其更具备个人属性，我还为它买了一个专属的域名。 OK，综上，这就是我日常的工作流过程～ ","date":"2022-01-10","objectID":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/:1:4","tags":["工作流","效率"],"title":"工作流总结","uri":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/"},{"categories":["论文阅读"],"content":"AFDetV2是地平线在2021waymo挑战赛上夺冠方案。本文主要创新点有三：self-calibrated block, keypoint auxiliary loss, the IoU prediction branch ","date":"2021-12-23","objectID":"/05-afdetv2/:0:0","tags":["论文阅读"],"title":"论文阅读05 AFDetV2","uri":"/05-afdetv2/"},{"categories":["论文阅读"],"content":"简介 论文：《Rethinking the Necessity of the Second Stage for Object Detection from Point Clouds》 作者：Yihan Hu*, Zhuangzhuang Ding*, Runzhou Ge* Wenxin Shao, Li Huang† , Kun Li, Qiang Liu† 机构：Horizon Robotics 论文水平：CVPR Waymo Challenge 2021 关键词：self-calibrated block \u0026\u0026 keypoint \u0026\u0026 IoU prediction 论文链接：paper ","date":"2021-12-23","objectID":"/05-afdetv2/:1:0","tags":["论文阅读"],"title":"论文阅读05 AFDetV2","uri":"/05-afdetv2/"},{"categories":["论文阅读"],"content":"摘要 本工作概括地对现有的点云目标检测方法做了总结.首先讨论单阶段和两阶段这两种主流方向.进而提出通过对比实验发现,单阶段也能达到和两阶段类似的性能,并且两阶段的第二个阶段的主要作用是对分数的再优化.根本作用是解决了分类和回归的misalignment. 综上,本工作基于之前的AFDet,提出了AFDetv2版本,主要引入了 IoU prediction branch来实现二阶段的作用,并且使用self-calibrated block以达到通道注意力以及扩大感受野的目的.此外,还在训练阶段使用了关键点的loss辅助约束模型.总体实现了通过一阶段达到了两阶段的精度,并且保持了一阶段的实时性,被称为“Most Efficient Model”(55.86 ms) ","date":"2021-12-23","objectID":"/05-afdetv2/:2:0","tags":["论文阅读"],"title":"论文阅读05 AFDetV2","uri":"/05-afdetv2/"},{"categories":["论文阅读"],"content":"引言讨论 为什么需要两阶段来完成检测的任务? 主流观点有两个 基于点的检测器均表示使用原始点云的信息可以弥补体素化等操作带来的精度损失或者感受野缺失.所以两阶段的检测器依靠两阶段实现了较高的精度 另外一点从分类和回归的misalignment出发.由于分类和回归一般都是两个单独的分支,所以分类最高的预测并不一定与回归最准确的预测相匹配. 针对观点1,目前很多方法,都是基于体素化的方式,转换成BEV来做的,他们都实现了与原始点云方案的同等精度.比如centerpoint 针对观点2,本工作做了对比试验,在一阶段检测器后面单独加上分类或者单独加上回归,以探究第二阶段究竟是哪里在起作用.结果表明分类的部分对一阶段的分类结果做了二次优化,并引起了显著的精度提升.而回归网络则是无显著作用. ","date":"2021-12-23","objectID":"/05-afdetv2/:3:0","tags":["论文阅读"],"title":"论文阅读05 AFDetV2","uri":"/05-afdetv2/"},{"categories":["论文阅读"],"content":"网络结构 网络结构主要分为三部分,分别是voxel以及点云特征提取,BEV backbone以及heads ","date":"2021-12-23","objectID":"/05-afdetv2/:4:0","tags":["论文阅读"],"title":"论文阅读05 AFDetV2","uri":"/05-afdetv2/"},{"categories":["论文阅读"],"content":"Voxelization 同HorizonLidar3D.先进行体素化,取每个体素所有点的均值作为体素信息.然后使用稀疏卷积对体素化的点云提取特征. ","date":"2021-12-23","objectID":"/05-afdetv2/:4:1","tags":["论文阅读"],"title":"论文阅读05 AFDetV2","uri":"/05-afdetv2/"},{"categories":["论文阅读"],"content":"BEV Backbone 对于上述转换好的bev feature map,使用二维的backbone进一步学习特征.这里作者提出了self cali backbone.主要工作就是引入了**SCNet**以增强一阶段检测器对特征的学习能力.网络结构如下.SCNet可以一定程度上增加网络的感受野以及实现通道级别的注意力机制. ","date":"2021-12-23","objectID":"/05-afdetv2/:4:2","tags":["论文阅读"],"title":"论文阅读05 AFDetV2","uri":"/05-afdetv2/"},{"categories":["论文阅读"],"content":"Heads 相比于AFDet中的五个head,本工作为了实现一阶段检测器对类别的优化,额外引入了一个head进行IOU的预测,实现IoU-aware confidence score prediction.然后将IOU的score与heatmap的score进行相乘,以抑制那些与回归不匹配的分数. 此外,还在训练阶段引入了一个辅助的head,用来计算keypoint,包括中心点以及周围四个点.这部分在测试阶段会被禁止掉.只是起到训练时辅助约束模型的作用. 综上,共七个head,最终对所有head的输出做解码.得到三维的box ","date":"2021-12-23","objectID":"/05-afdetv2/:4:3","tags":["论文阅读"],"title":"论文阅读05 AFDetV2","uri":"/05-afdetv2/"},{"categories":["论文阅读"],"content":"实验结果 ","date":"2021-12-23","objectID":"/05-afdetv2/:5:0","tags":["论文阅读"],"title":"论文阅读05 AFDetV2","uri":"/05-afdetv2/"},{"categories":["论文阅读"],"content":"单帧,不加ensemble waymo val set ","date":"2021-12-23","objectID":"/05-afdetv2/:5:1","tags":["论文阅读"],"title":"论文阅读05 AFDetV2","uri":"/05-afdetv2/"},{"categories":["论文阅读"],"content":"waymo test set 经过ensemble以及多帧之后,可以达到84,,差不多是3DAL的精度.tql ","date":"2021-12-23","objectID":"/05-afdetv2/:5:2","tags":["论文阅读"],"title":"论文阅读05 AFDetV2","uri":"/05-afdetv2/"},{"categories":["论文阅读"],"content":"三个模块的消融实验 其他实验略,详见paper ","date":"2021-12-23","objectID":"/05-afdetv2/:5:3","tags":["论文阅读"],"title":"论文阅读05 AFDetV2","uri":"/05-afdetv2/"},{"categories":["论文阅读"],"content":"本文是CVPR2020Waymo挑战赛的冠军方案，相比于AFDet，在数据增广、网络深度以及模型Ensemble等方面都做了改进。 ","date":"2021-12-16","objectID":"/04-horizonlidar3d/:0:0","tags":["论文阅读"],"title":"论文阅读04 HorizonLiDAR3D","uri":"/04-horizonlidar3d/"},{"categories":["论文阅读"],"content":"简介 论文：《1 st Place Solution for Waymo Open Dataset Challenge - 3D Detection and Domain Adaptation》 作者：Zhuangzhuang Ding∗ Yihan Hu∗ Runzhou Ge∗ Li Huang Sijia Chen Yu Wang Jie Liao 机构：Horizon Robotics 论文水平：CVPR Waymo Challenge 2020 关键词：data aug \u0026\u0026 multi frame \u0026\u0026 ensemble 论文链接：paper ","date":"2021-12-16","objectID":"/04-horizonlidar3d/:1:0","tags":["论文阅读"],"title":"论文阅读04 HorizonLiDAR3D","uri":"/04-horizonlidar3d/"},{"categories":["论文阅读"],"content":"摘要 本工作主要是基于AFDet,继续优化这种anchor free以及NMS free的网络,以挑战waymo数据集上的检测任务.相比于AFDet,本工作主要的修改方向包括: ","date":"2021-12-16","objectID":"/04-horizonlidar3d/:2:0","tags":["论文阅读"],"title":"论文阅读04 HorizonLiDAR3D","uri":"/04-horizonlidar3d/"},{"categories":["论文阅读"],"content":"data aug 在AFDet的基础上进行了test time data aug,主要包括point cloud rotation around pitch, roll and yaw axis, point cloud global scaling and point cloud translation along z-axis 在每帧中加入了6个车辆、8个行人和10个自行车 ","date":"2021-12-16","objectID":"/04-horizonlidar3d/:2:1","tags":["论文阅读"],"title":"论文阅读04 HorizonLiDAR3D","uri":"/04-horizonlidar3d/"},{"categories":["论文阅读"],"content":"network stronger 网络结构如下 在AFDet的基础上,使用了稀疏卷积,并且使用体素化替换了pillar,应该是为了保留z的特征细粒度. grid size 0.04m, 0.04m, 0.1m along x, y, z axis respectively 在上图的框架下,本工作在backbone后面加入了RPN网络,进而通过调整不同的backbone以及不同的rpn结构,形成了三种不同的网络版本,结构如下 剩下的部分,head与loss应该与AFDet保持一致 ","date":"2021-12-16","objectID":"/04-horizonlidar3d/:2:2","tags":["论文阅读"],"title":"论文阅读04 HorizonLiDAR3D","uri":"/04-horizonlidar3d/"},{"categories":["论文阅读"],"content":"first and second returns fusion in waymo waymo的数据集,激光雷达点云是双回波的,所以在这个版本中,为了加强点云密度,新增加了对第二次回波点云的使用.以及将5个lidar的点云都使用上了 ","date":"2021-12-16","objectID":"/04-horizonlidar3d/:2:3","tags":["论文阅读"],"title":"论文阅读04 HorizonLiDAR3D","uri":"/04-horizonlidar3d/"},{"categories":["论文阅读"],"content":"multi frame accumulation [-4, 0] 融合了多帧的信息,操作大概应该是位姿变换对齐,然后把每一帧的点云打上相对的时间戳.本工作是融合了前面四帧的点云. ","date":"2021-12-16","objectID":"/04-horizonlidar3d/:2:4","tags":["论文阅读"],"title":"论文阅读04 HorizonLiDAR3D","uri":"/04-horizonlidar3d/"},{"categories":["论文阅读"],"content":"utilizing image data: point painting 这里借助了pointpainting的思想,将图像的信息融合进来. 对图像信息的使用包括两阶段,首先是使用box,第二阶段是使用语义分割的信息. 如果只有box,对点云特征增加一个维度,具体计算方式为: 将lidar的点投影到图像,如果点在box中,那么将box的预测得分赋给这个点,如果不在box中,得分为0 如果可以有seg的信息,那么将seg的语义特征加到点云后面 训练阶段,使用图像的真值,保存成点云.测试阶段,使用Cascade-RCNN对图像进行检测. ","date":"2021-12-16","objectID":"/04-horizonlidar3d/:2:5","tags":["论文阅读"],"title":"论文阅读04 HorizonLiDAR3D","uri":"/04-horizonlidar3d/"},{"categories":["论文阅读"],"content":"model ensemble 涨点利器 ","date":"2021-12-16","objectID":"/04-horizonlidar3d/:2:6","tags":["论文阅读"],"title":"论文阅读04 HorizonLiDAR3D","uri":"/04-horizonlidar3d/"},{"categories":["论文阅读"],"content":"总结 整体网络结构分为三部分,首先是体素化并且提取点云特征,转换到BEV视角,第二步是使用二维的backbone(也就是RPN)提取高维度特征,最终接五个head,作为三维box信息的预测以及编码. 本工作在AFDet的基础上,网络结构主要改进了backbone,替换掉原有的轻量化backbone,所谓的RPN,个人理解就是Encoder-Decoder的结构.并且在Decoder部分融合了多个分辨率的feature map. 此外的主要工作就是采用painting的方式融合了图像的信息,并且使用了ensemble涨点.这些操作都很值得借鉴 ","date":"2021-12-16","objectID":"/04-horizonlidar3d/:3:0","tags":["论文阅读"],"title":"论文阅读04 HorizonLiDAR3D","uri":"/04-horizonlidar3d/"},{"categories":["论文阅读"],"content":"本文是CVPR2020Waymo挑战赛的冠军方案的baseline，由地平线提出，整体结构与CenterPoint类似，是一种轻量化的baseline，其针对嵌入式平台做了优化，抛弃了传统的基于anchor的方法，将二维centernet以及cornernet的思想应用到三维，第一个提出三维anchor free以及nms free的方法。 后续地平线基于这个网络改进,提出了HorizonLiDAR3D 拿到了2020 3D Detection and Domain Adaptation的第一名 ","date":"2021-12-13","objectID":"/03-afdet/:0:0","tags":["论文阅读"],"title":"论文阅读03 AFDet","uri":"/03-afdet/"},{"categories":["论文阅读"],"content":"简介 论文：《AFDet: Anchor Free One Stage 3D Object Detection》 作者：Runzhou Ge∗ Zhuangzhuang Ding∗ Yihan Hu∗ Yu Wang Sijia Chen Li Huang Yuan Li 机构：Horizon Robotics 论文水平：Arxiv 关键词：Anchor Free \u0026\u0026 One Stage 论文链接：paper ","date":"2021-12-13","objectID":"/03-afdet/:1:0","tags":["论文阅读"],"title":"论文阅读03 AFDet","uri":"/03-afdet/"},{"categories":["论文阅读"],"content":"摘要 之前的三维点云检测工作,大多基于anchor的方案,anchor的缺陷主要体现在两方面: 为了提高recall.需要产生大量的anchor,对应地就需要使用NMS等后处理操作,大大拖延了算法运行速度 anchor的尺寸属于hyper parameter,需要手动调参 因此,本工作是第一个提出anchor free以及NMS free的一阶段检测器,称为AFDet.其对嵌入式系统较为友好. ","date":"2021-12-13","objectID":"/03-afdet/:2:0","tags":["论文阅读"],"title":"论文阅读03 AFDet","uri":"/03-afdet/"},{"categories":["论文阅读"],"content":"方法 总体框架分为三部分,pillar编码/backbone/head ","date":"2021-12-13","objectID":"/03-afdet/:3:0","tags":["论文阅读"],"title":"论文阅读03 AFDet","uri":"/03-afdet/"},{"categories":["论文阅读"],"content":"pillar编码 使用了pointpillar的编码方式,对于一帧点云,提前定义好P个pillar,每个pillar中允许M个点,多则采样,少则补0.每个点编码9个维度的特征,具体参考pointpillar的paper. 第二步,对于每个pillar中的点进行MLP学习,也可以理解为使用pointnet学习其特征,然后将点的特征传递给对应的pillar. 最后就是形成BEV视图.对应WxHxF,F就是特征的维度 ","date":"2021-12-13","objectID":"/03-afdet/:3:1","tags":["论文阅读"],"title":"论文阅读03 AFDet","uri":"/03-afdet/"},{"categories":["论文阅读"],"content":"BACKBONE 为了保证轻量化,本工作对backbone进行了裁剪,只进行一次下采样和上采样,最终输出的特征图保证了与原图同样的尺度.但是特征层数变多了. ","date":"2021-12-13","objectID":"/03-afdet/:3:2","tags":["论文阅读"],"title":"论文阅读03 AFDet","uri":"/03-afdet/"},{"categories":["论文阅读"],"content":"Heads head是本工作较为重要的部分,但是并不是多么新颖的工作,思想基本来自centernet. heatmap cls head 这部分是在BEV图上对bbox的中心点进行分类.输入是WxHxF 的特征.输出是WxHxK 的heatmap,K表示类别的数量.意味着每一类都有一个heatmap,其中每个像素都预测K个类别的概率.值越大,代表是对应类别的中心点的可能性越高. 由于anchor free的方法,不能像anchor based的方法那样通过大量的覆盖来提高召回率,所以要求对中心点的预测要尽可能准,因此本工作对centernet进行了改进: 原有的centernet给定中心位置的label就只有一个中心点是1,其他位置都是0,,这样会对分类任务及其不友好,因为正样本的比例太低了.所以后续工作的改进分为两种: 高斯核 如上图(b)以bbox的中心为中心,向四周扩散一个方形的区域,对应的label值递减 本工作的方案, 如上图(a) 对box中所有的像素都进行label编码, 主要分为三种情况 其中d是当前像素相对bbox中心点的l2 norm,这种方式保证了box中所有像素都能有正样本的label覆盖.本文的消融实验也证明了这种方式会更好一些. heatmap offset reg head 本工作第二个重点就是这个offset的回归,其作用是抵消转换BEV时的量化误差以及抑制上面heatmap分类网络对中心预测不准的情况. 输入是WxHxF 的特征.输出是WxHx2 其中2代表两个方向x和y的offset.注意这个offset是在3D空间上的,并不是在二维BEV像素坐标上的. offset实际上就是弥补将bev上的真实bbox中心,进行坐标转换后,存在的从float形式变为int形式的精度损失,下图公式也表明了,预测的大O表示实际二维平面xy上的offset 这里需要注意的是,作者为了抑制误差较大的offset,还对真实的bbox中心周围进行了编码,将其位置加入到loss计算中.上述公式的目的就是,如果预测的offset恰巧等于实际的offset,那么radius在两个方向都应该是接近于0,否则,越远离真实的bbox中心,radius带来的loss 越大,起到了正则化的作用. z reg head 直接进行l1 loss的预测,找到heatmap预测的最大值的坐标对应的z预测值,作为当前box在三维空间中的中心店的高度z size reg head 直接回归长宽高,,使用l1 loss Orientation predict head 角度采用分bin的方式,将一周360度分为两部分,一部分是-7pi/6 - pi/6,另外一部分是-pi/6 - 7pi/6.两部分存在一定的重叠.对于yaw角的回归,需要8个标量,每个bin4个,其中两个预测softmax类别,另外两个预测相对于bin中心的角度,真实角度与bin中心角度的sin和cos的值. ","date":"2021-12-13","objectID":"/03-afdet/:3:3","tags":["论文阅读"],"title":"论文阅读03 AFDet","uri":"/03-afdet/"},{"categories":["论文阅读"],"content":"decode 上面5个head的信息可以帮助我们解码出三维bbox.对应有7个维度的信息,(x,y,z,w,h,l,yaw) 其中,x与y由heatmap cls head输出的预测与heatmap offset reg head输出的offset组成,具体计算方式为 此外,其他信息均直接使用head预测的结果即可 ","date":"2021-12-13","objectID":"/03-afdet/:3:4","tags":["论文阅读"],"title":"论文阅读03 AFDet","uri":"/03-afdet/"},{"categories":["论文阅读"],"content":"data aug 经典三板斧 database 把所有真值框收集起来,然后选场景,再把gtbox以及对应的点云放进场景中,并且保持一定的数量比例 随机rotate以及translate 随机flip along z ","date":"2021-12-13","objectID":"/03-afdet/:3:5","tags":["论文阅读"],"title":"论文阅读03 AFDet","uri":"/03-afdet/"},{"categories":["论文阅读"],"content":"实验结果 ","date":"2021-12-13","objectID":"/03-afdet/:4:0","tags":["论文阅读"],"title":"论文阅读03 AFDet","uri":"/03-afdet/"},{"categories":["论文阅读"],"content":"kitti pillar side length 0.16 m max number of points per pillar 100 max number of pillars P = 12000. ","date":"2021-12-13","objectID":"/03-afdet/:4:1","tags":["论文阅读"],"title":"论文阅读03 AFDet","uri":"/03-afdet/"},{"categories":["论文阅读"],"content":"waymo ","date":"2021-12-13","objectID":"/03-afdet/:4:2","tags":["论文阅读"],"title":"论文阅读03 AFDet","uri":"/03-afdet/"},{"categories":["编程算法"],"content":" 本文主要记录python中的一些零散琐碎的知识点，便于之后整理成系统性的学习笔记～ 在个人的角度来看，Python作为一门被深度学习、数据处理等领域大力推广的编程语言，其很多语法糖都是很有意思的，特此记录～ ","date":"2021-07-10","objectID":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/:0:0","tags":["python","Coding"],"title":"Python中的奇奇怪怪","uri":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/"},{"categories":["编程算法"],"content":"python中的奇奇怪怪 ","date":"2021-07-10","objectID":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/:1:0","tags":["python","Coding"],"title":"Python中的奇奇怪怪","uri":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/"},{"categories":["编程算法"],"content":"1. a+=b和a=a+b的区别 二者的区别与否，取决于a和b的对象类型，如果是不可变对象，这两种表达相同；如果是可变对象，两种表达不同，不同之处在于： a+=b 会调用 __iadd__方法，没有该方法时，再尝试调用__add__方法 a=a+b 会调用__add__方法 对于两种内置的方法接口，不同在于： __iadd__返回值是None，直接在原对象上进行更新，也就是说，原有的变量a和对象之间的引用并没有被打破 __add__会返回一个新的对象，原对象不做修改，但是这里会将变量a的引用破坏，将返回的新的对象与变量a建立引用 ","date":"2021-07-10","objectID":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/:1:1","tags":["python","Coding"],"title":"Python中的奇奇怪怪","uri":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/"},{"categories":["编程算法"],"content":"2. Python中的幂运算 Python 中常见有三种幂计算函数： * 和 pow() 的时间复杂度均为 O(\\log a)O(loga) ；而 math.pow() 始终调用 C 库的 pow() 函数，其执行浮点取幂，时间复杂度为 O(1)O(1) 。 ","date":"2021-07-10","objectID":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/:1:2","tags":["python","Coding"],"title":"Python中的奇奇怪怪","uri":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/"},{"categories":["编程算法"],"content":"3. Python中变量的作用域（变量的查找顺序） Python中的变量名可以指代变量、函数、类、对象等 python解释器查找变量的顺序，总结起来可以分为LEGB四种，分别是 Local -\u003e Enclosed -\u003e Global -\u003e Built-in Local 定义在函数内部的变量、定义在函数声明中的形式参数，视为局部变量。 Enclosed 定义在函数中，嵌套函数外，且被嵌套函数引用的变量，视为自由变量。 Global 定义在 .py 文件内的，且函数、类之外的变量，视为全局变量。 Built-in 定义在built in中的变量，视为内置变量。 定义变量的位置决定了变量的作用域; 为了在局部作用域中修改全局变量和自由变量，引入了 global 关键字和 nonlocal 关键字 global用于调用全局变量 nonlocal用于调用 闭包变量，也就是自由变量 此外，对于函数内部再定义一个函数，以形成闭包的情况，在内部函数中调用内部函数外的变量时，是否修改也是一个值得注意的问题 内部函数，不修改全局变量可以访问全局变量，不需要nonlocal或global 内部函数，修改同名全局变量，则python会认为它是一个局部变量 在内部函数修改同名全局变量之前调用变量名称（如print sum），则引发Unbound-LocalError，解决办法就是，加上nonlocal或者global关键字，具体用哪个视情况而定。 ","date":"2021-07-10","objectID":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/:1:3","tags":["python","Coding"],"title":"Python中的奇奇怪怪","uri":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/"},{"categories":["编程算法"],"content":"4. Python的加速运行 参考：https://zhuanlan.zhihu.com/p/143052860 ","date":"2021-07-10","objectID":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/:1:4","tags":["python","Coding"],"title":"Python中的奇奇怪怪","uri":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/"},{"categories":["编程算法"],"content":"5. Python中的闭包 需要明确的是，闭包是一个函数，可以理解为特殊的函数，并且闭包的说法并不是Python特有的，javascript等语言也涉及闭包的概念。 具体地，参考Wiki上对闭包的解释： 在计算机科学中，闭包（英语：Closure），又称词法闭包（Lexical Closure）或函数闭包（function closures），是引用了自由变量的函数。这个被引用的自由变量将和这个函数一同存在，即使已经离开了创造它的环境也不例外。所以，有另一种说法认为闭包是由函数和与其相关的引用环境组合而成的实体。闭包在运行时可以有多个实例，不同的引用环境和相同的函数组合可以产生不同的实例。 总的来看就是，闭包等同于函数引用了函数外定义地变量，并且该函数可以在其定义环境外被执行。这样地函数叫做闭包，类似地，C++中地static关键字定义的就是一个独立函数外地变量，二者有异曲同工之妙。 闭包的一些特性 闭包中的引用的自由变量只和具体的闭包有关联，闭包的每个实例引用的自由变量互不干扰。 一个闭包实例对其自由变量的修改会被传递到下一次该闭包实例的调用。 具体见：https://www.cnblogs.com/yssjun/p/9887239.html ","date":"2021-07-10","objectID":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/:1:5","tags":["python","Coding"],"title":"Python中的奇奇怪怪","uri":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/"},{"categories":["编程算法"],"content":"6. Python中的__new__与__init_ __new__(cls[, ...]) 是在一个对象实例化的时候所调用的第一个方法，在调用__init__初始化前，先调用__new__。 __new__至少要有一个参数cls，代表要实例化的类，此参数在实例化时由 Python 解释器自动提供，后面的参数直接传递给__init__。 __new__对当前类进行了实例化，并将实例返回，传给__init__的self。但是，执行了__new__，并不一定会进入__init__，只有__new__返回了，当前类cls的实例，当前类的__init__才会进入。 若__new__没有正确返回当前类cls的实例，那__init__是不会被调用的，即使是父类的实例也不行，将没有__init__被调用。 __new__方法主要是当你继承一些不可变的 class 时（比如int, str, tuple）， 提供给你一个自定义这些类的实例化过程的途径。 ","date":"2021-07-10","objectID":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/:1:6","tags":["python","Coding"],"title":"Python中的奇奇怪怪","uri":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/"},{"categories":["编程算法"],"content":"本文是学习排序系列的第五篇，主要对比三种基本排序算法以及三种进阶排序算法，对应的排序算法学习笔记可以翻阅本博客前面的内容。 ","date":"2021-05-27","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%8E%92%E5%BA%8F%E4%BB%A3%E7%A0%81/:0:0","tags":["Sorting","Algorithms"],"title":"算法学习之排序算法对比","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%8E%92%E5%BA%8F%E4%BB%A3%E7%A0%81/"},{"categories":["编程算法"],"content":"0. 常见排序算法性能对比 再贴一张常见排序算法的性能对比，方便查看~ ","date":"2021-05-27","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%8E%92%E5%BA%8F%E4%BB%A3%E7%A0%81/:1:0","tags":["Sorting","Algorithms"],"title":"算法学习之排序算法对比","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%8E%92%E5%BA%8F%E4%BB%A3%E7%A0%81/"},{"categories":["编程算法"],"content":"1. 代码 import numpy as np from time import process_time from typing import List import matplotlib.pyplot as plt import random class Sorting: def __init__(self, method: str): self.easy_samples = np.random.randint(0, 100000, 5000) self.medium_samples = np.random.randint(0, 100000, 50000) self.hard_samples = np.random.randint(0, 100000, 100000) self.start_time = process_time() self.method = getattr(self, method) def timeit(self): return float('%.4f' % (process_time() - self.start_time)) def sort(self): # print('---------------- Easy Test -------------------') easy_nums = self.method(self.easy_samples) t1 = self.timeit() # print('---------------- Medium Test -------------------') medium_nums = self.method(self.medium_samples) t2 = self.timeit() # print('---------------- Hard Test -------------------') hard_nums = self.method(self.hard_samples) t3 = self.timeit() assert self.checksort(easy_nums) assert self.checksort(medium_nums) assert self.checksort(hard_nums) return [t1, t2, t3], [self.easy_samples.shape, self.medium_samples.shape, self.hard_samples.shape] @staticmethod def checksort(nums): for i in range(len(nums) - 1): if nums[i] \u003e nums[i + 1]: return False return True @staticmethod def bubblesort(nums: List) -\u003e List: length = len(nums) for i in range(1, length): sort_over = True for j in range(length - i): if nums[j] \u003e nums[j + 1]: nums[j], nums[j + 1] = nums[j + 1], nums[j] sort_over = False if sort_over: return nums return nums @staticmethod def selectsort(nums: List) -\u003e List: length = len(nums) for i in range(length): min_id = i for j in range(i, length): min_id = j if nums[j] \u003c nums[min_id] else min_id if min_id != i: # 判断是否是当前元素最小，是的话就不用交换 nums[min_id], nums[i] = nums[i], nums[min_id] return nums @staticmethod def insertsort(nums: List) -\u003e List: length = len(nums) for i in range(length): cur_val = nums[i] last_id = i - 1 while last_id \u003e= 0 and nums[last_id] \u003e cur_val: nums[last_id + 1] = nums[last_id] last_id -= 1 nums[last_id + 1] = cur_val return nums @staticmethod def shellsort(nums: List) -\u003e List: length = len(nums) gap = length while gap \u003e 0: for i in range(gap, length): cur_val = nums[i] last_id = i - gap while last_id \u003e= 0 and nums[last_id] \u003e cur_val: nums[last_id + gap] = nums[last_id] last_id -= gap nums[last_id + gap] = cur_val gap //= 2 return nums @staticmethod def mergesort(nums: List) -\u003e List: def merge(arr_, left_, mid_, right_, tmp_): ptr1, ptr2, index = left_, mid_+1, 0 # 遍历ptr1和ptr2，装填res_数组，直到ptr1或ptr2到头 for i in range(right_-left_+1): if ptr1 \u003e mid_ or ptr2 \u003e right_: break if arr_[ptr1] \u003c= arr_[ptr2]: # 注意 '=' 才能让排序稳定 tmp_[index] = arr_[ptr1] ptr1, index = ptr1+1, index+1 else: tmp_[index] = arr_[ptr2] ptr2, index = ptr2+1, index+1 # 调用extend将剩余元素都装入数组res中 if ptr1 \u003e mid_: tmp_[index:right_-left_+1] = arr_[ptr2:right_+1] if ptr2 \u003e right_: tmp_[index:right_-left_+1] = arr_[ptr1:mid_+1] # 改变arr_区间中的元素顺序 arr_[left_:right_+1] = tmp_[:right_-left_+1] def mergesort_rec(arr, left, right, tmp): if left \u003e= right: return mid = (right + left) // 2 mergesort_rec(arr, left, mid, tmp) mergesort_rec(arr, mid+1, right, tmp) merge(arr, left, mid, right, tmp) length = len(nums) mergesort_rec(nums, 0, length-1, [0]*length) return nums @staticmethod def quicksort(nums: List) -\u003e List: def partition(left, right): i, pivot = left, nums[left] # 这里记录下左指针指向的值，后面比较时不需要重复索引，可以有效节省时间 while left \u003c right: while left \u003c right and nums[right] \u003e= pivot: right -= 1 while left \u003c right and nums[left] \u003c= pivot: left += 1 nums[left], nums[right] = nums[right], nums[left] nums[i], nums[left] = nums[left], pivot return left def sort(start, end): if start \u003e= end: return [] pivot = partition(start, end) sort(start, pivot-1) sort(pivot+1, end) sort(0, len(nums)-1) return nums def plot_and_show(sorting_algo, res, size): x = size # 点的横坐标 def randomcolor(): colorArr = ['1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F'] color = \"\" for i in range(6): color += colorArr[random.randint(0, 14)] return \"#\" + color for i, cur in enume","date":"2021-05-27","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%8E%92%E5%BA%8F%E4%BB%A3%E7%A0%81/:2:0","tags":["Sorting","Algorithms"],"title":"算法学习之排序算法对比","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%8E%92%E5%BA%8F%E4%BB%A3%E7%A0%81/"},{"categories":["编程算法"],"content":"2. 算法运行时间对比 横轴为数据量级，纵轴为运行时间 六种算法共同对比 希尔、归并、快排详细对比 ","date":"2021-05-27","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%8E%92%E5%BA%8F%E4%BB%A3%E7%A0%81/:3:0","tags":["Sorting","Algorithms"],"title":"算法学习之排序算法对比","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%8E%92%E5%BA%8F%E4%BB%A3%E7%A0%81/"},{"categories":["编程算法"],"content":"本文是学习排序系列的第四篇，主要介绍较为常用的排序算法：快速排序 前文学习了归并排序，该排序算法采用了分治(divide and conquer, D\u0026C)的思想，我们可以使用递归对输入序列进行排序。但是归并排序与输入序列的有序程度无关，并且需要额外创建线性的空间，这对于数据规模较大的场景不是很友好。 本文要学习的快速排序同样也是基于分治思想的排序算法，相比于归并，快排的空间复杂度为常数级别，在C中，sort方法的底层实现的原型就是qsort快速排序~ 注：本文的排序算法默认升序 ","date":"2021-05-25","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:0:0","tags":["Sorting","Algorithms"],"title":"算法学习之快速排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"0. 常见排序算法性能对比 再贴一张常见排序算法的性能对比，方便查看~ ","date":"2021-05-25","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:1:0","tags":["Sorting","Algorithms"],"title":"算法学习之快速排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"1. 快速排序 快排是使用分治思想的排序算法，其巧妙地使用哨兵节点(pivot)，递归地将待排序的序列分为大于pivot和小于pivot两部分，进而达到分而治之，化大为小的目的。快速排序就是个二叉树的前序遍历 ","date":"2021-05-25","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:2:0","tags":["Sorting","Algorithms"],"title":"算法学习之快速排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"排序的简化情况 因为快排使用了递归的方法，所以为了明确递归思路，我们先对排序任务进行简单的剖析。 如果待排序的序列长度小于2，那么可以直接返回 如果待排序的序列长度等于2，那么比较两个元素即可 如果待排序的序列长度大于2，可以递归到小于等于2的情况 以上就是递归的想法雏形，其实递归的终止条件就是将大问题简化，简化到极端的情况，进而使用简化来反推复杂情况。 ","date":"2021-05-25","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:2:1","tags":["Sorting","Algorithms"],"title":"算法学习之快速排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"如何递归且O(1)？ 前面说过，归并排序同样使用了分治与递归，但是空间复杂度为O(N)，所以快排应该如何将空间复杂度降低为常数级别的呢？ 快排的思路就是原地分组，通过定义一个哨兵节点来实现。具体操作是将所有元素与哨兵节点的值相比较，小于哨兵节点的放在左侧，大于哨兵节点的放在右侧，这样逐层递归，就完成了排序的过程。 如下图所示，展示的是两次递归完成排序的过程，每次都取第一个元素为哨兵节点： 从上图可以发现，其实快排的基本思想可以认为是一个二叉树的模型，从上面不断地将当前数组分为两部分，直到达到递归终止条件。所以快排与归并排序的不同点在计算方式上也有体现， 归并是直接分组，然后从子问题开始处理，最后归并，是自下而上的算法，先处理子问题，再归并 但是快排是分组时就进行比较，一直到子问题无法继续划分，这时数组就排序完成了，是自上而下的算法，快速排序通过哨兵节点以及原地分组的方式，解决了归并排序中的内存占用 ","date":"2021-05-25","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:2:2","tags":["Sorting","Algorithms"],"title":"算法学习之快速排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"快速排序初版 根据上述思路，我们可以总结一下算法步骤 确定递归终止条件，也称为 base case 这里的终止条件是排序数组为空，否则继续向下递归 确定哨兵节点 为了简单容易理解，这里先将哨兵节点设为输入数组的第一个元素 根据哨兵节点进行递归排序 此时我们可以宏观地将数组分为两部分，比pivot小的，比pivot大的，与pivot相等的。分组完毕后，我们就可以调用自身进一步地对比pivot小的以及pivot大的两组进行再一次的划分，直到达到终止条件。 python版本代码如下 def quicksort(nums: List) -\u003e List: def sort(nums): if nums == []: return [] pivot = nums[0] nums = nums[1:] left = sort([num for num in nums if num \u003c= pivot]) right = sort([num for num in nums if num \u003e pivot]) return left + [pivot] + right return sort(nums) ","date":"2021-05-25","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:2:3","tags":["Sorting","Algorithms"],"title":"算法学习之快速排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"复杂度分析 递归时间以及空间复杂度计算方式如下： 时间复杂度 = 递归调用栈深度 × 每次递归操作次数 空间复杂度 = 递归调用栈深度 × 每次递归开辟的空间 所以为了分析递归的复杂度，我们需要确定递归调用栈的深度。 那么仔细思考一下，其实上述代码中的递归调用栈的深度是不确定的，因为我们的哨兵节点与其余元素的大小关系未知，我们可以分两种情况讨论，设待排序序列长度为N 最好情况，每次的哨兵节点都恰巧是当前序列的中位数，那么我们每次都可以完美地将输入序列分成近乎均等的两部分，这时的递归调用栈的深度为log2(N)，每次递归操作次数为N，开辟空间为常数级别。 那么时间复杂度就是 O(Nlog2(N))，空间复杂度为O(log2(N)) 最坏情况，每次的哨兵节点都恰巧是当前序列中的极值，要么极大要么极小，这时我们的分治处理模型就从二叉树退化成了一维的结构，对应的递归调用栈深度为N，每次递归操作次数为N，开辟空间为常数级别。 那么对应的时间复杂度为O(N^2)，空间复杂度为O(N) 由此可见，上述快速排序可以称之为乞丐版，因为它不能很好地控制复杂度，所以我们可以进一步地改进，改进方案就是哨兵节点的选取。 ","date":"2021-05-25","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:2:4","tags":["Sorting","Algorithms"],"title":"算法学习之快速排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"优化方案：动态选取哨兵节点[双指针] 想要尽可能地分组均匀，哨兵节点的值应该尽可能地接近当前数组的中值 目的已经很明确了，就是要在当前数组中，遍历一遍，然后选取哨兵节点，我们可以使用双指针的方法来完成这个任务。 先假定基准值是数组中的第一个元素 定义两个指针left和right，分别指向第二个元素以及最后一个元素，规定left只能向右移动，right只能向左移动，且left不能超过right (这里再说明一下双指针的作用，左指针负责维护一个小于基准值的区间，右指针则负责维护一个大于基准值的区间) 右指针先向左移动，每移动一位，都和基准值比较，如果遇到比基准值小的元素，停止，反之继续移动。移动左指针，同样边移动边比较，直到遇到比基准值大的元素，停止，与右指针交换位置(为了保证各自维护区间的元素值符合预期要求) 重复3直到左右指针相遇，将相遇位置的元素与基准值交换位置 这里借用袁厨的动图来可视化整个过程，侵删哈 经过以上过程，基准值所在的位置就是我们想要的哨兵节点，这时哨兵节点左侧都是较小元素，右侧都是较大元素，当前区间分组完毕！继续进行下一次递归的分组即可 python代码如下： def quicksort(nums: List) -\u003e List: def partition(arr, left, right): base = left while left \u003c right: while left \u003c right and arr[right] \u003e= arr[base]: right -= 1 while left \u003c right and arr[left] \u003c= arr[base]: left += 1 nums[left], nums[right] = nums[right], nums[left] nums[base], nums[left] = nums[left], nums[base] return left def sort(nums, start, end): if start \u003e= end: return [] pivot = partition(nums, start, end) sort(nums, start, pivot-1) sort(nums, pivot+1, end) sort(nums, 0, len(nums) - 1) return nums ","date":"2021-05-25","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:2:5","tags":["Sorting","Algorithms"],"title":"算法学习之快速排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"优化后复杂度分析 如果不考虑极端情况的话，时间复杂度为O(NlogN)，空间复杂度为O(log2N) 但是不妨想一下，尽管我们使用双指针来优化了哨兵节点的选取，从而使每次哨兵节点的选择都尽可能靠近中间，但是如果输入的序列原本就是顺序或者倒序，那么退化的问题依旧会存在，所以极端情况下，时间复杂度依旧是O(N^2)，空间复杂度依旧是O(N) 为了解决上述问题，一般来讲都会将输入的序列进行打乱（shuffle），如果输入的序列规模很大，那么其实也可以尝试下随机选取一个哨兵节点，平均下来的时间复杂度是最优的。 ","date":"2021-05-25","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:2:6","tags":["Sorting","Algorithms"],"title":"算法学习之快速排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"稳定性分析 不稳定，因为分组时会发生随机的数据交换，从而导致值相同的元素相对位置变化 ","date":"2021-05-25","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:2:7","tags":["Sorting","Algorithms"],"title":"算法学习之快速排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"总结 快速排序一般比归并排序要快 快速排序是不稳定的，因为在分组时会发生随机的数据位置交换 上述优化过后的快排代码针对数组中大量重复数据的情况效果不是那么地好(比如从0-200范围内随机选取50000个数值，快排的速度可能比希尔排序还慢，更别说归并排序了)，如果重复数据较多，可以单独处理 最后，贴一张快排和归并排序耗时比较的图~ ","date":"2021-05-25","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:3:0","tags":["Sorting","Algorithms"],"title":"算法学习之快速排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"python中的列表解析式 ","date":"2021-05-13","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%88%97%E8%A1%A8%E8%A7%A3%E6%9E%90%E5%BC%8F/:0:0","tags":["python","Coding","列表解析式"],"title":"Python还债日记之列表解析式","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%88%97%E8%A1%A8%E8%A7%A3%E6%9E%90%E5%BC%8F/"},{"categories":["编程算法"],"content":"python中的列表解析式 ","date":"2021-05-13","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%88%97%E8%A1%A8%E8%A7%A3%E6%9E%90%E5%BC%8F/:1:0","tags":["python","Coding","列表解析式"],"title":"Python还债日记之列表解析式","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%88%97%E8%A1%A8%E8%A7%A3%E6%9E%90%E5%BC%8F/"},{"categories":["编程算法"],"content":"1. 列表解析式 python中的列表解析式可以帮助我们用简短的语言来创建一个列表，形如： [x*y for x in range(1,5) if x \u003e 2 for y in range(1,4) if y \u003c 3] 这里相当于两层循环，外加一些条件判断 for x in range(1,5) if x \u003e 2 for y in range(1,4) if y \u003c 3 x*y ","date":"2021-05-13","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%88%97%E8%A1%A8%E8%A7%A3%E6%9E%90%E5%BC%8F/:1:1","tags":["python","Coding","列表解析式"],"title":"Python还债日记之列表解析式","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%88%97%E8%A1%A8%E8%A7%A3%E6%9E%90%E5%BC%8F/"},{"categories":["编程算法"],"content":"2. 问题描述 但是今天偶尔在刷题时，想要用列表解析式创建一个列表，这里给定了第一个元素的值，然后之后每个元素都是前面元素数值的二倍，我们想要借用列表解析式的话，可能会这么写 [a[i-1]*2 for i in range(len(a))] 但是！！！问题就出在这里，出现的结果并不是想象的[1, 2, 4, 8, …] \u003e\u003e\u003e a = [1] * 5 \u003e\u003e\u003e a[1:] = [a[i-1]*2 for i in range(len(a))] \u003e\u003e\u003e print(a) [1, 2, 2, 2, 2, 2] 可见，列表解析式针对这种情况，应该是新建了一个对象，存储 a[i-1]的值，也就是说，这里的a[i-1]并不是我们想象的是可变的，而是一个定值！！！ 所以之后要注意，此类写法应该使用普通for循环来填充a ","date":"2021-05-13","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%88%97%E8%A1%A8%E8%A7%A3%E6%9E%90%E5%BC%8F/:1:2","tags":["python","Coding","列表解析式"],"title":"Python还债日记之列表解析式","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%88%97%E8%A1%A8%E8%A7%A3%E6%9E%90%E5%BC%8F/"},{"categories":["编程算法"],"content":" 本文是学习排序系列的第三篇，主要介绍归并排序 注：本文的排序算法默认升序 ","date":"2021-05-08","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/:0:0","tags":["Sorting","Algorithms"],"title":"算法学习之归并排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"0. 常见排序算法性能对比 再贴一张常见排序算法的性能对比，方便查看~ ","date":"2021-05-08","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/:1:0","tags":["Sorting","Algorithms"],"title":"算法学习之归并排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"1. 归并排序 ","date":"2021-05-08","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/:2:0","tags":["Sorting","Algorithms"],"title":"算法学习之归并排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"定义与可视化 归并排序的算法思想是分治，即先将待排序的序列划分成若干子序列，对子序列排序，然后再合并子序列的排序结果。归并排序就是个二叉树的后序遍历 再放一张K神的图，比较清晰，来源 算法步骤 给定一个待排序的序列，归并排序将主要分为两步，拆分、合并： 将序列递归地分成两份，直到子序列的长度为2，拆分停止。如果序列总长度为奇数N，则一份是(N+1)/2，一份是(N-1)/2 对子序列进行合并，每个子序列的合并规则如下 定义两个指针，循环对比指针指向元素的大小，取较小的放入原数组，注意更新指针位置。循环停止条件是有一个指针走到了子序列的末尾，这时剩余元素一定是较大值，直接插入原数组后面即可。 代码 每次递归都将序列一份为二，直到当前序列长度小于或等于2，对两个元素进行比较交换，那么对于长度大于2的子序列，每次都会创建与原序列相同长度的空间，以作为临时的排序结果。python代码如下 def mergesort(nums: List) -\u003e List: def merge(arr_, left_, mid_, right_): ptr1, ptr2, res_ = left_, mid_+1, [] # 遍历ptr1和ptr2，装填res_数组，直到ptr1或ptr2到头 for i in range(right_-left_+1): if ptr1 \u003e mid_ or ptr2 \u003e right_: break if arr_[ptr1] \u003c= arr_[ptr2]: # 注意 '=' 才能让排序稳定 res_.append(arr_[ptr1]) ptr1 += 1 else: res_.append(arr_[ptr2]) ptr2 += 1 # 调用extend将剩余元素都装入数组res_中 if ptr1 \u003e mid_: res_.extend(arr_[ptr2:right_+1]) if ptr2 \u003e right_: res_.extend(arr_[ptr1:mid_+1]) # 替换arr_区间中对应的区域 arr_[left_:right_+1] = res_ def mergesort_rec(arr, left, right): if left \u003e= right: return mid = (right + left) // 2 mergesort_rec(arr, left, mid) mergesort_rec(arr, mid+1, right) merge(arr, left, mid, right) length = len(nums) mergesort_rec(nums, 0, length-1) return nums 空间优化： 我们可以对空间进行优化，实际上一共迭代了log2(N)次， 每次空间占用最大就是N，所以可以创建一个长度与原序列相同的数组，这样就只需维护这一个数组即可，避免频繁开辟空间。当前序列长度小于N时，可以只使用一部分。 def mergesort(nums: List) -\u003e List: def merge(arr_, left_, mid_, right_, tmp_): ptr1, ptr2, index = left_, mid_+1, 0 # 遍历ptr1和ptr2，装填tmp数组，直到ptr1或ptr2到头 for i in range(right_-left_+1): if ptr1 \u003e mid_ or ptr2 \u003e right_: break if arr_[ptr1] \u003c= arr_[ptr2]: # 注意 '=' 才能让排序稳定 tmp_[index] = arr_[ptr1] ptr1, index = ptr1+1, index+1 else: tmp_[index] = arr_[ptr2] ptr2, index = ptr2+1, index+1 # 调用extend将剩余元素都装入数组tmp中 if ptr1 \u003e mid_: tmp_[index:right_-left_+1] = arr_[ptr2:right_+1] if ptr2 \u003e right_: tmp_[index:right_-left_+1] = arr_[ptr1:mid_+1] # 改变arr_区间中的元素顺序 arr_[left_:right_+1] = tmp_[:right_-left_+1] def mergesort_rec(arr, left, right, tmp): if left \u003e= right: return mid = (right + left) // 2 mergesort_rec(arr, left, mid, tmp) mergesort_rec(arr, mid+1, right, tmp) merge(arr, left, mid, right, tmp) length = len(nums) mergesort_rec(nums, 0, length-1, [0]*length) return nums 归并排序特点 归并排序的时间复杂度与空间复杂度和原序列是否有序无关 复杂度分析 设定序列长度为N 时间复杂度 因为需要不断地拆分数组，递归的次数为log2(N)，每次都需要遍历N个元素进行比较和交换，所以总的时间复杂度为𝑂(Nlog2(N)) 空间复杂度 因为使用了额外空间，且极端情况下，大小为N，且递归调用栈的空间复杂度为O(log2(N))，所以总的空间复杂度取较大值，为O(N) 稳定性分析 归并排序是稳定的，因为在比较时，对于相等的元素，优先采用索引较小的，所以保持了相对位置不变 可视化网站 Merge Sort visualize | Algorithms | HackerEarth ","date":"2021-05-08","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/:2:1","tags":["Sorting","Algorithms"],"title":"算法学习之归并排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":" 本文是学习排序系列的第二篇，主要介绍插入排序的进阶版-\u003e希尔排序 注：本文的排序算法默认升序 ","date":"2021-04-28","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/:0:0","tags":["Sorting","Algorithms"],"title":"算法学习之希尔排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"0. 常见排序算法性能对比 再贴一张常见排序算法的性能对比，方便查看~ ","date":"2021-04-28","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/:1:0","tags":["Sorting","Algorithms"],"title":"算法学习之希尔排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"1. 希尔排序(插入)(In-place) ","date":"2021-04-28","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/:2:0","tags":["Sorting","Algorithms"],"title":"算法学习之希尔排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"定义与可视化 希尔排序也叫递减增量排序，其在直接插入排序的基础上，巧妙使用增量的概念，让插入排序的作用对象逐层有序，而递减增量指的是增量的数值依次减小最终为1 ","date":"2021-04-28","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/:2:1","tags":["Sorting","Algorithms"],"title":"算法学习之希尔排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"定义(人话版) OK，说人话，上一篇总结了插入排序的原理和特点，我们知道插入排序在输入序列基本有序的情况下是蛮快的，时间复杂度可以达到O(N)级别，只不过插入排序针对基本逆序的输入处理依旧不够简洁。那么希尔排序，则是插入排序的升级版，通过预处理+插入排序的方案，最优情况下可以达到O(N)的时间复杂度。输入不够有序？先处理成相对有序，再进行插入排序操作就好~ 那么具体如何实现呢？希尔排序中用到了一个名词，叫做增量，记做gap，这个增量的作用是将原输入序列分批，与其直接处理原输入，先处理第1个元素与第gap+1个元素，将二者作为一组进行插入排序，原数组不够有序？其实减小输入规模，也相当于间接地减小无序程度。此外，希尔排序的定义中为什么说递减增量呢？其实换个角度理解，增量越大，每批处理的元素越多，那么增量递减相当于逐渐增加插入排序每次处理的数据规模，而且当前的数据又是在上一个增量时已经提前预处理过了，所以插入排序处理起来会更简单。 ","date":"2021-04-28","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/:2:2","tags":["Sorting","Algorithms"],"title":"算法学习之希尔排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"增量设定\u0026如何递减 最简单的增量方案(折半) 我们先以折半的方案为例，熟悉希尔排序的具体操作过程，便于写代码实现 首先，给定一些定义，我们设定增量为gap，输入序列长度为N，gap初始值为N//2 根据gap的值进行分批插入排序 遍历的起止索引是gap -\u003e (len(N)-1) 当前索引如果是cur，那么当前批的索引是 …, cur-3gap, cur-2gap, cur-gap, cur 将当前批索引对应的元素进行插入排序 将索引cur右移一位，重复上一过程 更新gap的值为 gap = gap//2 gap为0时，遍历结束 在上述过程中，折半增量的作用就是每次都将插入排序的对象数量扩大一倍，而且扩大前后的两批数据并不是相互独立的，而是扩大前的数据已经是有序的。一直到最后，gap为1时，插入排序拿到的数据已经是近乎有序的了，这就是预处理的作用。 极端情况 折半增量虽然简单容易理解，但是存在一种极端的情况，那就是当gap的值等于1之前，可能每批数据都是有序的，这时gap=1，插入排序拿到的序列顺序与原始顺序一致，相当于gap等于1之前的操作都是额外的，这样反而比直接插入排序还要耗时 如上图，gap初始为4，然后为2，你会发现这两种情况对应的数据都已经是有序的。 造成这种情况的原因就是：增量方案不够严谨。事实上，希尔排序的时间复杂度的确取决于增量递减的方案，那么，为了保证分组粗调没有盲区，每一轮的增量需要彼此“互质”，也就是没有除1之外的公约数，这样才能保证希尔排序不会好心办坏事。 所以，为了使增量互质，人们又提出了Hibbard增量：2^k-1[1, 3, 7, 15, …]，后续还有很多其他方案被提出，不过这不是我们关注的重点了。 比较 相比于直接插入排序 希尔排序是不稳定的，数据交换过程中可能丢失稳定性 希尔排序的比较次数和移动次数比直接插入排序要少，N越大效果越明显 希尔排序中增量gap的取法必须满足最后一个步长为1 代码 以折半增量为例 def shellsort(nums: List) -\u003e List: length = len(nums) gap = length while gap \u003e 0: for i in range(gap, length): cur_val = nums[i] last_id = i - gap while last_id \u003e= 0 and nums[last_id] \u003e cur_val: nums[last_id + gap] = nums[last_id] last_id -= gap nums[last_id + gap] = cur_val gap //= 2 return nums 复杂度分析 设定序列长度为N 时间复杂度 最坏时间复杂度为𝑂(𝑁^(3/2))，平均时间复杂度约为𝑂(𝑁^(5/4)) 空间复杂度 因为是原地操作，所以空间复杂度为O(1) 稳定性分析 希尔排序是不稳定的，因为其在插入元素的过程中可能会交换相等元素的顺序。 可视化网站 SORTING ","date":"2021-04-28","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/:2:3","tags":["Sorting","Algorithms"],"title":"算法学习之希尔排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":" 本文是学习排序系列的第一篇，主要介绍一些基本概念，对常见排序算法进行总结，以及介绍三种初级排序算法：冒泡、选择、插入 注：本文的排序算法默认升序 ","date":"2021-04-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/:0:0","tags":["Sorting","Algorithms"],"title":"算法学习之基础排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"0. 写在前面 ","date":"2021-04-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/:1:0","tags":["Sorting","Algorithms"],"title":"算法学习之基础排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"关于排序 排序算法是算法中较为基础的知识，给定一个无需序列，如何使其有序？这个问题目前拥有很多种解决方案，并且不同的方法也会涉及到不同的算法知识，比如常见的比较与非比较策略、迭代与递归的实现、分治策略、对算法的时间复杂度分析等 ","date":"2021-04-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/:1:1","tags":["Sorting","Algorithms"],"title":"算法学习之基础排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"大O表示法 ","date":"2021-04-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/:1:2","tags":["Sorting","Algorithms"],"title":"算法学习之基础排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"排序算法的稳定性 衡量一个排序算法的性能，我们不仅可以使用上述的大O表示法来表示算法的时间和空间复杂度，还可以判断其是否稳定。 如果Ai= Aj，排序前Ai在Aj之前，排序后Ai还在Aj之前，则称这种排序算法是稳定的。通俗地讲就是保证排序前后两个相等的数的相对顺序不变 对于不稳定的排序算法，只要举出一个实例，即可说明它的不稳定性；而对于稳定的排序算法，必须对算法进行分析从而得到稳定的特性。 排序算法是否为稳定的是由具体算法决定的，不稳定的算法在某种条件下可以变为稳定的算法，而稳定的算法在某种条件下也可以变为不稳定的算法。例如，对于冒泡排序，原本是稳定的排序算法，如果将记录交换的条件改成A[i] \u003e= A[i + 1]，则两个相等的记录就会交换位置，从而变成不稳定的排序算法。 排序算法稳定性的好处。排序算法如果是稳定的，那么从一个键上排序，然后再从另一个键上排序，前一个键排序的结果可以为后一个键排序所用。基数排序就是这样，先按低位排序，逐次按高位排序，低位排序后元素的顺序在高位也相同时是不会改变的 ","date":"2021-04-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/:1:3","tags":["Sorting","Algorithms"],"title":"算法学习之基础排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"1. 常见排序算法概览 ","date":"2021-04-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/:2:0","tags":["Sorting","Algorithms"],"title":"算法学习之基础排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"1.1 按照排序方式分类 一种是比较排序，时间复杂度O(nlogn) ~ O(n^2) 基于比较的排序算法，都免不了两种操作：比较与交换，所以在排序的过程中，我们可以通过计算比较操作与交换操作的次数来进一步衡量算法的有效性 交换：冒泡排序、快速排序 插入：简单插入排序、希尔排序 选择：简单选择排序、堆排序 归并：二路归并排序、多路归并排序 另一种是非比较排序，时间复杂度可以达到O(n) 计数排序 桶排序 基数排序 ","date":"2021-04-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/:2:1","tags":["Sorting","Algorithms"],"title":"算法学习之基础排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"1.2 各排序算法对比 ","date":"2021-04-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/:2:2","tags":["Sorting","Algorithms"],"title":"算法学习之基础排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"2. 常见排序算法学习 ","date":"2021-04-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/:3:0","tags":["Sorting","Algorithms"],"title":"算法学习之基础排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"2.1 初级排序算法 先来看三种基于比较的排序算法，这三种算法较容易实现，但却不是最有效的，因为时间复杂度是平方级别。 冒泡排序(交换)(In-place) 冒泡排序是较为初级的排序算法，思想简单，易实现，但其算法复杂度不友好，一般仅做为入门学习。算法核心思想就是通过不断的比较以及交换，使极值元素向一端移动，类似冒泡的过程 给定一个N个元素的数组，冒泡排序将： 比较一对相邻元素（a，b） 如果元素大小关系不正确，交换这两个数（在本例中为a\u003e b）， 重复步骤1和2，直到我们到达数组的末尾（最后一对是第（N-2）和（N-1）项，因为我们的数组从零开始） 到目前为止，最大的元素将在最后的位置。 然后我们将N减少1，并重复步骤1，直到N = 1。 问题分析及优化 原始冒泡排序较为耗时，且其比较次数与序列无序程度无关，即使输入完全有序的序列，比较次数还是N * (N-1) / 2 次 针对上述问题，可以维护一个标志位，如果当前这一层的迭代过程中，没有发生元素位置的交换，那么说明前面所有元素都已经是有序的，就可以结束排序了 代码 def bubblesort(nums: List) -\u003e List: length = len(nums) for i in range(1, length): sort_over = True for j in range(length-i): if nums[j] \u003e nums[j+1]: nums[j], nums[j+1] = nums[j+1], nums[j] sort_over = False if sort_over: return nums return nums 讨论 虽然优化后，冒泡排序在一般情况下运行得更快，但这种改进的想法并没有改变冒泡排序的 O(n^2) 时间复杂性…为什么？ 优化的情况只是针对有序的条件，当序列完全逆序时，冒泡排序的比较次数和交换次数仍然非常多，不够有效 复杂度分析 针对优化后的冒泡排序，设定序列长度为N 时间复杂度 最好情况下，序列完全有序，仅需比较 N-1 次，即可完成排序，无需交换，故时间复杂度为O(N) 最坏情况下，序列完全逆序，需要比较(N-1) + (N-2) + ... + 1 + 0 = N*(N-1)/2，同理，需要交换N*(N-1)/2次，故时间复杂度为O(N^2) 空间复杂度 因为是原地操作，所以空间复杂度为O(1) 是否稳定 冒泡排序是稳定的，因为其不改变相对顺序 选择排序(选择)(In-place) 选择排序也是基于比较的排序，其核心思想是比较(选择)、交换。相比与冒泡排序，选择排序大大减少了交换操作的次数，虽然时间复杂度与冒泡排序相同，但却更加高效 给定一个N个元素的数组，选择排序将从前向后遍历，假设当前元素为L，那么选择排序的方法是维护两部分内容，第一部分是L左侧的序列，该序列是升序有序的，第二部分是L以及L右侧的数据，可以理解为未排序的元素。所谓选择，就是每次都遍历从L到最后一个元素，选择最小的元素，并使其与L的位置交换。宏观上来看就是从L右边找到一个最小的，放到左边，然后不断右移L直到整个序列完全有序。具体可以分为三步 在 [L … N-1]范围内找出最小项目X的位置 用第 L 项交换X 将下限 L 增加1并重复步骤1直到 L = N-2 看到这里，不难发现，相比于冒泡排序，选择排序的比较次数与冒泡排序一致，都是O(n^2)级别，但是实际交换的次数却只有O(n)次，这也是为什么选择排序会比冒泡排序快的原因。 代码 def selectsort(nums: List) -\u003e List: length = len(nums) for i in range(length): min_id = i for j in range(i, length): min_id = j if nums[j] \u003c nums[min_id] else min_id if min_id != i: # 判断是否是当前元素最小，是的话就不用交换 nums[min_id], nums[i] = nums[i], nums[min_id] return nums 复杂度分析 设定序列长度为N 时间复杂度 最好情况下，序列完全有序，需比较 (N-1) + (N-2) + ... + 1 + 0 = N*(N-1)/2 次，即可完成排序，无需交换，故时间复杂度为O(N^2) 最坏情况下，序列完全逆序，需要比较(N-1) + (N-2) + ... + 1 + 0 = N*(N-1)/2，同理，需要交换N-1次(无重复元素)，故时间复杂度为O(N^2) 空间复杂度 因为是原地操作，所以空间复杂度为O(1) 是否稳定 选择排序是不稳定的，因为其在交换元素时可能改变相对顺序 插入排序(插入)(In-place) 插入排序类似‘打扑克’中我们抓牌码牌的过程，并且插入的思想使其平均操作次数小于选择排序，依据比较(交换)、插入的流程，插入排序的速度是三种基础排序算法中最快的 给定一个N个元素的数组，插入排序将从前向后遍历，假设当前元素为L，那么插入排序的方法是维护两部分内容，第一部分是L左侧的序列，该序列是升序有序的，第二部分是L以及L右侧的数据，可以理解为未排序的元素。所谓插入，就是在左侧有序序列中找到当前元素L的位置，使插入L后的序列依旧有序，然后依次右移L。可以总结为两步： 将L依次与L左侧第n个元素比较(n=1,2,…)，我们称被比较的元素叫Ln，如果L大于Ln，交换二者位置，并继续向前比较，直到L小于或等于Ln，设定当前Ln的位置后一位为L，这时插入完毕 更新L，重复1，直到遍历结束 代码 def insertsort(nums: List) -\u003e List: length = len(nums) for i in range(length): cur_val = nums[i] last_id = i - 1 while last_id \u003e= 0 and nums[last_id] \u003e cur_val: nums[last_id + 1] = nums[last_id] last_id -= 1 nums[last_id + 1] = cur_val return nums 复杂度分析 设定序列长度为N 时间复杂度 最好情况下，序列完全有序，外循环需N-1次，内循环主需要比较1次就会发现不需要交换，即可完成排序，故时间复杂度为O(N) 最坏情况下，序列完全逆序，外循环需N-1次，内循环需要比较和交换O(n)级别的次数，故时间复杂度为O(N^2) 空间复杂度 因为是原地操作，所以空间复杂度为O(1) 分析 上述过程说明了，插入排序在输入基本有序的情况下，时间复杂度可以达到O(N)级别，这已经很快了，但是当序列基本逆序的情况下，插入排序较为耗时的步骤在于，不断地比较与交换的操作，我们假设当前元素为L，L前面有K个元素已经处于有序状态，那么序列完全逆序时，L需要与这K个元素逐一比较并交换，对应的时间复杂度就是O(2K)，约等于O(K)级别，这依旧是较为耗时的，改进的方案有两种： 二分 将插入步骤中的比较过程，改为二分法，二分查找的方案比线性查找的时间复杂度低，毕竟是O(logK)与O(K)级别的对比，规模越大越明显，通过二分查找得到当前元素L应该插入的位置后，再将这个位置后面的元素统一后移一位，将L插入即可 预处理 这个思想仅需记住一点，插入排序对基本有序的输入，时间是很快的。 那么所谓的预处理，我们可以通过某种方式使输入先变得相对有序一些，再进行插入排序，这样就会大大降低处理的耗时啦，这个思想其实就对应着插入排序的升级版本—希尔排序，下篇文章会详细介绍～ 是否稳定 插入排序是稳定的，因为其在比较插入的过程中，遇到相等的元素并不进行交换 可视化网页 https://visualgo.net/zh/sorting ","date":"2021-04-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/:3:1","tags":["Sorting","Algorithms"],"title":"算法学习之基础排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"总结 衡量排序算法好坏的标准有两个：复杂度以及稳定性 冒泡排序通过不断比较、交换来使序列中的极值元素向序列的一端移动，形如冒泡 选择排序则是通过选择操作取代了冒泡排序中冗余的交换次数，但却牺牲了稳定性 插入排序在小数量级且序列基本有序时，表现的最快，原因是其在基本有序情况下，时间复杂度最小可以是O(N)级别，且操作次数少于冒泡排序。 注意，复杂度分析是针对数量级进行的，同等数量级下，插入排序的操作次数就比冒泡排序少很多 最后，贴出个人测试的三种排序方式的时间对比，可见插入排序还是厉害的呀 ","date":"2021-04-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/:4:0","tags":["Sorting","Algorithms"],"title":"算法学习之基础排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/"},{"categories":["论文阅读"],"content":"本文是MIT HAN Lab的工作，通过结合点云的两种表述方式，来设计一种Point + Voxel的融合框架。 ","date":"2021-04-16","objectID":"/02-pvcnn/:0:0","tags":["论文阅读"],"title":"论文阅读02 PVCNN","uri":"/02-pvcnn/"},{"categories":["论文阅读"],"content":"简介 论文：《PVCNN: Point-Voxel CNN for Efficient 3D Deep Learning》 作者：Zhijian Liu，Haotian Tang，Yujun Lin，Song Han 机构：MIT \u0026\u0026 SJTU 论文水平：NIPS19 spotlight 关键词：PointCloud DeepLearning \u0026\u0026 Point-Voxel 论文链接：paper | code ","date":"2021-04-16","objectID":"/02-pvcnn/:1:0","tags":["论文阅读"],"title":"论文阅读02 PVCNN","uri":"/02-pvcnn/"},{"categories":["论文阅读"],"content":"1. 速览 针对问题： 基于体素的点云深度学习方法，虽然体素化相对于最远点采样更快，但是如果想要获得高分辨率的体素化结果，其内存占用和计算耗时会 cubically 增长 基于点的点云深度学习方法，虽然内存占用很少，但受点云稀疏性的影响，大概有 80% 的时间都消耗在点云计算的准备工作中，所以直接处理点云可能比较耗时 解决方案： 提出了 Point-Voxel 的方式来实现高效又轻量化的点云深度学习 以点的形式存储数据，减少内存占用 以体素化形式进行卷积，避免处理点云的不规则、稀疏性带来的数据访问耗时，提高局部感知能力 效果量化： 相同精度下，相比于体素化方法节省10倍GPU内存开销 相比于基于点的方法平均速度提升了7倍 narrower version PVCNN在分割的 benchmarks中达到了2倍于PointNet的速度，且精度更高 F-PVCNN相对于F-PointNet++，有2.4%的mAP提升以及1.5倍的加速以及GPU内存节省 ","date":"2021-04-16","objectID":"/02-pvcnn/:2:0","tags":["论文阅读"],"title":"论文阅读02 PVCNN","uri":"/02-pvcnn/"},{"categories":["论文阅读"],"content":"2. 简介 来自于激光雷达等传感器的3D数据，通常以点云的形式表述，目前对于3D点云的研究，大概分为两个方向，基于体素或是基于点云 Voxel-Based： 体素化方法是通过划分网格，将点云均匀的分成若干网格，这样就可以将不规则的点云表述转变成规则的体素网格，进而应用3D CNN等深度学习方法。但是划分体素化的算法，其时间复杂度一般是和体素网格的尺寸成正比的，较大的体素网格带来的体素化结果也就意味着低分辨率，等价于信息的丢失，想要解决，就需要提高体素化的分辨率，而这时，对应的内存占用是随着尺寸的增加呈立方级别的增长的。这里作者举了例子，3D-UNet的网络输入 batch-size为16，体素化大小为64 x 64 x 64，需要至少10GB的显存占用，这样的内存资源消耗让我们很难提升体素化结果的分辨率 Point-Based： 基于点的方法是直接对输入的点进行处理，由于点云具有稀疏的特性，所以相比于体素化，基于点的方法占用的GPU内存资源更少。但是同样因为点云的稀疏性，输入点云的顺序是紧密排列的，但是并不代表其在三维空间上是紧密的，这样使得算法的执行时间有 80% 以上都用在了对无序点云的内存访问上，真实的算法处理时间不到 20%。 这里所谓的 Random Memory Access其实之的是点云搜索的过程，索引无序又不规则的点云需要很高昂的时间代价，而这是体素化方法不需要承受的。目前大多基于点的方法都是通过聚合每个点的相邻特征来提高感受野，拿PointNet++来举例，PointNet++中需要对点云做若干次的FPS最远点采样，这个过程相比于体素化，是更为耗时的，所以基于点的方法从运行时间来看，也可以进行优化 Point-Voxel： 将以上两种方法相融合，设计一种新方法，其具有基于点的方法的低内存占用，也拥有基于体素的方法的低时间复杂度，对规则体素进行卷积，省略了点级别的内存访问以及动态卷积核，这种方法被作者称为 PVConv，融合CNN之后就是PVCNN ","date":"2021-04-16","objectID":"/02-pvcnn/:3:0","tags":["论文阅读"],"title":"论文阅读02 PVCNN","uri":"/02-pvcnn/"},{"categories":["论文阅读"],"content":"3. Motivation 对于三维数据，可以表示成下面的形式，三维坐标加上对应的特征 基于体素和基于点的卷积都可以概括成下侧的公式，首先对于当前点 xk，索引其周围的点 xi，然后通过核滤波 K 与其周围点的特征进行卷积，得到对应的 yk ","date":"2021-04-16","objectID":"/02-pvcnn/:4:0","tags":["论文阅读"],"title":"论文阅读02 PVCNN","uri":"/02-pvcnn/"},{"categories":["论文阅读"],"content":"3.1 Voxel-Based Models：Large Memory Footprint 前文提过，体素化方法如果想要做到不丢失信息，就需要达到特别高的分辨率。当分辨率较低时，意味着有很多点会同时存在于同一个体素网格中，也就是说经过体素化后丢失的信息就越多。 上图可以看到，当显存为11G时，对应的体素化的分辨率会导致42%的信息丢失，如果想要保留90%以上的信息，需要对应GPU的显存为 83GB，实际工程应用中很难在处理平台上部署这种内存爆炸的方法。 ","date":"2021-04-16","objectID":"/02-pvcnn/:4:1","tags":["论文阅读"],"title":"论文阅读02 PVCNN","uri":"/02-pvcnn/"},{"categories":["论文阅读"],"content":"3.2 Point-Based Models: Irregular Memory Access and Dynamic Kernel Overhead 基于点的方法中，作者列举了两类，一类是PointNet，因为PointNet是针对每个点做特征提取的，并没有关注点与点之间的局部特征，而PointNet中使用的就是MLP，通过多次的MLP学习其不变性，并且通过最大池化，处理点云的无序性。PointNet的内存访问是极其高效的，因为不涉及到对无序点的索引遍历。第二类就是对PointNet的改良，在PointNet之后，为了改善PointNet的局部感知能力，在PointNet之前先用特征聚合的方法将局部信息聚合到一起，再通过PointNet提取特征，这些方法之一就是我们所熟悉的PointNet++ 但是与此同时，采样算法以及特征聚合过程就涉及到了对无序点云的索引，作者称为 Irregular Memory Access，在这一环节通常引入 dynamic kernel computation，而这就是限制Point-Based方法效率的瓶颈所在。 对 Irregular Memory Access 的解释 基于点的方法不像体素化方法，体素化得到的是规则的体素网格，对于周围信息的聚合操作，只需要索引周围体素网格的 id 即可，但是基于点的方法是对无序点云的直接处理，而点云在三维空间中是不规则分布的，我们并不能通过索引点的 id 的方式找到某一个点的若干邻近点，所以只能通过类似KNN的算法，用高昂的访问时间来换取邻近点的搜寻。 如上图所示，作者对比了三个较为先进的Point-Based方法，指出其在不规则点云索引上消耗的时间占比分别为36%，52%，57%（PointCNN，DGCNN,SpiderCNN） 对 Dynamic Kernel Computation 的解释 上述步骤后，已经得到了邻近区域的点，接下来就是对这个区域进行卷积，Point-Based的卷积与规则的Voxel-Based卷积方式不同，仍然是由于点云的分布不规则，邻居点的位置并不是固定不变的，所以就需要一个动态计算每个邻近区域的核，上图也可以看到，PointCNN的核计算开销是最大的，甚至超过了50%！ 总之，不规则内存访问和动态内核计算的总开销在55％（对于DGCNN）到88％（对于PointCNN）之间，这表明大多数计算都浪费在处理基于点的表示的不规则性上! ","date":"2021-04-16","objectID":"/02-pvcnn/:4:2","tags":["论文阅读"],"title":"论文阅读02 PVCNN","uri":"/02-pvcnn/"},{"categories":["论文阅读"],"content":"4. PVConv PVConv由低分辨率的基于体素的分支和高分辨率的基于点的分支组成。 基于体素的分支提取粗粒度的邻域信息，并从基于点的分支中对单个点的特征进行细粒度的补充。 上部的基于体素的分支首先将点转换为低分辨率的体素网格，然后通过基于体素的卷积将相邻点聚合在一起，然后将其转换回点。 体素化或反体素化都仅需要对所有点进行一次索引，从而降低了内存成本。 基于点的分支则对每个单独的点提取特征。 由于它不聚合邻居点的信息，因此能够提供非常高的处理速度并且保持高分辨率。 ","date":"2021-04-16","objectID":"/02-pvcnn/:5:0","tags":["论文阅读"],"title":"论文阅读02 PVCNN","uri":"/02-pvcnn/"},{"categories":["论文阅读"],"content":"4.1 Voxel-Based Feature Aggregation 前面已经分析了，Point-Based方法在特征聚合时由于点云的不规则分布，特征聚合的耗时明显高于Voxel-Based方法，所以特征聚合是转换为体素进行的。 尺度归一化 这一步是为了处理不同尺寸的输入点云，注意只是对坐标归一化，特征并没有！ 归一化过程如下： 平移所有点到以中心为原点的局部坐标系中 所有点除以坐标二范数的最大值，坐标就缩放到了 [-1, 1] 之间 将 [-1, 1] 的坐标线性映射到 [0, 1]（平移和缩放） 点云体素化 得到范围在 [0, 1] 的体素坐标后，对坐标以及体素分辨率 r 进行计算，得到每个点对应的体素编号，这里对于体素中多个点的特征处理，是仿照PointNet做了平均池化，以平均特征作为当前体素的特征 体素卷积、信息聚合 使用3D体素卷积做特征聚合 反体素化 因为需要将体素化的结果与Point-Based结果做融合，所以需要将体素网格做去体素化处理，这里作者提到一种最近邻插值的方法，但是这种方法是将体素网格与点做映射，反推点的坐标之后，同一个体素网格中的点对应的特征都是一样的。所以作者用了三线性插值上采样，保证每个点都有属于自己的独特的特征。 ","date":"2021-04-16","objectID":"/02-pvcnn/:5:1","tags":["论文阅读"],"title":"论文阅读02 PVCNN","uri":"/02-pvcnn/"},{"categories":["论文阅读"],"content":"4.2 Point-Based Feature Transformation 到这里已经完成了网络图中上面分支的学习，而实际上在体素分支将点周围的信息进行特征聚合，得到的只是低分辨率的特征，因为体素的方法注定很难得到较高的分辨率，所以作者就将Point-Based的方法融合到Voxel-Based方法输出的聚合特征中，这样可以增加最终结果的细粒度特征。 具体的操作就是借鉴PointNet的思想，针对每个点提取特征，而仅需使用MLP就可以较好的完成这一工作，并且能够保证较少的算法耗时 ","date":"2021-04-16","objectID":"/02-pvcnn/:5:2","tags":["论文阅读"],"title":"论文阅读02 PVCNN","uri":"/02-pvcnn/"},{"categories":["论文阅读"],"content":"4.3 Feature Fusion 将两个分支的结果直接相加，就得到了最终结果 ","date":"2021-04-16","objectID":"/02-pvcnn/:5:3","tags":["论文阅读"],"title":"论文阅读02 PVCNN","uri":"/02-pvcnn/"},{"categories":["论文阅读"],"content":"4.4 Discussions 关于如何高效运行的细节部分： 相比于Point-Based的方法，Point-Based提升了 K 倍的速度 对于PointNet++，在N个点中取其聚合特征，需要找到每一个点周围的 K 个点，对应的时间复杂度是 Kn，而这里的 K 一般为 36/64。在PointCNN中， K 一般为16。 而Point-Voxel由于在体素中进行聚合，只需要遍历N个点对应哪一个体素即可，故作者提到时间复杂度为 n 关于保持点云高分辨率的细节部分： 作者将PVConv与PointNet++中的SA Module做了对比，输入是[16, 2048, 64] 时，采样临近点数量为125，SA Module需要75.2ms，3.6G显存占用，而PVConv需要25.7ms，1.0G显存占用。但是这里没说SA下采样的数量，作者只是给出，如果SA Module也想达到25.7ms，那么必须下采样到685个点，而这无疑会损失信息。并且这时PVConv的内存占用仍然低于SA Module。 ","date":"2021-04-16","objectID":"/02-pvcnn/:5:4","tags":["论文阅读"],"title":"论文阅读02 PVCNN","uri":"/02-pvcnn/"},{"categories":["论文阅读"],"content":"5. Experiments 作者将PVCNN在很多任务上做了测试， 包括3D分割、3D检测等，效果均不错 值得一提的是，PVCNN可以部署在 Jetson Nano上并且达到实时的效果，并且其速度与精度都明显高于PointCNN和PointNet ","date":"2021-04-16","objectID":"/02-pvcnn/:6:0","tags":["论文阅读"],"title":"论文阅读02 PVCNN","uri":"/02-pvcnn/"},{"categories":["编程算法"],"content":"总结 比较项目 数组 链表 大小定义 声明时给定好，增删会重新定义数组大小 无需指定，在执行过程中自行增长和收缩 元素位置 编译时分配 运行时分配 元素顺序 连续空间 随机空间 增 时间复杂度O(n)， 空间复杂度O(n) 时间复杂度O(1)， 空间复杂度O(1) 删 时间复杂度O(n)， 空间复杂度O(n) 时间复杂度O(1)， 空间复杂度O(1) 查 时间复杂度O(1)， 空间复杂度O(1) 时间复杂度O(n)， 空间复杂度O(1) 注： 数组的增删操作，平均时间复杂度最好情况是在最后一个元素，最坏情况是在第一个元素，平均为O(n/2)，所以等同于O(n)，空间复杂度类似 链表的增删操作，不考虑遍历到需要更改的元素位置所需要的时间复杂度的，所以时间复杂度可以认为是O(1) 因为数组在内存空间是连续的，所以内存利用率，数组要低于链表 注重数据的随机访问效率的话，不考虑数据的增删操作，选择数组 经常增加删除数据，又不是太在意数据访问时间，选择链表 下面内容转自Difference Between Array and Linked List (with Comparison Chart) - Tech Differences 侵删 The major difference between Array and Linked list regards to their structure. Arrays are index based data structure where each element associated with an index. On the other hand, Linked list relies on references where each node consists of the data and the references to the previous and next element. Basically, an array is a set of similar data objects stored in sequential memory locations under a common heading or a variable name. While a linked list is a data structure which contains a sequence of the elements where each element is linked to its next element. There are two fields in an element of linked list. One is Data field, and other is link field, Data field contains the actual value to be stored and processed. Furthermore, the link field holds the address of the next data item in the linked list. The address used to access a particular node is known as a pointer. Another significant difference between an array and linked list is that Array has a fixed size and required to be declared prior, but Linked List is not restricted to size and expand and contract during execution. ","date":"2021-03-17","objectID":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/:1:0","tags":["DataStructure","Coding"],"title":"总结数组与链表的区别[转载]","uri":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["编程算法"],"content":"Comparison Chart ","date":"2021-03-17","objectID":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/:2:0","tags":["DataStructure","Coding"],"title":"总结数组与链表的区别[转载]","uri":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["编程算法"],"content":"Definition of Array An array is defined as a set of a definite number of homogeneous elements or data items. It means an array can contain one type of data only, either all integers, all floating-point numbers, or all characters. Declaration of an array is as follows: int a [10]; Where int specifies the data type or type elements array stores. “a” is the name of an array, and the number specified inside the square brackets is the number of elements an array can store, this is also called size or length of the array. ","date":"2021-03-17","objectID":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/:2:1","tags":["DataStructure","Coding"],"title":"总结数组与链表的区别[转载]","uri":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["编程算法"],"content":"Points to Ponder Let us look at some of the concepts to be remembered about arrays: The individual elements of an array can be accessed by describing the name of the array, followed by index or subscript (determining the location of the element in the array) inside the square brackets. For example, to retrieve 5th element of the array, we need to write a statement a[4]. In any case the elements of an array will be stored in a consecutive memory location. The very first element of the array has index zero [0]. It means the first and last element will be specified as a[0], and a[9] respectively. The number of elements that can be stored in an array, i.e., the size of an array or its length is given by the following equation: (upper bound-lower bound) + 1 For the above array, it would be (9-0) + 1 =10. Where 0 is the lower bound of the array, and 9 is the upper bound of the array. Arrays can be read or written through the loop. If we read the one-dimensional array, it requires one loop for reading and other for writing (printing) the array, for example: a. For reading an array for ( i= 0; i \u003c= 9; i++) { scanf ( “%d”, \u0026a[ i ] ) ; } b. For writing an array for (i = 0 ; i \u003c= 9 ; i++) {printf ( “%d”, a[ i ] ) ; } In the case of a 2-D array, it would require two loops and similarly n-dimensional array would need n loops. ","date":"2021-03-17","objectID":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/:2:2","tags":["DataStructure","Coding"],"title":"总结数组与链表的区别[转载]","uri":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["编程算法"],"content":"Operations performed on arrays Creation of array Traversing an array Insertion of new elements Deletion of required elements. Modification of an element. Merging of arrays ","date":"2021-03-17","objectID":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/:2:3","tags":["DataStructure","Coding"],"title":"总结数组与链表的区别[转载]","uri":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["编程算法"],"content":"Example The following program illustrates the reading and writing of the array. #include\u003cstdio.h\u003e#include\u003cconio.h\u003e void main () { int a[10],i; printf(\"Enter the array\"); for ( i= 0; i \u003c= 9; i++) { scanf ( \"%d\", \u0026a[ i ] ) ; } printf( \"Enter the array\" ); for (i = 0 ; i \u003c= 9 ; i++) { printf ( \"%d\\n\", a[ i ] ) ; } getch (); } ","date":"2021-03-17","objectID":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/:2:4","tags":["DataStructure","Coding"],"title":"总结数组与链表的区别[转载]","uri":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["编程算法"],"content":"Definition of Linked List Linked list is a particular list of some data elements linked to one other. In this every element point to the next element which represents the logical ordering. Each element is called a node, which has two parts. INFO part which stores the information and POINTER which points to the next element. As you know for storing address, we have a unique data structures in C called pointers. Hence the second field of the list must be a pointer type. Types of linked lists are Singly-linked list, Doubly linked list, Circular linked list, Circular double linked list. ","date":"2021-03-17","objectID":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/:2:5","tags":["DataStructure","Coding"],"title":"总结数组与链表的区别[转载]","uri":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["编程算法"],"content":"Operations performed on Linked List Creation Traversing Insertion Deletion Searching Concatenation Display ","date":"2021-03-17","objectID":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/:2:6","tags":["DataStructure","Coding"],"title":"总结数组与链表的区别[转载]","uri":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["编程算法"],"content":"Example The following snippet illustrates the creation of a linked list: struct node { int num; stuct node *next; } start = NULL; void create() { typedef struct node NODE; NODE *p, *q; char choice; first = NULL; do { p = (NODE *) malloc (sizeof (NODE)); printf (\"Enter the data item\\n\"); scanf (\"%d\", \u0026 p -\u003e num); if (p == NULL) { q = start; while (q -\u003e next ! = NULL) { q = q -\u003e next } p -\u003e next = q -\u003e next; q -\u003e = p; } else { p -\u003e next = start; start = p; } printf (\"Do you want to continue (type y or n) ? \\n\"); scanf (\"%c\", \u0026choice) ; } while ((choice == \u0026#39;y\u0026#39;) || (choice == \u0026#39;Y\u0026#39;)); } ","date":"2021-03-17","objectID":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/:2:7","tags":["DataStructure","Coding"],"title":"总结数组与链表的区别[转载]","uri":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["编程算法"],"content":"Key Differences Between Array and Linked List An array is the data structure contains a collection of similar type data elements whereas the Linked list is considered as non-primitive data structure contains a collection of unordered linked elements known as nodes. In the array the elements belong to indexes, i.e., if you want to get into the fourth element you have to write the variable name with its index or location within the square bracket. In a linked list though, you have to start from the head and work your way through until you get to the fourth element. While accessing an element array is fast while Linked list takes linear time so, it is quite bit slower. Operations like insertion and deletion in arrays consume a lot of time. On the other hand, the performance of these operations in Linked lists is fast. Arrays are of fixed size. In contrast, Linked lists are dynamic and flexible and can expand and contract its size. In an array, memory is assigned during compile time while in a Linked list it is allocated during execution or runtime. Elements are stored consecutively in arrays whereas it is stored randomly in Linked lists. The requirement of memory is less due to actual data being stored within the index in the array. As against, there is a need for more memory in Linked Lists due to storage of additional next and previous referencing elements. In addition memory utilization is inefficient in the array. Conversely, memory utilization is efficient in the array. ","date":"2021-03-17","objectID":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/:3:0","tags":["DataStructure","Coding"],"title":"总结数组与链表的区别[转载]","uri":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["编程算法"],"content":"Conclusion Array and Linked lists are the types of data structures differ in their structure, accessing and manipulation methods, memory requirement and utilization. And have particular advantage and disadvantage over its implementation. Consequently, either one can be used as per need. ","date":"2021-03-17","objectID":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/:3:1","tags":["DataStructure","Coding"],"title":"总结数组与链表的区别[转载]","uri":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["论文阅读"],"content":"本文是shaoshuai的3D点云检测工作，发表在TPAMI，融合了点在box中的位置分布规律, 通过这个位置约束确定更精准的box。 ","date":"2021-03-16","objectID":"/01-part-a2/:0:0","tags":["论文阅读"],"title":"论文阅读01 Part-A2","uri":"/01-part-a2/"},{"categories":["论文阅读"],"content":"简介 论文：《From Points to Parts: 3D Object Detection from Point Cloud with Part-aware and Part-aggregation Network》 作者：Shaoshuai Shi, Zhe Wang, Jianping Shi, Xiaogang Wang, Hongsheng Li 机构：The Chinese University of Hong Kong, Hong Kong, China. 论文水平：TPAMI 2021 关键词：intra-object part location 论文链接：paper | code 视频链接：presentation ","date":"2021-03-16","objectID":"/01-part-a2/:1:0","tags":["论文阅读"],"title":"论文阅读01 Part-A2","uri":"/01-part-a2/"},{"categories":["论文阅读"],"content":"摘要 LiDAR 点云的 3D 对象检测是 3D 场景理解中的一个具有挑战性的问题，具有许多实际应用。在本文中，我们将我们的初步工作 PointRCNN 扩展到一个新颖且强大的基于点云的 3D 对象检测框架，即部分感知和聚合神经网络（Part-A2 网络）。整个框架由部分感知阶段和部分聚合阶段组成。首先，部分感知阶段首次充分利用从 3D 真实框派生的免费部分监督，同时预测高质量的 3D 提议和准确的对象内部位置得分。同一提案中预测的对象内部分位置由我们新设计的 RoI 感知点云池模块分组，从而有效地表示对每个 3D 提案的几何特定特征进行编码。然后，部分聚合阶段通过探索池化的对象内部分位置的空间关系来学习对框进行重新评分并细化框位置。进行了广泛的实验以证明我们提出的框架的每个组件的性能改进。我们的 Part-A2 网络优于所有现有的 3D 检测方法，并通过仅利用 LiDAR 点云数据在 KITTI 3D 对象检测数据集上实现了新的最新技术。 ","date":"2021-03-16","objectID":"/01-part-a2/:2:0","tags":["论文阅读"],"title":"论文阅读01 Part-A2","uri":"/01-part-a2/"},{"categories":["论文阅读"],"content":"什么是intra-object part location 通过判断每个 object 内各个点的坐标与 box的位置关系, 得到每个点在物体中的相对位置关系, 提供了一个位置上的约束 作者说,前景点也就是在框中的点,分布都是有规律的, 而背景点一般都是杂乱的, 所以可以通过这种点和box之间的关系来增强判别能力 ","date":"2021-03-16","objectID":"/01-part-a2/:3:0","tags":["论文阅读"],"title":"论文阅读01 Part-A2","uri":"/01-part-a2/"},{"categories":["论文阅读"],"content":"如何表述 intra-object part location? 将当前的物体中的点云进行坐标变换, 如图, 一个顶点是 (0, 0, 0), 对角顶点是 (1, 1, 1) 三个轴的坐标都映射到 [0, 1] 之间, 这样物体中每个点的分布一定都是 在[0, 1] 之间的, 就可以用来计算每个点分布的 label ","date":"2021-03-16","objectID":"/01-part-a2/:4:0","tags":["论文阅读"],"title":"论文阅读01 Part-A2","uri":"/01-part-a2/"},{"categories":["论文阅读"],"content":"如何用 intra-object part location? ","date":"2021-03-16","objectID":"/01-part-a2/:5:0","tags":["论文阅读"],"title":"论文阅读01 Part-A2","uri":"/01-part-a2/"},{"categories":["论文阅读"],"content":"1. Part-aware stage 第一部分主要是将前景点分割出来, 并且预测前景点的 intra-object part location 还会初步预测 proposal Sparse Convolution 针对输入点云, 先体素化, 进行稀疏卷积 可以看到, 体素化之后的网格与原始点云, 包含的信息几乎一致 稀疏卷积相比于PointNet++, 会更快, 优化的更好 Semantic segmentation + Intra-object part location 分割得到前景点 预测前景点的 intra-object part location 信息 Genarate 3D proposals to group the intra-object part locations for each 3D ROI 两种生成proposal的策略: Anchor-free 利用分割分数作为 proposal 的大概分数 较为简单, 对于小物体较为友好, 不需要下采样 Anchor-Based 将稀疏卷积编码之后的特征转换为 BEV 视角, 进而在俯视图上生成Anchor 更高的 recall 更高的 performance ","date":"2021-03-16","objectID":"/01-part-a2/:5:1","tags":["论文阅读"],"title":"论文阅读01 Part-A2","uri":"/01-part-a2/"},{"categories":["论文阅读"],"content":"2. Part-aggregation stage 第二部分就是使用 intra-object part location 以及分割信息等, 对生成的 proposal 进行精调 第一阶段输出的信息有: point-wise features point-wise intra-object part locations 3D proposals ROI-aware point cloud region pooling 进行框的预测, 打分以及 refine PointRCNN的方法可能存在歧义性, 相同的点可能产生不同的框 这里会保留空的体素, 这样就相当与间接保留了物体的形状信息 ","date":"2021-03-16","objectID":"/01-part-a2/:5:2","tags":["论文阅读"],"title":"论文阅读01 Part-A2","uri":"/01-part-a2/"},{"categories":["论文阅读"],"content":"结果 三个方向预测的 part location 平均误差为 6.28cm 高度( Z )方向的误差一般较小, 容易预测一些 Failure Case 背景点与前景点的区分, 背景点与前景点相似情况下, 容易误检测 3D IOU的评价对于定位结果较为敏感 检测准确率还是较高的, 只有4.5% 的概率误检测 可视化结果 前景物体点的颜色越靠近 corner, 颜色越接近corner的颜色 ","date":"2021-03-16","objectID":"/01-part-a2/:6:0","tags":["论文阅读"],"title":"论文阅读01 Part-A2","uri":"/01-part-a2/"},{"categories":["系统装机"],"content":"1. 系统安装 关闭secure boot 插上系统盘，开机后狂按ESC，暂停启动，然后弹出BIOS设置，选择启动设备，使用U盘启动 在选择‘Install UBUNTU’之前，按E进入设置，在quiet splash —那处,把—替换为nomodeset,再按F10进入系统进行安装，否则会报错acpi bios error以及花屏！！！ 然后正常选择，我选的最小系统安装，免去安装多余的游戏软件等 分区设置，先选择something else，自己设置分区，如下 设置swap空间:主分区/空间起始/交换空间/大小一般是实际内存1-2倍 设置引导EFI:逻辑分区/空间起始/EFI分区/大小一般1GB 设置挂载的/:这个是ubuntu计算机的安装位置,逻辑分区/空间起始/EXT4/挂载点为/ 最后设置引导,最下面的那个选项,选择之前设置的EFI引导在的那个分区 注意，这里建议不单独分出来/home的空间，直接全都放在/下面就好，免得空间不够难以重新分区 进入安装,完成后会重启,重启后同样按e进入,在quiet splash后加nomodeset再按F10进入 ","date":"2021-03-07","objectID":"/ubuntu_install/:1:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"2. 换源，更新，升级 进入系统后第一步操作应该就是将源改成国内的清华或者阿里，然后运行以下命令 sudo apt update sudo apt upgrade ","date":"2021-03-07","objectID":"/ubuntu_install/:2:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"3. Nvidia驱动安装 上述操作装完系统后，没有显卡驱动是无法进入的，所以必须加上nomodeset 除此之外，进系统后的分辨率应该也不对，会更大一些，这一切的原因都是显卡没有驱动程序，以及没有集显导致的 装一个独显驱动即可，方法： 进入Software \u0026 Updates 在第一个选项卡，ubuntu software处，勾选source code 在第五个选项卡，additional drivers处，选择nvidia驱动 using nvidia driver metapackage from nvidia-driver-450（proprietary） 点击右下角的apply changes，重启即可 ","date":"2021-03-07","objectID":"/ubuntu_install/:3:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"4. 安装常用软件 sudo apt install python python3 gconf-service-backend gconf-service gconf2 ","date":"2021-03-07","objectID":"/ubuntu_install/:4:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"5. 安装小飞机 先确保安装python以及python3 建议使用appimage，方便开机自启动 #! /bin/bash cd ~/Softwares ./electron-ssr-0.2.6.AppImage 自启动 将以上写成脚本，在start application里面添加启动程序，直接查找脚本位置即可，不需要 . 或者 sh 注意权限 ","date":"2021-03-07","objectID":"/ubuntu_install/:5:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"6. 挂载其它ntfs磁盘，实现开机自动挂载 查看磁盘 sudo fdisk -l 安装包 sudo apt install ntfs-3g sudo apt install ntfs-config 查看uuid sudo blkid ​ 创建要挂载的文件夹 mkdir /home/disks sudo mkdir /media/echo/Docs sudo mkdir /media/echo/Storage ​ 修改fstab sudo gedit /etc/fstab 添加以下内容 #Entry for /dev/sda5 : UUID=10AA0A8510AA0A85 /media/echo/Docs ntfs defaults,nodev,nosuid,uid=1000,gid=1000,uhelper=udisks2 0 0 #Entry for /dev/sda1 : UUID=10A8073A10A8073A /media/echo/Storage ntfs defaults,nodev,nosuid,uid=1000,gid=1000,uhelper=udisks2 0 0 #Entry for /dev/nvme0n1p4 : UUID=0BE104A20BE104A2 /home/echo/disks ntfs defaults 0 0 ​ ​ 测试挂载，不报错即为没问题 sudo umount -a sudo mount -a ","date":"2021-03-07","objectID":"/ubuntu_install/:6:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"7. 安装ipgw 找到对应ipgw安装包 sudo chmod +x ipgw sudo mv ipgw /usr/local/bin ipgw version ipgw login -u 1901938 -p xxx -s ","date":"2021-03-07","objectID":"/ubuntu_install/:7:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"8. 安装chrome sudo dpkg -i google-chrome-stable_current_amd64.deb sudo apt upgrade ","date":"2021-03-07","objectID":"/ubuntu_install/:8:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"9. 安装搜狗输入法 先装fcitx sudo apt install fcitx # 如果报错，使用 sudo apt-get install -f 再执行 sudo dpkg -i sogoupinyin_2.3.1.0112_amd64.deb reboot 打开设置，找到 language-\u003e Manage Installed Languages, 將“Keyboard input method system”設定為“fcitx” 在系統中搜索fcitx configuration，點選左下角新增輸入法，在彈出的對話方塊中將Only Show Current Language取消，即可看到sogou Pinyin，選擇新增即可 ","date":"2021-03-07","objectID":"/ubuntu_install/:9:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"10. 安装terminator sudo apt install terminator 刷新配置 cp terminator_config ~/.config/terminator/config ","date":"2021-03-07","objectID":"/ubuntu_install/:10:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"11. 安装typora or run: sudo apt-key adv –keyserver keyserver.ubuntu.com –recv-keys BA300B7755AFCFAE wget -qO - https://typora.io/linux/public-key.asc | sudo apt-key add - add Typora’s repository sudo add-apt-repository ‘deb https://typora.io/linux ./’ sudo apt-get update install typora sudo apt-get install typora ","date":"2021-03-07","objectID":"/ubuntu_install/:11:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"12. 安装CUDA\\CUDNN ","date":"2021-03-07","objectID":"/ubuntu_install/:12:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"cuda10.2 cuda下载列表 https://developer.nvidia.com/cuda-toolkit-archive 选择18.04 cuda10.2 使用deb安装 wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin sudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600 wget https://developer.download.nvidia.com/compute/cuda/10.2/Prod/local_installers/cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb sudo dpkg -i cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb sudo apt-key add /var/cuda-repo-10-2-local-10.2.89-440.33.01/7fa2af80.pub sudo apt-get update sudo apt-get -y install cuda 在bashrc或者zshrc中加入 cuda add export CPATH=/usr/local/cuda/targets/x86_64-linux/include:$CPATH export LD_LIBRARY_PATH=/usr/local/cuda/targets/x86_64-linux/lib:$LD_LIBRARY_PATH export PATH=/usr/local/cuda/bin:$PATH export CUDA_HOME=/usr/local/cuda 使用nvcc -V测试 nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2019 NVIDIA Corporation Built on Wed_Oct_23_19:24:38_PDT_2019 Cuda compilation tools, release 10.2, V10.2.89 安装patch https://developer.nvidia.com/cuda-10.2-download-archive?target_os=Linux\u0026target_arch=x86_64\u0026target_distro=Ubuntu\u0026target_version=1804\u0026target_type=deblocal patch1 sudo dpkg -i cuda-repo-ubuntu1804-10-2-local_10.2.1-1_amd64.deb sudo apt update sudo apt -y upgrade patch2 sudo dpkg -i cuda-repo-ubuntu1804-10-2-local_10.2.2-1_amd64.deb sudo apt update sudo apt -y upgrade ","date":"2021-03-07","objectID":"/ubuntu_install/:12:1","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"cudnn 需要登录，使用google账号登录， 下载 cudnn-10.2-linux-x64-v8.1.1.33 source安装，先解压，出现一个cuda的文件夹 tar -zxf cudnn-10.2-linux-x64-v8.1.1.33.tgz sudo cp cuda/include/cudnn.h /usr/local/cuda/include sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64 sudo chmod a+r /usr/local/cuda/include/cudnn.h sudo chmod a+r /usr/local/cuda/lib64/libcudnn* deb安装-未尝试 要下载的文件也是两个，分别是cuDNN Runtime Library for Ubuntu18.04 (Deb和 [cuDNN Developer Library for Ubuntu18.04 (Deb)] 下载完成后一次安装这两个文件就可以了**（先安装runtime library，再安装developer library）** 至此，CUDA10.2+cuDNN8就成功的在Ubuntu18.04上安装成功了。 更换安装方法！！！！ 由于源码安装的cudnn无法被找到，所以换deb安装 sudo rm /usr/local/cuda/include/cudnn.h sudo rm /usr/local/cuda/lib64/libcudnn* sudo dpkg -i libcudnn8_8.1.0.77-1+cuda10.2_amd64.deb sudo dpkg -i libcudnn8-dev_8.1.0.77-1+cuda10.2_amd64.deb sudo dpkg -i libcudnn8-samples_8.1.0.77-1+cuda10.2_amd64.deb 由于8.1.0无法通过cudnn测试，所以换成7.6.5 又安装了源码tar格式的cudnn 关于查看GPU显卡的状态，除了使用显卡驱动中提供的命令 nvidia-smi 外，推荐使用 https://github.com/Syllo/nvtopgithub.com ","date":"2021-03-07","objectID":"/ubuntu_install/:12:2","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"13. 安装pycharm 由于ubuntu自带了snap，使用snap安装 sudo snap install [pycharm-professional|pycharm-community] –classic sudo snap install pycharm-professional –classic ","date":"2021-03-07","objectID":"/ubuntu_install/:13:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"14. 安装openvpn ","date":"2021-03-07","objectID":"/ubuntu_install/:14:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"补充在ubuntu18.04安装的记录 sudo apt update sudo apt install openvpn 接下来和ubuntu16.04一致，运行脚本以及ovpn文件即可 ","date":"2021-03-07","objectID":"/ubuntu_install/:15:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"15. 安装anaconda wget https://repo.anaconda.com/archive/Anaconda3-2020.11-Linux-x86_64.sh 给权限, 运行 sudo chmod 777 Anaconda3-2020.07-Linux-x86_64.sh bash Anaconda3-2020.07-Linux-x86_64.sh 安装过程中, 在安装目录处修改目录, 第二个问题选yes ","date":"2021-03-07","objectID":"/ubuntu_install/:16:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"16. 安装git sudo apt install -y git 自动保存账户密码 git config –global -e -\u003e 添加以下行 [credential] helper = store ","date":"2021-03-07","objectID":"/ubuntu_install/:17:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"17. 安装zsh 确保安装了git https://ohmyz.sh/#install https://github.com/romkatv/powerlevel10k sudo apt-get install zsh sh -c “$(wget https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -)” git clone –depth=1 https://gitee.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions ","date":"2021-03-07","objectID":"/ubuntu_install/:18:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"18. 安装opencv ","date":"2021-03-07","objectID":"/ubuntu_install/:19:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"19. 安装ros sudo sh -c ‘echo “deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main” \u003e /etc/apt/sources.list.d/ros-latest.list’ sudo apt-key adv –keyserver ‘hkp://keyserver.ubuntu.com:80’ –recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654 Executing: /tmp/apt-key-gpghome.GnF5MH9S4s/gpg.1.sh –keyserver hkp://keyserver.ubuntu.com:80 –recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654 gpg: key F42ED6FBAB17C654: public key “Open Robotics info@osrfoundation.org” imported gpg: Total number processed: 1 gpg: imported: 1 报错 /sbin/ldconfig.real: /usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8 is not a symbolic link /sbin/ldconfig.real: /usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudnn_adv_train.so.8 is not a symbolic link /sbin/ldconfig.real: /usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8 is not a symbolic link /sbin/ldconfig.real: /usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudnn_ops_train.so.8 is not a symbolic link /sbin/ldconfig.real: /usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8 is not a symbolic link /sbin/ldconfig.real: /usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudnn.so.8 is not a symbolic link /sbin/ldconfig.real: /usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8 is not a symbolic link sudo ln -sf libcudnn_adv_infer.so.8.1.1 libcudnn_adv_infer.so.8 sudo ln -sf libcudnn_adv_infer.so.8 libcudnn_adv_infer.so sudo ln -sf libcudnn_adv_train.so.8.1.1 libcudnn_adv_train.so.8 sudo ln -sf libcudnn_adv_train.so.8 libcudnn_adv_train.so sudo ln -sf libcudnn_cnn_train.so.8.1.1 libcudnn_cnn_train.so.8 sudo ln -sf libcudnn_cnn_train.so.8 libcudnn_cnn_train.so sudo ln -sf libcudnn_ops_infer.so.8.1.1 libcudnn_ops_infer.so.8 sudo ln -sf libcudnn_ops_train.so.8.1.1 libcudnn_ops_train.so.8 sudo ln -sf libcudnn_ops_train.so.8 libcudnn_ops_train.so sudo ln -sf libcudnn.so.8.1.1 libcudnn.so.8 sudo ln -sf libcudnn.so.8 libcudnn.so 执行 sudo rosdep init 报错 sudo: rosdep: command not found 执行 sudo apt install rospack-tools 开代理 sudo rosdep init rosdep update 写入bashrc以及zshrc alias ros=‘source /opt/ros/melodic/setup.zsh’ ","date":"2021-03-07","objectID":"/ubuntu_install/:20:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"20. 安装hexo\u0026Gitbook\u0026slidev ","date":"2021-03-07","objectID":"/ubuntu_install/:21:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"1. 安装nodejs v10.x https://github.com/nodesource/distributions curl -fsSL https://deb.nodesource.com/setup_10.x | sudo -E bash - sudo apt-get install -y nodejs ","date":"2021-03-07","objectID":"/ubuntu_install/:21:1","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"2. 安装Git[略] ","date":"2021-03-07","objectID":"/ubuntu_install/:21:2","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"3. 安装Hexo npm install hexo PATH=\"$PATH:/home/echo/disks/HexoBlogs/node_modules/.bin\" ","date":"2021-03-07","objectID":"/ubuntu_install/:21:3","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"4. 安装Gitbook sudo npm install -g gitbook-cli gitbook init 将node升级到了14，但是发现hexo不好用，无法hexo d，所以降级到12，但是gitbook还不好使，于是修改gitbook 查看和更改node版本 node -v sudo n 查看hexo版本 hexo -v ","date":"2021-03-07","objectID":"/ubuntu_install/:21:4","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"6. 重装hexo以及部署新的博客主题，还有gitbook[2021-6-10] 解决npm全局安装的问题 在 /home 下 mkdir ~/.npm-global npm config set prefix ‘~/.npm-global’ # 设置npm全局包的安装路径: export PATH=~/.npm-global/bin:$PATH # 在用户的根目录下查看有没有.profile文件, 如果没有就创建 source ~/.profile 安装hexo npm install -g hexo-cli | 注：还有第二种安装方式 在blog目录下安装 npm install hexo 然后在 ~/.profile中添加路径，就可以在终端启动hexo命令了 PATH=\"$PATH:/home/echo/disks/blog/node_modules/.bin\" 接下来就可以初始化并创建博客了，新建一个博客文件夹（原来的HexoBlogs被我弄的坏了，运行命令报错） hexo init blog #初始化博客站点 cd blog npm install #安装依赖 把原来的博客文件夹 HexoBlogs路径下的 source 拷贝到新建的 blog对应的source下面 运行命令 hexo g \u0026 hexo s 这时没改config里面的主题，还应该是可以显示原来博客内容的，只是主题不对 更改主题为butterfly 在blog目录下，开终端，先下载，然后安装渲染器 git clone -b master https://github.com/jerryc127/hexo-theme-butterfly.git themes/butterfly npm install hexo-renderer-pug hexo-renderer-stylus –save npm install hexo-deployer-git –save npm install –save hexo-word-counter ","date":"2021-03-07","objectID":"/ubuntu_install/:21:5","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"21. 安装deepin相关 deepin wine基础框架，星外之神那个不好用，下载下面的安装 https://github.com/chenyingzhou/deepin-wine-ubuntu deepin wine相关软件 http://packages.deepin.com/deepin/pool/non-free/d/ 下载里面的deepin.com.wechat/ 以及 deepin.com.qq.office/ 这两个是好用的 dpkg安装 sudo apt install chrome-gnome-shell sudo apt install gnome-shell-extensions 除此之外，还需要安装topicons plus插件，然后使用tweak打开插件，方便图标显示 ","date":"2021-03-07","objectID":"/ubuntu_install/:22:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"微信 解决中文乱码问题 装完后中文乱码，按照下列教程 sudo gedit /opt/deepinwine/tools/run.sh sudo gedit /opt/deepinwine/tools/run_v2.sh 找到WINE_CMD 修改为： WINE_CMD=“LC_ALL=zh_CN.UTF-8 deepin-wine” 然后下载字体，更换 修改字体 下载字体msyh.ttc, 下载地址一：蓝奏云 （推荐）https://www.lanzous.com/i5wivmd 下载地址二：百度网盘 链接: https://pan.baidu.com/s/1rkjkmGJlpdaijCEWi7TZIw 提取码: btxw 将下载的字体解压，然后： cp msyh.ttc ~/.deepinwine/Deepin-WeChat/drive_c/windows/Fonts 修改系统注册表 gedit ~/.deepinwine/Deepin-WeChat/system.reg 更改以下两行内容为： “MS Shell Dlg”=“msyh” “MS Shell Dlg 2”=“msyh” gedit msyh_config.reg 在文件msyh_config.reg内添加如下内容： REGEDIT4 [HKEY_LOCAL_MACHINE\\Software\\Microsoft\\Windows NT\\CurrentVersion\\FontLink\\SystemLink] “Lucida Sans Unicode”=“msyh.ttc” “Microsoft Sans Serif”=“msyh.ttc” “MS Sans Serif”=“msyh.ttc” “Tahoma”=“msyh.ttc” “Tahoma Bold”=“msyhbd.ttc” “msyh”=“msyh.ttc” “Arial”=“msyh.ttc” “Arial Black”=“msyh.ttc” 注册字体 deepin-wine regedit msyh_config.reg 解决中心黑框问题 https://blog.diqigan.cn/posts/wine-wechat-black-square-fix.html 按照操作，做一遍，调试了一下sleep的值，改为0的话就成功了 ","date":"2021-03-07","objectID":"/ubuntu_install/:22:1","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"22. 定制Mac主题 未尝试 安装gnome-tweak-tool 和 chrome-gnome-shell 插件 (sudo aptitude install [name]) 安装GTK3主题 =\u003e X-Arc-Collection 使用tweak载入应用程序主题 =\u003e tweak — 外观 — 应用程序 — 选择X-Arc-Collection 安装gnome-shell 主题 =\u003e macOS High Sierra 安装gnome-shell 插件 =\u003e User Themes ( 之后重启Gnome =\u003e [Alt + F2] \u0026 [输入 r] \u0026 [点击 Enter] ) 使用tweak载入shell主题 =\u003e tweak — 外观 — shell — 选择Sierra shell主题 下载Mac图标主题 la-capitaine-icon-theme 或 McMojave-circle 图标文件夹移动到 ~/.icons目录下(没有则新建目录) 使用tweak载入icon主题 =\u003e tweak — 外观 — 图标 — 选择对应的图标主题 安装gnome-shell插件 =\u003e Dash to dock (将原生dock转变为可定制的浮动dock) 定制firefox主题 =\u003e Majave-gtk-theme ","date":"2021-03-07","objectID":"/ubuntu_install/:23:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"23. 安装handbrake sudo add-apt-repository ppa:stebbins/handbrake-releases sudo apt update sudo apt-get install handbrake-gtk ","date":"2021-03-07","objectID":"/ubuntu_install/:24:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"24. 安装ffmpeg https://octopuslian.github.io/2019/11/13/ubuntu1804-ffmpeg-install/ 安装在/home/echo/softwares下 可执行文件在ffmerg_install/bin下，将两个文件复制到/usr/local/bin下面 ","date":"2021-03-07","objectID":"/ubuntu_install/:25:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"25.安装视频播放软件 vlc ","date":"2021-03-07","objectID":"/ubuntu_install/:26:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"26. 安装notion https://appmaker.xyz/web2desk/将notion桌面化 解压后，找到notion，./执行即可 因难于使用，放弃 使用snap安装软件版notion sudo snap install notion-snap sudo apt install fonts-wqy-zenhei # 解决部分字体变为楷体的问题 ","date":"2021-03-07","objectID":"/ubuntu_install/:27:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"27. 其他appimage 将其放在/home/echo/softwares下，使用terminator右键执行 ","date":"2021-03-07","objectID":"/ubuntu_install/:28:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"28. 安装mendeley 下载软件deb，安装 由于使用了sudo打开，导致正常权限无法打开软件 sudo chown -R $(whoami) ~/.local/share/data/Mendeley Ltd. 运行，注意空格 sudo chown -R echo ~/.local/share/data/Mendeley\\ Ltd. 解决！ 此外，由于1.19.8版本没有文献搜索，所以最好使用1.19.6 https://www.mendeley.com/autoupdates/installers/1.19.6 ","date":"2021-03-07","objectID":"/ubuntu_install/:29:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"29. 安装flameshot sudo apt install flameshot 更改默认截图键为flameshot On Ubuntu (Tested on 18.04) To use Flameshot instead of the default screenshot application in Ubuntu we need to remove the binding on Prt Sc key, and then create a new binding for /usr/bin/flameshot gui (adaptated from Pavel’s answer on AskUbuntu). Remove the binding on Prt Sc using the following command. gsettings set org.gnome.settings-daemon.plugins.media-keys screenshot ‘[]’ Go to Settings \u003e Device \u003e Keyboard and press the ‘+’ button at the bottom. Name the command as you like it, e.g. flameshot. And in the command insert /usr/bin/flameshot gui. Then click “Set Shortcut..” and press Prt Sc. This will show as “print”. Now every time you press Prt Sc, it will start the Flameshot GUI instead of the default application. ","date":"2021-03-07","objectID":"/ubuntu_install/:30:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"30. 安装filezilla sudo apt-get install filezilla ","date":"2021-03-07","objectID":"/ubuntu_install/:31:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"31. 安装youtube-dl \u0026\u0026 annie ","date":"2021-03-07","objectID":"/ubuntu_install/:32:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"youtube-dl sudo curl -L https://yt-dl.org/downloads/latest/youtube-dl -o /usr/local/bin/youtube-dl sudo chmod a+rx /usr/local/bin/youtube-dl ","date":"2021-03-07","objectID":"/ubuntu_install/:32:1","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"annie wget https://github.com/iawia002/annie/releases/download/0.10.3/annie_0.10.3_Linux_64-bit.tar.gz tar zxvf annie_*.tar.gz mv annie /usr/local/bin/ ","date":"2021-03-07","objectID":"/ubuntu_install/:32:2","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"32. 安装Tex相关 sudo apt update sudo apt install texlive-full sudo apt install texstudio ","date":"2021-03-07","objectID":"/ubuntu_install/:33:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"33.右键打开terminator https://blog.csdn.net/bestBT/article/details/81221378 ","date":"2021-03-07","objectID":"/ubuntu_install/:34:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"34.更新cmake 不知什么原因，cmake版本是3.10，无法安装pcdet里需要的spconv 故升级到3.19.6 ./bootstrap –prefix=/usr make -jproc sudo make install 使用cmake --version查看版本 ","date":"2021-03-07","objectID":"/ubuntu_install/:35:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"35. 安装tensorrt 在官网下载对应的版本，TensorRT-7.0.0.11.Ubuntu-18.04.x86_64-gnu.cuda-10.2.cudnn7.6 下载tar版本以及deb版本 ","date":"2021-03-07","objectID":"/ubuntu_install/:36:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"安装tar到python tar版本的解压到 /home/echo/misc/extra_libs/ 同时在zshrc中加入 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/echo/misc/extra_libs/TensorRT-7.0.0.11.Ubuntu-18.04.x86_64-gnu.cuda-10.2.cudnn7.6/TensorRT-7.0.0.11/lib 进入到python环境，然后到TensorRT-7.0.0.11目录下，打开终端执行： cd python pip install tensorrt-7.0.0.11-cp37-none-linux_x86_64.whl cd .. cd uff pip install uff-0.6.5-py2.py3-none-any.whl cd .. cd graphsurgeon pip install graphsurgeon-0.4.1-py2.py3-none-any.whl 测试下 python import tensorrt # 无反应即为成功 ","date":"2021-03-07","objectID":"/ubuntu_install/:36:1","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"安装deb版本到c++ $ sudo dpkg -i nv-tensorrt-repo-ubuntu1804-cuda10.2-trt7.0.0.11-ga-20191216_1-1_amd64.deb $ sudo apt-key add /var/nv-tensorrt-repo-cuda10.2-trt7.0.0.11-ga-20191216/7fa2af80.pub $ sudo apt-get update $ sudo apt-get install tensorrt ","date":"2021-03-07","objectID":"/ubuntu_install/:36:2","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"$ dpkg -l | grep TensorRT ii libnvinfer-bin 7.0.0-1+cuda10.2 amd64 TensorRT binaries ii libnvinfer-dev 7.0.0-1+cuda10.2 amd64 TensorRT development libraries and headers ii libnvinfer-doc 7.0.0-1+cuda10.2 all TensorRT documentation ii libnvinfer-plugin-dev 7.0.0-1+cuda10.2 amd64 TensorRT plugin libraries ii libnvinfer-plugin7 7.0.0-1+cuda10.2 amd64 TensorRT plugin libraries ii libnvinfer-samples 7.0.0-1+cuda10.2 all TensorRT samples ii libnvinfer7 7.0.0-1+cuda10.2 amd64 TensorRT runtime libraries ii libnvonnxparsers-dev 7.0.0-1+cuda10.2 amd64 TensorRT ONNX libraries ii libnvonnxparsers7 7.0.0-1+cuda10.2 amd64 TensorRT ONNX libraries ii libnvparsers-dev 7.0.0-1+cuda10.2 amd64 TensorRT parsers libraries ii libnvparsers7 7.0.0-1+cuda10.2 amd64 TensorRT parsers libraries ii tensorrt 7.0.0.11-1+cuda10.2 amd64 Meta package of TensorRT 说明安装成功 ","date":"2021-03-07","objectID":"/ubuntu_install/:37:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"36. 安装苹果主题 https://zhuanlan.zhihu.com/p/71588449 按照以上链接执行即可 sudo apt install gnome-tweak-tool gnome-shell-extensions chrome-gnome-shell sudo apt-get install gtk2-engines-murrine gtk2-engines-pixbuf sudo add-apt-repository ppa:dyatlov-igor/sierra-theme sudo apt update sudo apt install sierra-gtk-theme git clone https://github.com/USBA/Cupertino-iCons sudo unzip -o Cupertino-iCons.zip -d /usr/share/icons 安装gnome插件的方法如下 https://zhuanlan.zhihu.com/p/36265103 ","date":"2021-03-07","objectID":"/ubuntu_install/:38:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"37. 安装惠普打印机驱动 sudo apt-get install hplip hplip-gui 然后找到hplip toolsbox，按照提示安装即可 ","date":"2021-03-07","objectID":"/ubuntu_install/:39:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"其他小工具 小火车 sudo apt install sl # 使用sl调用 代码雨 sudo apt install cmatrix CPU内存等显示插件 https://www.sohu.com/a/301992941_495675 sudo apt-get install gir1.2-gtop-2.0 gir1.2-networkmanager-1.0 gir1.2-clutter-1.0 打开Ubuntu软件，然后搜索“system monitor extension” 选择system monitor 可以显示network的那一个 ","date":"2021-03-07","objectID":"/ubuntu_install/:40:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"更改锁屏输入密码时的壁纸 sudo cp /usr/share/gnome-shell/theme/ubuntu.css /usr/share/gnome-shell/theme/ubuntu.css.bak sudo gedit /usr/share/gnome-shell/theme/ubuntu.css 修改配置文件，记得修改路径 #lockDialogGroup { background: #2c001e url(resource:///org/gnome/shell/theme/noise-texture.png); background-repeat: repeat; } —————- 改为 ———————– #lockDialogGroup { background: #2c001e url(file:///home/echo/.lock.jpg); height: 100%; background-size: contain; background-attachment: fixed; background-position: 0px 0px; background-repeat: repeat; } 这个版本可以解决多显示器问题 注意壁纸的分辨率应该符合显示器分辨率 ","date":"2021-03-07","objectID":"/ubuntu_install/:41:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"安装Ceres http://ceres-solver.org/installation.html 官网安装教程 http://ceres-solver.org/ceres-solver-2.0.0.tar.gz 下载最新的 2.0.0 的压缩包 CMake sudo apt-get install cmake google-glog + gflags sudo apt-get install libgoogle-glog-dev libgflags-dev BLAS \u0026 LAPACK sudo apt-get install libatlas-base-dev Eigen3 sudo apt-get install libeigen3-dev SuiteSparse and CXSparse (optional) sudo apt-get install libsuitesparse-dev tar zxf ceres-solver-2.0.0.tar.gz mkdir ceres-bin cd ceres-bin cmake ../ceres-solver-2.0.0 make -j3 make test sudo make install # 这个和官网安装教程不一致，需要sudo 2.0.0版本不满足，安装1.14 进入 ceres-bin 执行sudo make uninstall 然后解压 mkdir ceres-bin cd ceres-bin cmake ../ceres-solver-1.14.0 make -j3 make test sudo make install # 这个和官网安装教程不一致，需要sudo ","date":"2021-03-07","objectID":"/ubuntu_install/:42:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"安装网络可视化工具zetane https://github.com/shanjiayao/viewer ","date":"2021-03-07","objectID":"/ubuntu_install/:43:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["编程算法"],"content":"有关python中的yeild关键字的学习。 转载自： https://liam.page/2017/06/30/understanding-yield-in-python/ 生成器 = 迭代器 + yeild ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:0:0","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"概述 逐个获取元素的过程，就是「迭代」 迭代器中没有元素时，调用 next() 方法会抛出 StopIteration 异常 如果提供了 __iter__() 或者 __getitem__() 方法，那么该类的对象就是可迭代的 如果一个函数包含 yield 表达式，那么它是一个生成器函数；调用它会返回一个特殊的迭代器，称为生成器 对生成器执行next()：从上一次在 yield 表达式暂停的状态恢复，继续执行到下一次遇见 yield 表达式 在 Python 3 中，range 相当于 Python 2 中的 xrange，大大节省了内存占用 python3.3以后，新增了yeild from语法， yield from g相当于for v in g: yield v 对于一个生成器对象g，可以使用list(g)将其转换成列表 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:1:0","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"迭代、可迭代、迭代器 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:2:0","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"迭代（iteration）与可迭代（iterable） 迭代是一种操作，是遍历方式的一种（另一种是递归）；可迭代是对象的一种特性。 很多数据都是「容器」；它们包含了很多其他类型的元素。实际使用容器时，我们常常需要逐个获取其中的元素。逐个获取元素的过程，就是「迭代」。 # iteration a_list = [1, 2, 3] for i in a_list: print(i) 如果我们可以从一个对象中，逐个地获取元素，那么我们就说这个对象是「可迭代的」。 Python 中的顺序类型，都是可迭代的（list, tuple, string）。其余包括 dict, set, file 也是可迭代的。对于用户自己实现的类型，如果提供了 __iter__() 或者 __getitem__() 方法，那么该类的对象也是可迭代的。 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:2:1","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"迭代器（iterator） 迭代器是一种对象。 迭代器抽象的是一个「数据流」，是只允许迭代一次的对象。对迭代器不断调用 next() 方法，则可以依次获取下一个元素；当迭代器中没有元素时，调用 next() 方法会抛出 StopIteration 异常。迭代器的 __iter__() 方法返回迭代器自身；因此迭代器也是可迭代的。 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:2:2","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"迭代器协议（iterator protocol） 迭代器协议指的是容器类需要包含一个特殊方法。 如果一个容器类提供了 __iter__() 方法，并且该方法能返回一个能够逐个访问容器内所有元素的迭代器，则我们说该容器类实现了迭代器协议。 Python 中的迭代器协议和 Python 中的 for 循环是紧密相连的。 # iterator protocol and for loop for x in something: print(x) Python 处理 for 循环时，首先会调用内建函数 iter(something)，它实际上会调用 something.__iter__()，返回 something 对应的迭代器。而后，for 循环会调用内建函数 next()，作用在迭代器上，获取迭代器的下一个元素，并赋值给 x。此后，Python 才开始执行循环体。 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:2:3","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"生成器、yield 表达式 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:3:0","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"生成器函数（generator function）和生成器（generator） 生成器函数是一种特殊的函数；生成器则是特殊的迭代器。 如果一个函数包含 yield 表达式，那么它是一个生成器函数；调用它会返回一个特殊的迭代器，称为生成器。 def func(): return 1 def gen(): yield 1 print(type(func)) # \u003cclass 'function'\u003e print(type(gen)) # \u003cclass 'function'\u003e print(type(func())) # \u003cclass 'int'\u003e print(type(gen())) # \u003cclass 'generator'\u003e 如上，生成器 gen 看起来和普通的函数没有太大区别。仅只是将 return 换成了 yield。用 type() 函数打印二者的类型也能发现，func 和 gen 都是函数。然而，二者的返回值的类型就不同了。func() 是一个 int 类型的对象；而 gen() 则是一个迭代器对象。 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:3:1","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"yield 表达式 如前所述，如果一个函数定义中包含 yield 表达式，那么该函数是一个生成器函数（而非普通函数）。实际上，yield 仅能用于定义生成器函数。 与普通函数不同，生成器函数被调用后，其函数体内的代码并不会立即执行，而是返回一个生成器（generator-iterator）。当返回的生成器调用成员方法时，相应的生成器函数中的代码才会执行。 def square(): for x in range(4): yield x ** 2 square_gen = square() for x in square_gen: print(x) 前面说到，for 循环会调用 iter() 函数，获取一个生成器；而后调用 next() 函数，将生成器中的下一个值赋值给 x；再执行循环体。因此，上述 for 循环基本等价于： genitor = square_gen.__iter__() while True: x = geniter.next() # Python 3 是 __next__() print(x) 注意到，square 是一个生成器函数；作为它的返回值，square_gen 已经是一个迭代器；迭代器的 __iter__() 返回它自己。因此 geniter 对应的生成器函数，即是 square。 每次执行到 x = geniter.next() 时，square 函数会从上一次暂停的位置开始，一直执行到下一个 yield 表达式，将 yield 关键字后的表达式列表返回给调用者，并再次暂停。注意，每次从暂停恢复时，生成器函数的内部变量、指令指针、内部求值栈等内容和暂停时完全一致。 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:3:2","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"生成器的方法 生成器有一些方法。调用这些方法可以控制对应的生成器函数；不过，若是生成器函数已在执行过程中，调用这些方法则会抛出 ValueError 异常。 generator.next()：从上一次在 yield 表达式暂停的状态恢复，继续执行到下一次遇见 yield 表达式。当该方法被调用时，当前 yield 表达式的值为 None，下一个 yield 表达式中的表达式列表会被返回给该方法的调用者。若没有遇到 yield 表达式，生成器函数就已经退出，那么该方法会抛出 StopIterator 异常。 generator.send(value)：和 generator.next() 类似，差别仅在与它会将当前 yield 表达式的值设置为 value。 generator.throw(type[, value[, traceback]])：向生成器函数抛出一个类型为 type 值为 value 调用栈为 traceback 的异常，而后让生成器函数继续执行到下一个 yield 表达式。其余行为与 generator.next() 类似。 generator.close()：告诉生成器函数，当前生成器作废不再使用。 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:3:3","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"举例和说明 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:3:4","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"如果你看不懂生成器函数 如果你还是不太能理解生成器函数，那么大致上你可以这样去理解。 在函数开始处，加入 result = list()； 将每个 yield 表达式 yield expr 替换为 result.append(expr)； 在函数末尾处，加入 return result。 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:3:5","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"关于「下一个」yield 表达式 介绍「生成器的方法」时，我们说当调用 generator.next() 时，生成器函数会从当前位置开始执行到下一个 yield 表达式。这里的「下一个」指的是执行逻辑的下一个。因此 def f123(): yield 1 yield 2 yield 3 for item in f123(): # 1, 2, and 3, will be printed print(item) def f13(): yield 1 while False: yield 2 yield 3 for item in f13(): # 1 and 3, will be printed print(item) ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:3:6","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"使用 send() 方法与生成器函数通信 def func(): x = 1 while True: y = (yield x) x += y geniter = func() geniter.next() # 1 geniter.send(3) # 4 geniter.send(10)# 14 此处，生成器函数 func 用 yield 表达式，将处理好的 x 发送给生成器的调用者；与此同时，生成器的调用者通过 send 函数，将外部信息作为生成器函数内部的 yield 表达式的值，保存在 y 当中，并参与后续的处理。 这一特性是使用 yield 在 Python 中使用协程的基础。 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:3:7","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"yield 的好处 Python 的老用户应该会熟悉 Python 2 中的一个特性：内建函数 range 和 xrange。其中，range 函数返回的是一个列表，而 xrange 返回的是一个迭代器。 在 Python 3 中，range 相当于 Python 2 中的 xrange；而 Python 2 中的 range 可以用 list(range()) 来实现。 Python 之所以要提供这样的解决方案，是因为在很多时候，我们只是需要逐个顺序访问容器内的元素。大多数时候，我们不需要「一口气获取容器内所有的元素」。比方说，顺序访问容器内的前 5 个元素，可以有两种做法： 获取容器内的所有元素，然后取出前 5 个； 从头开始，逐个迭代容器内的元素，迭代 5 个元素之后停止。 显而易见，如果容器内的元素数量非常多（比如有 10 ** 8 个），或者容器内的元素体积非常大，那么后一种方案能节省巨大的时间、空间开销。 现在假设，我们有一个函数，其产出（返回值）是一个列表。而若我们知道，调用者对该函数的返回值，只有逐个迭代这一种方式。那么，如果函数生产列表中的每一个元素都需要耗费非常多的时间，或者生成所有元素需要等待很长时间，则使用 yield 把函数变成一个生成器函数，每次只产生一个元素，就能节省很多开销了。 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:4:0","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["学习笔记"],"content":"记录学习Transformer过程中的一些个人理解与思考 ","date":"2021-01-27","objectID":"/transformer%E4%B9%8Bself-attention/:0:0","tags":["Transformer","DeepLearning"],"title":"Transformer之self-attention机制","uri":"/transformer%E4%B9%8Bself-attention/"},{"categories":["学习笔记"],"content":"self-attention ","date":"2021-01-27","objectID":"/transformer%E4%B9%8Bself-attention/:1:0","tags":["Transformer","DeepLearning"],"title":"Transformer之self-attention机制","uri":"/transformer%E4%B9%8Bself-attention/"},{"categories":["学习笔记"],"content":"1. 宏观理解 关于注意力机制，在此不做赘述，不过关于自注意力，可能还是先要从宏观上分析一下他是如何进行工作的 给定一个输入，可以是sequence或是图片或是点云，Transformer如何利用self-attention机制对输入进行深层次理解与学习？这其实就是self-attention的工作方式，总的来说，可以概括为 self-attention[自注意力层]是对输入信息做深层自我剖析，探究不同输入之间的相关性 在编码阶段，self-attention让每个当前向量“看”到其他位置向量的信息，进而编码成对应的特征 比如这张图片，在编码it时，self-attention就计算了it和其他单词向量之间的关系，进而让网络更好的编码it的特征 ","date":"2021-01-27","objectID":"/transformer%E4%B9%8Bself-attention/:1:1","tags":["Transformer","DeepLearning"],"title":"Transformer之self-attention机制","uri":"/transformer%E4%B9%8Bself-attention/"},{"categories":["学习笔记"],"content":"2. 微观分析 下面从细节上分析self-attention机制，以问题的方式记录 输入输出？ 一般来说，self-attention的输入和输出一般都是特征张量，因为其主要作用是通过编码来对特征进行加权，除此之外还会涉及到Pos Encoding需要的位置信息等 如何对输入进行学习？ 这里其实self-attention可以抽象地表达输入信息，如下图 输入向量化（Embedding） 如果输入的是原始数据，那么需要将其向量化，进行 Embedding Vector 转换，其实就是转换成固定大小的特征向量，毕竟同一尺寸的特征对于网络比较友好 从三个角度学习输入的特征（Queries、Keys、Values） 在self-attention中，可以理解为将输入拆解成三个参数，分别是Q K V，这个拆解是指输入的特征经过一个共享权值的网络层学习三个参数矩阵的具体值，如下图 其中Q代表着query，K代表Key，这两个向量的作用是对每个输入的特征向量做加权，让当前这个输入向量可以看到其他位置的特征信息，具体的做法就是，每个当前位置的Q与其他所有位置的K依次进行点积运算，得到的结果我们认为一定程度上代表了两个位置之间的相关性 V的意义，我个人理解很大程度上是对输入的更鲁棒的表达，类似于卷积网络提取图片特征，这个V经过了矩阵Wv之后，其本身应该学习到了输入特征向量的一些高层次特征，这些特征较为鲁棒，所以可以更好的用来表达自身特征向量 计算self-attention的三步骤 那下面来说具体如何计算self-attention的，以及上面所有的Q、K、V是如何使用的 第一步，通过共享权值的参数矩阵W学习出三个矩阵Q、K、V 第二步，重复计算每个Q和所有K的内积，得到scaled inner product，并除以维度的开方以及做softmax归一化处理，这样就得到了每个向量的注意力加权得分，0-1之间 第三步，将每个向量的注意力加权得分与V进行点乘，也就是对每个向量进行注意力加权，在这个过程中，将Q和K计算得到的特征编码到了加权之后的V中 这里的自注意力，指的是，当前向量对全局的注意力，也可以理解为当前向量和全局所有向量的关联程度 self-attention与编码的关系 这里所谓的自注意力机制，就是在编码的过程中，增加全局线索，具体做法就是将当前向量和其他向量做计算，得到相关性，这个相关性经过正则化之后作为权重，分别乘上所有向量，最后将计算结果加和，其实上述过程就是在对当前向量编码的过程中，设定编码方式为计算当前向量与所有向量的相关度，然后加权求和，得到当前向量的特征编码。而体现全局线索的部分就是当前向量与所有向量计算相关性的操作 并行化加速的可能 矩阵运算 注意，上述说的计算self-attention过程中，都可以通过矩阵来对运算进行表达，这也实现了加速的目的，相比于RNN的序列化计算，Transformer使用的self-attention就会快得多 一些问题 为什么学习q k v的参数矩阵是权值共享的？能否单独计算？ 这里的权值共享，指的是所有的输入都经过同样的W（包括Wq Wk Wv）来学习q k v，而如果权值不共享的话，应该是每个输入单独学习一个权重矩阵 q k v的维度一定全部相同么？ 不是，是q和k计算relation之后得到的张量维度与v相同即可，因为relation function不仅有点乘这一种，也有相减 为什么q和k是做点乘的？这样可以很好的表达向量之间的相关性么？ 这种做法是通用的，此外，这种方式还有一种名字，叫做 scalar self-attention，这样计算的结果更多是对全局信息的一种表达，标量是对每个输入都一致的 还有一种方案叫做 vector self-attention，具体做法就是将q和k做类似减法计算，然后得到的是每个特征向量都单独的结果，向量是每个输入得到的加权都不同 为什么需要做softmax？可不可以替换其他？功能要求是什么？ 这里的softmax其实可以概括为 normalization function，主要作用就是归一化，不过softmax是非线性的，这样可以是网络对于复杂的非线性系统拥有更好的表达 最终self attention的权重表示什么？atte与v一定要相乘么？系数相加不行么？ 最终的self attention权重表示的意义其实更多的取决于如何计算q和k之间的关系，如果是计算点乘，最终得到的是一个标量，那么这个权重更多是倾向一些全局信息的表达，如果是得到一个向量，那么每个权重不一致，则会更好的表达输入特征向量之间的相关性 Pos Encoding 位置编码层是为了让网络在另一个维度对输入数据进行理解，比如空间位置或序列信息 位置编码的概念就是在把原始数据向量化后，输入网络之前，让特征向量级联上一个表示位置信息或者序列信息的向量，这样可以让网络学习到一些序列化的信息 举个例子，如果没有位置编码，那么网络则更像是在计算组合，他不会考虑位置上的不同，注意这个位置是广泛的，可以是空间、时间等，那么这样的结果就是，输入一个语句， 你借了我100块钱 那么这句话也可能被翻译成 我借了你100块钱 所以加上位置编码，就可以让网络理解上下文信息的顺序特征，这是很重要的 提高网络感知信息的维度 — Multi Head 所谓的Multi Head机制，其实就是将每个特征向量原本学习到一组q k v，扩展到了N组，这样子分别计算注意力权重，那么每个输入的特征向量其实就得到了N个不同的加权之后的特征，经过网络的训练可以让这N个不同特征关注不同的点，这样更符合我们人类的注意力机制的方案 注意： 各个head之间，学习q k v参数矩阵的W矩阵也不相同 假如有N个head，那么最终得到的输出特征，其维度由N个head级联组成的，需要先将N个head进行concat，然后使用维度变换矩阵对其做维度对齐。 Multi-head Self-attention的不同head分别关注了global和local的讯息 ","date":"2021-01-27","objectID":"/transformer%E4%B9%8Bself-attention/:1:2","tags":["Transformer","DeepLearning"],"title":"Transformer之self-attention机制","uri":"/transformer%E4%B9%8Bself-attention/"},{"categories":["学习笔记"],"content":"参考 The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time. 本来想自己翻译了，不过找到了对应的翻译版，链接如下 The Illustrated Transformer[翻译] ","date":"2021-01-27","objectID":"/transformer%E4%B9%8Bself-attention/:2:0","tags":["Transformer","DeepLearning"],"title":"Transformer之self-attention机制","uri":"/transformer%E4%B9%8Bself-attention/"},{"categories":["学习笔记"],"content":"本文主要介绍学习目标跟踪算法时遇到的关于边界效应以及余弦窗平滑的相关知识 ","date":"2021-01-27","objectID":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/:0:0","tags":["Tracking","DeepLearning"],"title":"目标跟踪中的边界效应与余弦窗平滑","uri":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/"},{"categories":["学习笔记"],"content":"1. 边界效应 ","date":"2021-01-27","objectID":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/:1:0","tags":["Tracking","DeepLearning"],"title":"目标跟踪中的边界效应与余弦窗平滑","uri":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/"},{"categories":["学习笔记"],"content":"1.1 背景 在目标跟踪算法中，边界效应最早在的出现，是在基于相关滤波方法的目标跟踪算法中。 先简述相关滤波的目标跟踪算法，相关滤波(correlation filter)是一种模板类方法，采用在线模板匹配的方式，在线学习模板变化，但是相关滤波的缺点也很明显，对快速变形和快速运动情况的跟踪效果不好。 快速变形效果差是因为模板类方法的机制，快速形变的时候，对于目标模板的基于HOG的梯度计算很难跟上目标，目标快速变色也会导致模板无法准确适应的情况，此外，在线学习的模板更新策略与更新频率都会影响跟踪效果 而快速运动效果差则是因为所谓的边界效应，目标的快速运动会导致相邻两帧之间目标在图像中的像素距离过大，从到导致跟踪效果差甚至跟踪失败的现象 ","date":"2021-01-27","objectID":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/:1:1","tags":["Tracking","DeepLearning"],"title":"目标跟踪中的边界效应与余弦窗平滑","uri":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/"},{"categories":["学习笔记"],"content":"1.2 定义 对于边界效应的定义，如下： 宏观上来看，目标在被跟踪过程中，在下一帧图像中的位置偏离了search window中心太远，比如非常靠近边缘、出去一半、全部出去，叫做边界效应 边界效应的产生原因，经查阅资料，源于在跟踪算法中引入了离散傅里叶变换，这极大地提高了算法的计算效率，不过也产生了副作用，就是边界效应 ","date":"2021-01-27","objectID":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/:1:2","tags":["Tracking","DeepLearning"],"title":"目标跟踪中的边界效应与余弦窗平滑","uri":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/"},{"categories":["学习笔记"],"content":"1.3 总结 对于边界效应，其根本原因可以概括为三个字，大位移，其实实际应用中，这种情况都是经常遇到的，因为我们所说的位移是针对传感器坐标系下的，是相对量，并不一定是世界坐标系下，所以产生的原因可能有两点 处理频率低 包括传感器的采样频率以及算法的运行频率，我统称他们为处理频率，如果处理频率上不去，那么每次在新的搜索区域中寻找目标时，就会发现目标的位移大 实际运动快 另外一种原因就是在世界坐标系下，目标的确处于高速运动，相对于传感器来说，两帧之间位置变化较大 ","date":"2021-01-27","objectID":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/:1:3","tags":["Tracking","DeepLearning"],"title":"目标跟踪中的边界效应与余弦窗平滑","uri":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/"},{"categories":["学习笔记"],"content":"1.4 解决方案 通常来说有两种经典的解决方案，分别是余弦窗机制以及增加搜索区域面积 增加搜索区域面积 这个很好理解，大的搜索区域可以很有效的解决边界效应，因为边界的概念是相对于搜索区域大小来定义的，但是缺陷是搜索区域的扩大同样也引入了更多的背景信息，容易造成跟踪模板的漂移，导致模板跟着背景走，一去不回头～ 余弦窗机制 这也是本文想着重记录的，余弦窗机制不仅仅是出现在基于相关滤波的目标算法中，基于深度学习孪生网络的目标跟踪器也有很多都用到了余弦窗来做平滑 但是这种机制自身也有一定的弊端，用的时候需要做取舍 ","date":"2021-01-27","objectID":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/:1:4","tags":["Tracking","DeepLearning"],"title":"目标跟踪中的边界效应与余弦窗平滑","uri":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/"},{"categories":["学习笔记"],"content":"2. 余弦窗机制 ","date":"2021-01-27","objectID":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/:2:0","tags":["Tracking","DeepLearning"],"title":"目标跟踪中的边界效应与余弦窗平滑","uri":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/"},{"categories":["学习笔记"],"content":"2.1 作用原理 余弦窗机制为什么能处理边界效应？ 在相关滤波算法中，余弦窗的机制作用在像素上：对搜索区域的像素做更改，使搜索区域边界的像素值接近0，这样可以消除边界的不连续性 而在基于深度学习的目标跟踪算法中，余弦窗的引入则是针对于特征学习到的score map，对得到的得分根据余弦窗进行重新加权，越靠近中心，认为得分越准确，这时余弦窗的作用其实说成对错误检测结果的抑制更合理一点，因为在 score map中，大位移还有一种情况就是目标检测错误，这样使用余弦窗机制可以很好的对其进行抑制和惩罚 ","date":"2021-01-27","objectID":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/:2:1","tags":["Tracking","DeepLearning"],"title":"目标跟踪中的边界效应与余弦窗平滑","uri":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/"},{"categories":["学习笔记"],"content":"2.2 缺点 在相关滤波中，余弦窗直接让边界像素趋近于0，这样会导致背景信息的弱化，甚至前景信息的丢失。背景信息的弱化是指像素趋近0让模板不能学习背景的特征，前景目标的丢失是说，当目标产生大位移，运动到边界时，余弦窗会让目标仅存的像素也被过滤掉，就导致无法跟踪快速运动的目标 在孪生网络中，在score map上使用余弦窗，个人感觉更多的是对分数的加权，这样做的目的是保证搜索区域中间的目标拥有最高的优先级，但是同样，这并不是一个可以适应所有情况的方案，比如说一个目标快速运动经过了另外一个相似目标，那么跟踪器可能就跟踪错误了 ","date":"2021-01-27","objectID":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/:2:2","tags":["Tracking","DeepLearning"],"title":"目标跟踪中的边界效应与余弦窗平滑","uri":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/"},{"categories":["学习笔记"],"content":"2.3 实现 深入了解余弦窗，我只找了其在深度学习中的应用，看的代码是SiamMask # 定义 if p.windowing == 'cosine': # 默认cosine window = np.outer(np.hanning(p.score_size), np.hanning(p.score_size)) # 求外积 \u003c(25, 25), float64\u003e # 调用，更新score map中的分数 pscore = pscore * (1 - p.window_influence) + window * p.window_influence # ndarray\u003c(3125,), float64\u003e 调用的是numpy中的汉宁窗(hanning)和计算外积(outer)的函数 简单解释就是，使用汉宁窗初始化两个向量分别作为长和宽方向的定义，这里的余弦窗其实是正方形，所以两个向量大小一致，类似这样 \u003e\u003e\u003e np.hanning(12) array([0. , 0.07937323, 0.29229249, 0.57115742, 0.82743037, 0.97974649, 0.97974649, 0.82743037, 0.57115742, 0.29229249, 0.07937323, 0. ]) 然后np.outer这个函数的作用就是计算两个向量的外积，结果是一个矩阵，大小等于向量大小的平方，类似这样 这样就得到了一个余弦窗，越靠近中心，其加权分数越大，将这个分数作用在得到的 score map 上，就可以起到对跟踪结果的惩罚和抑制作用了 ","date":"2021-01-27","objectID":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/:2:3","tags":["Tracking","DeepLearning"],"title":"目标跟踪中的边界效应与余弦窗平滑","uri":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/"},{"categories":["学习笔记"],"content":"参考 https://zhuanlan.zhihu.com/p/26417182 https://gsy00517.github.io/computer-vision20200120120823/ https://zhuanlan.zhihu.com/p/59624151 https://zhuanlan.zhihu.com/p/66757733 ","date":"2021-01-27","objectID":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/:3:0","tags":["Tracking","DeepLearning"],"title":"目标跟踪中的边界效应与余弦窗平滑","uri":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/"},{"categories":["学习笔记"],"content":"学习Pytorch中的卷积相关。 ","date":"2021-01-21","objectID":"/pytorch-conv1d/:0:0","tags":["Pytorch","DeepLearning","Convolution"],"title":"Pytorch中的Convolution layers","uri":"/pytorch-conv1d/"},{"categories":["学习笔记"],"content":"互相关和卷积的区别 在CNN中，互相关和卷积都是使用filter/kernel对一张图像进行操作 互相关是从上到下，从左到右 卷积是从下到上，从右到左 卷积等同于将卷积核沿着x轴y轴翻转后，再进行互相关操作 在CNN中，为了简化操作，通常直接使用互相关来代替卷积，因为对于网络来说，无论是否翻转，都只不过是网络要学习的参数，翻转与否其实并无影响，所以互相关和卷积在这种情况下是等同的 ","date":"2021-01-21","objectID":"/pytorch-conv1d/:1:0","tags":["Pytorch","DeepLearning","Convolution"],"title":"Pytorch中的Convolution layers","uri":"/pytorch-conv1d/"},{"categories":["学习笔记"],"content":"Pytorch 中的ConvNd [官方文档](torch.nn.modules.conv — PyTorch 1.9.0 documentation) [中文文档](torch.nn · Pytorch 中文文档) Pytorch中的卷积层操作有三种，分别对应了一维，二维和三维，对于函数的参数以及相关说明，文档中都有详细的介绍，这里略过不提，本文更多的是对自己的理解以及感悟的记录，将会以问题的形式表达 ","date":"2021-01-21","objectID":"/pytorch-conv1d/:2:0","tags":["Pytorch","DeepLearning","Convolution"],"title":"Pytorch中的Convolution layers","uri":"/pytorch-conv1d/"},{"categories":["学习笔记"],"content":"1. 卷积是如何实现维度变化的 无论卷积操作的维度是多少，通过卷积核之后，输入的特征都可以发生维度的变化，比如输入的是点云数据的张量，维度是[B, 3， N]，对应的一维卷积的卷积核是[Cout, 3, Size]，其中Cout就代表了输出的维度，Size就是卷积核的大小，因为是一维卷积核，所以大小维度是1[注意是维度，不代表大小直接为1] 关于卷积核尺寸的定义，我将相关参数分为两种，一种参数定义卷积核的数量，这些参数包括了卷积操作的输入维度，以及卷积操作的输出维度；另一种参数定义卷积核的大小，比如在一维卷积中，kernel size就是一个一维的数值，如果需要关注上下文信息，就将其大小设置为大于1，或者像PointNet网络中设定的那样，将一维卷积核的大小设置为1，只学习一个点的特征信息 那么最终，一个卷积核的shape应该是 [Cout， Cin， kernelSize]，具体来说，Cin*kernelSize大小的卷积核与输入的Cin维度的特征进行卷积，然后为了输出Cout维度的特征，需要重复Cout份，所以总的大小就是Cout*Cin*kernelSize 注：既然明确了卷积核的参数以及卷积核的shape，那么还有一点要知道，这些卷积参数都是需要经过网络学习的，那么对应的卷积操作的参数量计算，结果等同于上述计算的卷积核大小 ","date":"2021-01-21","objectID":"/pytorch-conv1d/:2:1","tags":["Pytorch","DeepLearning","Convolution"],"title":"Pytorch中的Convolution layers","uri":"/pytorch-conv1d/"},{"categories":["学习笔记"],"content":"2. 卷积核的大小如何影响卷积效果的 首先说明，这个卷积核的大小指的是上述卷积核shape中的kernelSize 关于这个问题，是我在学习PointNet时想到的，因为点云数据索引的无序性，所以PointNet学习点云特征时，不能让网络学习到点与相邻点的局部信息，只能单独地学习每个点的特征，那么从感官上来看这样做是有问题的。后面的PointNet++用了那么多繁复的操作，其实最终目的也是为了让网络学习更多的局部感知信息而已 所以经过思考后，关于卷积核的尺寸大小如何影响卷积效果的，其最直观的答案就是，kernelSize设置不同大小尺寸时，会直接影响网络对于输入特征的感知能力，而这在深度学习领域有一个专有名词，叫做感受野（Receptive Field） 虽说卷积核的尺寸越大，越能感知更多的局部信息，但是对应的也会带来两个问题 背景噪声的加入 参数量的增加 所以实际设计网络结构时，还是尽可能地考虑周全 ","date":"2021-01-21","objectID":"/pytorch-conv1d/:2:2","tags":["Pytorch","DeepLearning","Convolution"],"title":"Pytorch中的Convolution layers","uri":"/pytorch-conv1d/"},{"categories":["学习笔记"],"content":"3. 1*1卷积核的作用[Bottleneck] Bottleneck机制的产生，就是为了让CNN能够在少量参数的前提下，学习到深层次的特征 具体方案就是使用 1×1的卷积升维，卷积核是小-\u003e 大 -\u003e 小的结构 第一种的参数量为：256×3×3×256 = 589824 第二种的参数量为：256×1×1×64 + 64×3×3×64 + 64×1×1×256 = 69632 可见这种Bottleneck机制能有效降低CNN的参数量 参考：https://davex.pw/2018/02/01/guide-for-kernel/ ","date":"2021-01-21","objectID":"/pytorch-conv1d/:2:3","tags":["Pytorch","DeepLearning","Convolution"],"title":"Pytorch中的Convolution layers","uri":"/pytorch-conv1d/"},{"categories":["学习笔记"],"content":"4. 空洞卷积核的机制 空洞卷积的原理就是通过对卷积核进行改变，将卷积核增加了扩张率（dilation rate）的概念，如下图，对卷积核每个卷积核之间加入了扩张距离，这样做的好处就是让网络在不增加参数量的情况下，提高感受野，下图的感受野从3*3变为了5×5 不过空洞卷积也有缺点： 不适用于精度较高的任务，比如像素级别的任务，因为计算卷积时，不是感受野中所有的像素都用来计算了，这样会损失信息，这也叫Gridding Effect网格效应 想不起来了，，等想起来再补充。。。 ","date":"2021-01-21","objectID":"/pytorch-conv1d/:2:4","tags":["Pytorch","DeepLearning","Convolution"],"title":"Pytorch中的Convolution layers","uri":"/pytorch-conv1d/"},{"categories":["学习笔记"],"content":"5. 可变形卷积核的原理 接下来这个卷积核的设计思路是我认为比较合理的，因为卷积核的作用是改变维度，进而提高感受野，那么对于不同的任务来说，可能一味提高感受野并不是好事，因为感受野如果不能较好地覆盖前景目标，反而引入了太多的背景信息，那么就会让网络学习到错误的特征，所以如何让感受野可变形？似乎是一个很好的研究方向 微软亚洲研究院（MSRA）就做了相关的研究，让卷积核自己形变，通过参数学习来决定感受野的覆盖区域，这是更加智能的方式 图片目标跟踪算法Ocean中，也使用了这种可变形卷积核，来让网络更好地关注前景目标，也得到了不错的结果，感兴趣的小伙伴可以了解下 ","date":"2021-01-21","objectID":"/pytorch-conv1d/:2:5","tags":["Pytorch","DeepLearning","Convolution"],"title":"Pytorch中的Convolution layers","uri":"/pytorch-conv1d/"},{"categories":["编程算法"],"content":"python中的sort与sorted的区别 Python 列表有一个内置的 list.sort() 方法可以直接修改列表。还有一个 sorted() 内置函数，它会从一个可迭代对象构建一个新的排序列表 sort和sorted使用了Timsort排序算法，时间复杂度和空间复杂度如下 ","date":"2021-01-17","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Bsort%E5%92%8Csorted/:1:0","tags":["sort","Coding","Python"],"title":"Python还债日记之sort和sorted","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Bsort%E5%92%8Csorted/"},{"categories":["编程算法"],"content":"1. sort(*, key=None, reverse=False) 针对python中的列表进行操作 sort是对原列表进行修改，是一种原地操作，使用 \u003c 进行比较，默认按升序排序 key 指定带有一个参数的函数，用于从每个列表元素中提取比较键 (例如 key=str.lower)。 对应于列表中每一项的键会被计算一次，然后在整个排序过程中使用。 默认值 None 表示直接对列表项排序而不计算一个单独的键值 reverse 为一个布尔值。 如果设为 True，则每个列表元素将按反向顺序比较进行排序，也就是输出降序排序结果 ","date":"2021-01-17","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Bsort%E5%92%8Csorted/:1:1","tags":["sort","Coding","Python"],"title":"Python还债日记之sort和sorted","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Bsort%E5%92%8Csorted/"},{"categories":["编程算法"],"content":"2. sorted(iterable, ***, key=None, reverse=False) 根据 iterable 中的项返回一个新的已排序列表，相比于sort只能针对python的列表对象，sorted可以针对任何可迭代对象使用（字典、元组等） 默认输出升序排序结果 具有两个可选参数，它们都必须指定为关键字参数。 key 指定带有单个参数的函数，用于从 iterable 的每个元素中提取用于比较的键 (例如 key=str.lower)。 默认值为 None (直接比较元素)。 reverse 为一个布尔值。 如果设为 True，则每个列表元素将按反向顺序比较进行排序 ","date":"2021-01-17","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Bsort%E5%92%8Csorted/:1:2","tags":["sort","Coding","Python"],"title":"Python还债日记之sort和sorted","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Bsort%E5%92%8Csorted/"},{"categories":["编程算法"],"content":"python中的广播机制 ","date":"2021-01-13","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6/:1:0","tags":["广播机制","Coding","Python"],"title":"Python还债日记之广播机制","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6/"},{"categories":["编程算法"],"content":"1. 定义 广播机制是对不同维度进行计算的方式，这种机制会执行维度进行自动对齐的操作，在python中，针对位运算（包括加减乘除），广播机制会自动将输入的矩阵或者张量维度进行计算，然后按照广播的方式，将维度对齐，这样可以有效地帮助代码变简洁 ","date":"2021-01-13","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6/:1:1","tags":["广播机制","Coding","Python"],"title":"Python还债日记之广播机制","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6/"},{"categories":["编程算法"],"content":"2. 举例分析 向量加张量 import numpy as np vect = np.array([1, 2, 3]) scalar = 1 print(vect + scalar) [2, 3, 4] 最终的输出结果相当于向量加上了一个经过广播之后的同维度的向量 矩阵加向量 import numpy as np a = np.array([[ 0, 0, 0], [10,10,10], [20,20,20], [30,30,30]]) b = np.array([1,2,3]) print(a + b) 输出是 [[ 1 2 3] [11 12 13] [21 22 23] [31 32 33]]  ","date":"2021-01-13","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6/:1:2","tags":["广播机制","Coding","Python"],"title":"Python还债日记之广播机制","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6/"},{"categories":["编程算法"],"content":"3. 机制总结 以输入两个不同维度的数组为例，两个数组的shape分别是a和b，那么广播机制的执行规则是 判断shape长度 如果两个数组shape的长度不一致，就说明数组的维度不统一，那么，按照shape最长的数组看齐，其他数组的shape不足的补1 (2, 3) + (3) -\u003e (2, 3) + (1, 3) 比较两数组各个维度的长度 当两数组的shape对齐之后，就逐维度比较两个数组的长度大小，应该满足以下条件： 同一维度，两数组的长度相同 同一维度，两数组的长度有一个是1 如果不满足，则两数组不能做shape广播 当某一维度上的长度是1，那么就将这个维度上的值复制N份，这个N是另外一个数组的对应维度的长度，然后按位运算 ","date":"2021-01-13","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6/:1:3","tags":["广播机制","Coding","Python"],"title":"Python还债日记之广播机制","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6/"},{"categories":["学习笔记"],"content":"Pytorch中的 nn 与 nn.functional 这两者其实本质上功能是一致的，都是用于开发者调用pytorch中的接口以搭建自己的网络 有一点不同的是，nn继承于nn.Module，是对nn.functional中定义的函数的类封装，所以nn.functional更加灵活，更加底层 Attributes torch.nn.Xxx torch.nn.functional.xxx 类型 class function 自身属性 继承nn.Module相关属性 / 调用方式 先实例化，再调用实例化对象 直接传参 支持nn.Sequential 是 否 dropout兼容性 自动关闭dropout 需手动传参关闭 weight管理 自动 手动定义相关权重 官方文档中有写到，需要学习参数的网路结构，最好使用 nn.Xxx的方式定义，便于管理权重参数，其他像maxpool, loss func, activation func等不需要学习参数的结构，可以直接使用 nn.functional.xxx调用底层函数，使用更加灵活方便 ","date":"2021-01-13","objectID":"/pytorch-nn%E4%B8%8Efunctional%E7%9A%84%E5%8C%BA%E5%88%AB/:1:0","tags":["Pytorch","DeepLearning"],"title":"Pytorch-nn与functional的区别","uri":"/pytorch-nn%E4%B8%8Efunctional%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["学习笔记"],"content":"Pytorch 矩阵乘法 关于广播机制，参考 torch.mul torch.mul(input, other, *, out=None) 按位相乘，对维度的要求是，两个张量尽量维度对齐，或者是可以遵循广播机制 比如： \u003e\u003e\u003e a = torch.randn(4, 1) \u003e\u003e\u003e a tensor([[ 1.1207], [-0.3137], [ 0.0700], [ 0.8378]]) \u003e\u003e\u003e b = torch.randn(1, 4) \u003e\u003e\u003e b tensor([[ 0.5146, 0.1216, -0.5244, 2.2382]]) \u003e\u003e\u003e torch.mul(a, b) tensor([[ 0.5767, 0.1363, -0.5877, 2.5083], [-0.1614, -0.0382, 0.1645, -0.7021], [ 0.0360, 0.0085, -0.0367, 0.1567], [ 0.4312, 0.1019, -0.4394, 1.8753]]) torch.mm torch.mm(input, mat2, *, out=None) → Tensor 矩阵相乘，，注意只支持二维的张量 这个函数不支持广播机制，也就是说，必须完全按照矩阵相乘的顺序输入 torch.matmul torch.mm(input, mat2, *, out=None) → Tensor 也是矩阵相乘，不过与 mm不同，这个函数支持广播机制 也就是说输入的两个张量维度不一定需要完全按照矩阵乘法顺序输入 比如，输入的张量是 (j×1×n×m) ，另外一个张量是 (k×m×p)，则会自动按照维度，广播到 (j×k×n×m) 和 (j×k×m×p)，然后计算矩阵相乘，得到 (j×k×n×p) ","date":"2021-01-13","objectID":"/pytorch%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95/:0:1","tags":["Pytorch","DeepLearning"],"title":"Pytorch中的矩阵乘法","uri":"/pytorch%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95/"},{"categories":["读书观影"],"content":"记录看到的美好文章。 若能避开猛烈的欢喜，自然也不会有悲痛的来袭。我尝试绕开那些悲痛，却也错过了所有欢喜，倘若真的无从避免，倒不如先享受那顽固的欢喜。《人间失格》 长情不过一杯酒，早春不过一棵树 年龄是时间的箭头，往前延伸，总会遇到更多的事 不管那些事是你想遇到的，还是不想遇到的，但它就在那里，你的心态自然会发生变化 不要说自我控制、消解、努力或者别的什么，因为当我们连评价的标准都还找不到的时候，这样做是无意义的 那么只能就此刻来说，我们做自己喜欢的事便好，快活就好 须尽欢，无论享乐还是工作 ——来自猫腻的书 逝者如斯，故不舍昼夜，须尽欢！ 我们总会担心，当面临人生的岔路口时，是不是拥有足够的认知来选择一条足够适合自己的路；但，世事往往多变，如果没办法确定地做一个一定正确的选择，那就在以后的日子里，学会忠于自己的选择吧！ 生死之间无小事，生离，或是死别 大都好物不坚牢，彩云易散琉璃脆 人生不得行胸臆，纵年百岁犹为夭 Sidere mens eadem mutato. 繁星纵变，智慧永恒。 ——悉尼大学校训 Die Luft der Freiheit weht. 自由之风永远吹拂。——斯坦福校训 Je pense, donc je suis. 我思故我在。——笛卡尔 Facta non verba. 行胜于言 Eadem mutata resurgo. 纵使改变，依然故我。——伯努利墓志铭 Velut arbor aevo. 像参天大树一样成长/百年树人。——加拿大多伦多大学校训 Hinc itur ad astra. 此处通往繁星。 ——立陶宛维尔纽斯大学校训 ","date":"2021-01-13","objectID":"/%E7%BE%8E%E6%96%87%E6%94%B6%E5%BD%95/:0:0","tags":["美文收录"],"title":"美文收录","uri":"/%E7%BE%8E%E6%96%87%E6%94%B6%E5%BD%95/"},{"categories":["必备工具"],"content":"gitbook是github与markdown的结合体，我们可以通过markdown笔记记录书籍内容，然后发布到gitbook上，使用操作和流程与github类似，详细了解见官网以及Git ","date":"2021-01-11","objectID":"/gitbook%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/:0:0","tags":["gitbook","Tools"],"title":"Gitbook使用笔记","uri":"/gitbook%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/"},{"categories":["必备工具"],"content":"Gitbook安装及使用 ","date":"2021-01-11","objectID":"/gitbook%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/:1:0","tags":["gitbook","Tools"],"title":"Gitbook使用笔记","uri":"/gitbook%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/"},{"categories":["必备工具"],"content":"1. 安装 npm install -g gitbook-cli gitbook init # then system will download gitbook automatically 详见 ","date":"2021-01-11","objectID":"/gitbook%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/:1:1","tags":["gitbook","Tools"],"title":"Gitbook使用笔记","uri":"/gitbook%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/"},{"categories":["必备工具"],"content":"2. 创建书籍 初始化一个Gitbook cd到要创建书籍的目录下，比如 ~/books，然后运行 $ gitbook init 终端会输出以下命令，并创建两个文件 warn no summary file in this book info: create README.md info: create SUMMARY.md info: initialization is finished 编写README.md和SUMMARY.md 这时文件夹下的目录为 $ ls README.md SUMMARY.md README.md是对创建书籍的介绍，这里面的内容会在整个gitbook的简介中出现 SUMMARY.md是整个书籍的目录结构，这个文件的编写需要按照对应的格式，以标题的形式，每一个标题对应一个.md文件的路径，类似这样 # Summary * [Introduction](README.md) ----- * [Detection](detection/README.md) * [PointPillars](detection/pointpillars.md) * [Tracking](tracking/README.md) * [SC3D](tracking/sc3d.md) * [Segmentation](seg/README.md) * [SOLO](seg/solo.md) * [PointCloud](pointcloud/README.md) * [PV-CNN](pointcloud/pvcnn.md) 我们可以按照自己对书籍的设想，编写对应的目录大纲 当做完更改之后，再次执行git init，就会根据SUMMARY.md中编写的目录自动生成对应文件 编译 仍然在~/books目录下，执行 $ gitbook build ---------------------------------------------------- info: 7 plugins are installed info: 6 explicitly listed info: loading plugin \"highlight\"... OK info: loading plugin \"search\"... OK info: loading plugin \"lunr\"... OK info: loading plugin \"sharing\"... OK info: loading plugin \"fontsettings\"... OK info: loading plugin \"theme-default\"... OK info: found 9 pages info: found 0 asset files info: \u003e\u003e generation finished with success in 0.5s ! 此时目录下会生成对应的书籍编译文件_book $ tree . -L 2 ------------------- . ├── _book │ ├── detection │ ├── gitbook │ ├── index.html │ ├── pointcloud │ ├── search_index.json │ ├── seg │ └── tracking ├── detection │ ├── pointpillars.md │ └── README.md ├── pointcloud │ ├── pvcnn.md │ └── README.md ├── README.md ├── seg │ ├── README.md │ └── solo.md ├── SUMMARY.md └── tracking ├── README.md └── sc3d.md 10 directories, 12 files 编译得到的_book目录就是对已有的书籍内容做了转换，变成了html网页文件，如果你想将gitbook链接到个人博客，只需要上传这个目录下的文件即可，具体操作见下文 本地运行 仍然在~/books目录下，执行 $ gitbook serve # 这个命令会自动执行 gitbook build命令 --------------------------------- Live reload server started on port: 35729 Press CTRL+C to quit ... info: 7 plugins are installed info: loading plugin \"livereload\"... OK info: loading plugin \"highlight\"... OK info: loading plugin \"search\"... OK info: loading plugin \"lunr\"... OK info: loading plugin \"sharing\"... OK info: loading plugin \"fontsettings\"... OK info: loading plugin \"theme-default\"... OK info: found 9 pages info: found 0 asset files info: \u003e\u003e generation finished with success in 0.6s ! Starting server ... Serving book on http://localhost:4000 这时打开浏览器，输入http://localhost:4000，即可查看本地版的gitbook OK，到这里关于gitbook的简单使用就介绍完了，下面记录下如何在个人主页上使用gitbook ","date":"2021-01-11","objectID":"/gitbook%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/:1:2","tags":["gitbook","Tools"],"title":"Gitbook使用笔记","uri":"/gitbook%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/"},{"categories":["必备工具"],"content":"将GitBook链接到个人博客 简单记录下 个人使用的是 hexo 框架以及 fluid 主题搭建的个人博客 使用gitbook的初衷就是，我想在个人博客上链接一个地址，这个网页记录一些比如力扣刷题笔记等自己学习的内容，所以就简单了解了一下gitbook OK，那现在我默认已经拥有了自己的博客，并且已经按照上述流程初步体验了gitbook的使用，并且拥有了自己的第一个gitbook，如果你想把他链接到个人博客上，应该分以下三步： 将gitbook原始内容上传至github远程仓库 这里指的是自己编写的markdown笔记等 在github新建一个仓库，这个仓库的名字会是你博客跳转到gitbook网页的后缀 在gitbook本地，初始化仓库，远程仓库设定为刚刚建立的仓库地址 新建.gitignore文件，里面的内容设置为 *~ _book 上传当前文件到远程仓库的main分支 编译gitbook，将生成的_book中的内容上传到新的分支，叫做gh-pages gitbook build mkdir book_build cp -r _book/* book_build cd book_build git init git remote add origin xxx git checkout -b gh-pages git add . git commit -m \"first pub\" git push origin gh-pages 这样就将编译得到的_book下面的静态网页文件上传到了远程仓库的gh-pages分支下 登录github，找到仓库-\u003esetting-\u003eoptions-\u003eGithub pages，设置gh-pages为要展示的分支，保存，Over！ 设置个人博客中，对应的链接为 your-blog-address/xxx/，其中xxx既是远程仓库的名字，也是你的gitbook的名字 结果展示 leetcode· GitBook ","date":"2021-01-11","objectID":"/gitbook%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/:2:0","tags":["gitbook","Tools"],"title":"Gitbook使用笔记","uri":"/gitbook%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/"},{"categories":["学习笔记"],"content":"常见名词 device device一般指GPU端，也叫设备端，一般以 __device__ 前缀修饰的函数，函数的调用以及执行都需要在设备端进行 host host指CPU，也叫主机端，以 __host__ 前缀修饰的函数，调用和执行都在主机端进行 kernel \u0026 kernel func 全称是数据并行处理函数，一般也被成为核函数，个人理解，核函数负责主机与设备的交互，一般而言，核函数以 __global__ 前缀修饰，代表着其可以从主机端调用，在设备端执行，这就完成了数据从主机端到设备端的传输 通常，我们使用以下形式，在主机端调用核函数 kernel\u003c\u003c\u003cDg, Db, Ns, S\u003e\u003e\u003e(param list); kernel指核函数的名字，最后一部分就是核函数计算时需要传入的参数，«\u003c … »\u003e 中的参数就是对grid，block以及共享内存等CUDA参数的设定，具体表示会在后面说明 SM \u0026 SP SM指的是 Streaming MultiProcessing SP指的是 Streaming Processing SM和SP都是硬件层次的术语 一块GPU上面，有非常多的SM，以Tesla P100 GPU举例，其基于Pascal架构的版本包含56个SMs 一个SM包含多个SP，这里的SP其实和我们常说的CUDA core是等同的 每一个SM有自己的指令缓存，L1缓存，共享内存 每个SM通过执行block来进行GPU的同步计算，但是每个SM每次只能执行一个block grid \u0026 block \u0026 thread 这三者是CUDA编程时经常会遇到的概念，从上而下的层级依次是 grid → block → thread 为了更加清晰地理解这些层级关系，自下而上依次介绍如下： thread thread是GPU工作的最小执行单元，是程序员可以控制的最细粒度的并行单位。每一个thread在运算单元上就对应一个sp，所以大家会常常会笼统的把sp数量等同于thread的并行数量，从而量化不同GPU的性能 关于thread，还有一个概念，在GPU中，thread通常是一组一组执行的，一般来说每组的thread数量为32，这32个thread也被称为warp(线程束)，同一个warp中的thread执行的指令都是相同的，只是处理不同的数据。除此之外，对于warp的分组，一般来说都是SM自动进行的，每个warp中的thread，其id都是连续的 block block是CUDA执行代码时的基础单位，一个block由多个thread组成，具体参数是上述内核启动函数中传递的参数，也就是 «\u003c »\u003e中的 Db 参数，是一个Dim3类型的数据，具体包括x，y，z三个参数，分别对应行、列以及高度方向上的thread数量，这只是理想的参数，实际上，线程数还受到硬件计算能力的限制，不同计算能力的显卡，其允许的最大线程数量也不同，如下图 不同计算能力的显卡对应的最大允许Grid、block以及thread运行数量 Grid Grid是由若干个block组成的，一般而言，一个kernel的程序就对应一个grid去执行 一个grid对应的参数有三个，同样在核函数中«\u003c »\u003e可以设置，对应第一个参数Dg，具体有x，y，z三个方向，不过z方向的数量恒定为1，所以一个grid中包括的block数量就是 Dg.x × Dg.y × 1 总结 总体来看，一个GPU由SM构成，而每个SM就是运行blocks中指令的硬件载体 软件方面，当我们在CUDA编程时，编写一个形如kernel\u003c\u003c\u003cDg, Db, Ns, S\u003e\u003e\u003e(param list); 的核函数时，其在GPU中就会对应一个grid，而通过Dg, Db分配每个grid中包含多少个blocks以及每个block包含多少个threads， 最终，每个block会对应若干个由threads组成的warp，而硬件方面，每个SM就会运行对应block 中的每个warp，这就是整体的机制，为了方便理解，我画了一张草图来表示几者之间的关系 其实，仔细思考一下，对于编程人员来说，程序并行化的关键就在于设计一个方案，使得一个SM内的各种硬件单元都能有效利用，比如如何分配每个block中的线程数，让每个warp中尽可能都包含32个线程，进而合理利用资源，得到最理想的吞吐 ","date":"2021-01-10","objectID":"/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/:1:0","tags":["CUDA名词","DeepLearning"],"title":"cuda常见名词解释","uri":"/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/"},{"categories":["学习笔记"],"content":"关于 ","date":"2021-01-10","objectID":"/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/:2:0","tags":["CUDA名词","DeepLearning"],"title":"cuda常见名词解释","uri":"/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/"},{"categories":["学习笔记"],"content":"编程时实际线程数的计算 由于每个block里面的线程，在各自block内部都是有自己的线程id的，那么实际编程时如何计算对应每个block中的线程编号呢？ 如上图所示，以一个维度上的grid、block以及thread三者关系为例 实际线程编号 = 当前block编号 × block在对应维度上的尺寸 + 当前block中的thread编号 代码如下： __global__ void add(int n, float *x, float *y) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (int i = index; i \u003c n; i += stride) y[i] = x[i] + y[i]; } ","date":"2021-01-10","objectID":"/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/:2:1","tags":["CUDA名词","DeepLearning"],"title":"cuda常见名词解释","uri":"/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/"},{"categories":["学习笔记"],"content":"算法测试耗时 分别测试了一个线程、一个block以及多个block下的算法耗时，可以看到非常明显的加速！ ","date":"2021-01-10","objectID":"/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/:2:2","tags":["CUDA名词","DeepLearning"],"title":"cuda常见名词解释","uri":"/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/"},{"categories":["学习笔记"],"content":"参考 认识什么是 host code device code 以及 kernel An Easy Introduction to CUDA C and C++ | NVIDIA Developer Blog 其他基础概念了解，块、网格等 An Even Easier Introduction to CUDA | NVIDIA Developer Blog ","date":"2021-01-10","objectID":"/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/:3:0","tags":["CUDA名词","DeepLearning"],"title":"cuda常见名词解释","uri":"/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/"},{"categories":["学习笔记"],"content":"官网文档 [Pytorch 1.7] Custom C++ and CUDA Extensions - PyTorch Tutorials 1.7.1 documentation Custom C++ and CUDA Extensions - PyTorch Tutorials 1.7.1 documentation CN ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:1:0","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["学习笔记"],"content":"自定义扩展的必要性 Pytorch虽然已经使用了NVIDIA cuDNN、Intel MKL和NNPACK这些底层来加快训练速度，但是在某些情况下，比如我们要实现一些特定算法，光靠组合Pytorch已有的操作是不够的。这是因为Pytorch虽然在特定操作上经过了很好的优化，但却并不见得适合我们自定义的操作，所以，作为一名程序员，应该了解如何将自己的网络或者操作以底层C++的代码实现，这是很重要的 除此之外，如果pytorch代码需要与C++代码进行交互，也需要自己编写对应的C++扩展 ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:2:0","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["学习笔记"],"content":"操作步骤 ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:3:0","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["学习笔记"],"content":"1. 如何用C++实现我们的扩展/操作？ 头文件包括：#include \u003ctorch/extension.h\u003e 以及定义对应的函数名 #include \u003ctorch/extension.h\u003e //这一句是无论要实现任何op都必须添加的 #include \u003cvector\u003e //前向传播 torch::Tensor my_op_forward(const torch::Tensor\u0026 x, const torch::Tensor\u0026 y); //反向传播 std::vector\u003ctorch::Tensor\u003e my_op_backward(const torch::Tensor\u0026 gradOutput); 源文件包括：网络的定义，包括前向传播、反向传播以及pybind11将c++代码绑定到python的部分 #include \"my_op.h\" torch::Tensor my_op_forward(const torch::Tensor\u0026 x, const torch::Tensor\u0026 y) { AT_ASSERTM(x.sizes() == y.sizes(), \"x must be the same size as y\"); torch::Tensor z = torch::zeros(x.sizes()); z = 3 * x - y; return z; } std::vector\u003ctorch::Tensor\u003e my_op_backward(const torch::Tensor\u0026 gradOutput) { torch::Tensor gradOutputX = 3 * gradOutput * torch::ones(gradOutput.sizes()); torch::Tensor gradOutputY = -1 * gradOutput * torch::ones(gradOutput.sizes()); return {gradOutputX, gradOutputY}; } // pybind11 绑定 PYBIND11_MODULE(**TORCH_EXTENSION_NAME**, m) { m.def(\"forward\", \u0026my_op_forward, \"MY_OP forward\"); m.def(\"backward\", \u0026my_op_backward, \"MY_OP backward\"); } pybind11是python中用来和c++11通信的库 TORCH_EXTENSION_NAME不需要指定，这个定义在运行 setup.py 脚本文件时，对应的扩展名会传给这个定义，这样避免两者匹配不上 这里网络的定义可以调用pytorch/extension 的库，也就是ATen，也可以通过自定义的cuda kernels实现 ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:3:1","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["学习笔记"],"content":"2. 如何编译C++代码为python可以识别的文件？ 对应两种方案，setuptools 或者 torch.utils.cpp_extension.load() 这里详细介绍前者 编写对应的 setup.py，构建pytorch的c++扩展，利用python的 setuptools 来编译并加载C++代码，这样，执行setup.py from setuptools import setup import os import glob from torch.utils.cpp_extension import BuildExtension, CppExtension # 头文件目录 include_dirs = os.path.dirname(os.path.abspath(__file__)) # 源代码目录 source_file = glob.glob(os.path.join(working_dirs, 'src', '*.cpp')) setup( name='test_cpp', # 模块名称 与.cpp中的TORCH_EXTENSION_NAME对应 ext_modules=[CppExtension('test_cpp', sources=source_file, include_dirs=[include_dirs])], cmdclass={ 'build_ext': BuildExtension } ) 在终端执行 python setup.py install 这一步其实是包含了build+install执行的是先编译链接动态链接库，然后将构建好的文件以package的形式安装存放再当前开发环境的package的集中存放处，这样就相当于生成了一个完整的package了。和其他的如numpy，torch这些package没什么两样。 执行后，目录下会生成三个目录build/ dist/ ***.egg-info/ ，除此之外，一个名子类似 ***-0.0.0-py3.6-linux-x86_64.egg 的文件也会出现在当前python的环境中site-package ，具体的编译输出如下： output running install running bdist_egg running egg_info writing lltm.egg-info/PKG-INFO writing dependency_links to lltm.egg-info/dependency_links.txt writing top-level names to lltm.egg-info/top_level.txt reading manifest file 'lltm.egg-info/SOURCES.txt' writing manifest file 'lltm.egg-info/SOURCES.txt' installing library code to build/bdist.linux-x86_64/egg running install_lib running build_ext building 'lltm' extension gcc -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I~/local/miniconda/lib/python3.6/site-packages/torch/lib/include -I~/local/miniconda/lib/python3.6/site-packages/torch/lib/include/TH -I~/local/miniconda/lib/python3.6/site-packages/torch/lib/include/THC -I~/local/miniconda/include/python3.6m -c lltm.cpp -o build/temp.linux-x86_64-3.6/lltm.o -DTORCH_EXTENSION_NAME=lltm -std=c++11 cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++ g++ -pthread -shared -B ~/local/miniconda/compiler_compat -L~/local/miniconda/lib -Wl,-rpath=~/local/miniconda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/lltm.o -o build/lib.linux-x86_64-3.6/lltm.cpython-36m-x86_64-linux-gnu.so creating build/bdist.linux-x86_64/egg copying build/lib.linux-x86_64-3.6/lltm_cuda.cpython-36m-x86_64-linux-gnu.so -\u003e build/bdist.linux-x86_64/egg copying build/lib.linux-x86_64-3.6/lltm.cpython-36m-x86_64-linux-gnu.so -\u003e build/bdist.linux-x86_64/egg creating stub loader for lltm.cpython-36m-x86_64-linux-gnu.so byte-compiling build/bdist.linux-x86_64/egg/lltm.py to lltm.cpython-36.pyc creating build/bdist.linux-x86_64/egg/EGG-INFO copying lltm.egg-info/PKG-INFO -\u003e build/bdist.linux-x86_64/egg/EGG-INFO copying lltm.egg-info/SOURCES.txt -\u003e build/bdist.linux-x86_64/egg/EGG-INFO copying lltm.egg-info/dependency_links.txt -\u003e build/bdist.linux-x86_64/egg/EGG-INFO copying lltm.egg-info/top_level.txt -\u003e build/bdist.linux-x86_64/egg/EGG-INFO writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt zip_safe flag not set; analyzing archive contents... __pycache__.lltm.cpython-36: module references __file__ creating 'dist/lltm-0.0.0-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it removing 'build/bdist.linux-x86_64/egg' (and everything under it) Processing lltm-0.0.0-py3.6-linux-x86_64.egg removing '~/local/miniconda/lib/python3.6/site-packages/lltm-0.0.0-py3.6-linux-x86_64.egg' (and everything under it) creating ~/local/miniconda/lib/python3.6/site-packages/lltm-0.0.0-py3.6-linux-x86_64.egg Extracting lltm-0.0.0-py3.6-linux-x86_64.egg to ~/local/miniconda/lib/python3.6/site-packages lltm 0.0.0 is already the active version in easy-install.pth Installed ~/local/miniconda/lib/python3.6/site-packages/lltm-0.0.0-py3.6-linux-x86_64.egg Processing dependencies for lltm==0.0.0 Finished processing dependencies for lltm==0.0.0 此外，使用 pip list 或者 conda list 查看包列表时，可以找到对应的包已经安装了，并且有对应的版本信息以及来源等 ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:3:2","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["学习笔记"],"content":"3. 如何通过python调用编译好的扩展/操作？ 在上述操作完成后，虽然python/conda环境下已经有了相对应的库，但通过python进行import 是会报错的，如下 undefined symbol: _ZTIN3c1021AutogradMetaInterfaceE 原因是编译好的包还需要进一步封装才能在python中调用，具体做法如下： 在setup.py 相同路径下新建一个py文件，内容为： from torch.autograd import Function import torch import test_cpp class _TestFunction(Function): @staticmethod def forward(ctx, x, y): \"\"\" It must accept a context ctx as the first argument, followed by any number of arguments (tensors or other types). The context can be used to store tensors that can be then retrieved during the backward pass.\"\"\" return test_cpp.forward(x, y) @staticmethod def backward(ctx, gradOutput): gradX, gradY = test_cpp.backward(gradOutput) return gradX, gradY # 封装成一个模块（Module） class Test(torch.nn.Module): def __init__(self): super(Test, self).__init__() def forward(self, inputA, inputB): return **_TestFunction.apply**(inputA, inputB) 可以看到，主要就是继承pytorch中的父类，新建对应的类，进而做了一些接口上的封装，具体就是使用 torch.autograd.Function 来将这个扩展写成一个函数，方便在构建网络的时候调用。最后就在合适的地方使用Function.apply(*args) ，就完成了一个自定义扩展了！ ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:3:3","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["学习笔记"],"content":"注意 ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:4:0","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["学习笔记"],"content":"1. 关于C++底层代码的编写，有两种方案 第一种形式，用pytorch/extension 的库，也就是ATen，加速效果尚好，需要以类似at::sigmoid的形式将pytorch的接口API复现一遍 Pytorch学习 (二十一) ——自定义C++/ATen扩展_Hungryof的专栏-CSDN博客 效果展示 python Forward: 187.719 us | Backward 410.815 us extension Forward: 149.802 us | Backward 393.458 us 第二种形式，使用自定义的cuda kernels来进一步加速，详见 Custom C++ and CUDA Extensions Custom C++ and CUDA Extensions - PyTorch Tutorials 1.7.1 documentation ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:4:1","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["学习笔记"],"content":"2. 关于 setup.py python库打包分发的详细攻略（setup.py编写）见 程序包的打包和分发 ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:4:2","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["学习笔记"],"content":"3. 关于扩展包的封装 注意一定要有前向传播和反向传播的定义 实现torch.autograd.Function 子类时，注意其前向传播和反向传播，都需要有ctx参数 大体上来说就是，这个 ctx 变量会在前向传播时，保存一些涉及到计算梯度的信息，然后在反向传播时辅助计算梯度，如 class Sigmoid(Function): @staticmethod def forward(ctx, x): output = 1 / (1 + torch.exp(-x)) ctx.**save_for_backward**(output) return output @staticmethod def backward(ctx, grad_output): output, = ctx.**saved_tensors** grad_x = output * (1 - output) * grad_output return grad_x 前向传播的输入参数和反向传播的输出参数数量必须一致 如果有些变量不需要求导，就直接返回None即可 ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:4:3","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["学习笔记"],"content":"4. 关于梯度计算的验证 pytorch提供了torch.autograd.gradcheck() 函数来检测计算的梯度是否合理 如上述的sigmoid梯度计算，可以通过如下代码检验 # tensor([-0.4646, -0.4403, 1.2525, -0.5953], requires_grad=True) test_input = torch.randn(4, requires_grad=True) torch.autograd.gradcheck(Sigmoid.apply, (test_input,), eps=1e-3) # pass torch.autograd.gradcheck(torch.sigmoid, (test_input,), eps=1e-3) # pass torch.autograd.gradcheck(Sigmoid.apply, (test_input,), eps=1e-4) # fail torch.autograd.gradcheck(torch.sigmoid, (test_input,), eps=1e-4) # fail 我们发现：eps 为 1e-3 时，我们编写的 Sigmoid 和 torch 自带的 builtin Sigmoid 都可以通过梯度检查，但 eps 下降至 1e-4 时，两者反而都无法通过。而一般直觉下，计算数值梯度时， eps 越小，求得的值应该更接近于真实的梯度。这里的反常现象，是由于机器精度带来的误差所致：test_input的类型为torch.float32，因此在 eps 过小的情况下，产生了较大的精度误差（计算数值梯度时，eps 作为被除数），因而与真实精度间产生了较大的 gap。将test_input换为float64的 tensor 后，不再出现这一现象。这点同时提醒我们，在编写backward时，要考虑的数值计算的一些性质，尽可能保留更精确的结果 test_input = torch.randn(4, requires_grad=True, **dtype=torch.float64**) # tensor([-0.4646, -0.4403, 1.2525, -0.5953], dtype=torch.float64, requires_grad=True) torch.autograd.gradcheck(Sigmoid.apply, (test_input,), eps=1e-4) # pass torch.autograd.gradcheck(torch.sigmoid, (test_input,), eps=1e-4) # pass torch.autograd.gradcheck(Sigmoid.apply, (test_input,), eps=1e-6) # pass torch.autograd.gradcheck(torch.sigmoid, (test_input,), eps=1e-6) # pass 具体介绍见 PyTorch 源码解读之 torch.autograd ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:4:4","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["学习笔记"],"content":"5. 关于运行设备 由于Pytorch的C++库 ATen可以同时适用于CPU和GPU，所以只需要传给封装好的函数对应cuda形式的张量，就可以调用GPU加速运算了 ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:4:5","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["学习笔记"],"content":"6. 关于torch.utils.cpp_extension.load() 实时编译扩展库 这种方式调用pytorch中的api，是一种动态编译和加载扩展的方式 代码如下 from torch.utils.cpp_extension import load lltm_cpp = load(name=\"lltm_cpp\", sources=[\"lltm.cpp\"]) Custom C++ and CUDA Extensions - PyTorch Tutorials 1.7.1 documentation ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:4:6","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["学习笔记"],"content":"参考 https://zhuanlan.zhihu.com/p/100459760 ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:5:0","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["编程算法"],"content":"Python中对象的一些基础操作，赋值、拷贝等。 前文链接： Python还债日记之对象(一) ","date":"2021-01-02","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/:0:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(二)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/"},{"categories":["编程算法"],"content":"1. 对象的操作之对比 python中有两种对变量的比较方式，分别是 == 以及调用 is 关键词，不同点在于： == 只比较两个变量的值是否相等，相等则返回True is 则即比较两个变量值，又比较两个变量地址，都相等才返回True is等同于调用id判断地址是否相等，再和操作==判断值是否相等相与 ","date":"2021-01-02","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/:1:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(二)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/"},{"categories":["编程算法"],"content":"2. 对象的操作之赋值 个人理解，在python中，赋值就是将对象的地址通过引用的方式传递给变量，同时对象的引用次数加1 赋值的内在操作是地址的传递，这个地址指对象个体的地址，而不是子对象地址 赋值操作具有以下几点特征： 赋值与被赋值的两个对象，在python中可以认为是完全一样的，用一个变量给另一个变量赋值，其实就是给当前内存中的对象增加一个“标签”而已 \u003e\u003e\u003e a = (11) \u003e\u003e\u003e print(id(a)) 10914816 \u003e\u003e\u003e b = a \u003e\u003e\u003e print(id(b)) 10914816 \u003e\u003e\u003e b is a True 对于可变对象，如List，赋值时不需要重新开辟空间（因为可变对象是可变的，赋值时相当于给对象添加了一个新的标签） 对于不可变对象，如Tuple、Set等，在赋值时需要开辟新的空间（因为需要破坏原有的引用，将变量的引用指向新的对象）但是python中的小对象整数池、短字符串缓冲区需要特殊考虑 对于可变对象，b是a的赋值，那么改变b的值，或者改变b的值，都会更新另外一方的值 ","date":"2021-01-02","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/:2:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(二)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/"},{"categories":["编程算法"],"content":"3. 对象的操作之拷贝 拷贝操作有两种，在python中，只拷贝浅层对象的操作叫做浅拷贝，递归拷贝所有对象的操作叫做深拷贝 ","date":"2021-01-02","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/:3:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(二)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/"},{"categories":["编程算法"],"content":"3.1 浅拷贝 python中的浅拷贝操作包括：copy 模块的 copy 函数 ，对象的 copy 函数 ，工厂方法，切片等 对于不可变对象，浅拷贝操作是传递引用，相当于赋值 对于可变对象，浅拷贝操作是对浅层对象进行拷贝，子对象不变 这里的浅层对象，对于字典、列表等类型来说，指的就是最外层的对象，也就是列表或者字典本身。可变对象的浅拷贝过程，实际上是在堆区分配了一块新内存，但是这块新内存内部的子对象，依旧是指向原内存中的位置的。 举例说明： 不可变对象的浅拷贝 \u003e\u003e\u003e a = 555 \u003e\u003e\u003e b = a \u003e\u003e\u003e id(a), id(b) (140441428658224, 140441428658224) 因为是赋值的过程，所以内存地址一致，这时如果改变b，相当于一次新的赋值，a不会一起改变 可变对象的浅拷贝 \u003e\u003e\u003e listA = [1, 'a', [1, 2]] \u003e\u003e\u003e listB = listA.copy() \u003e\u003e\u003e print(listA, listB) [1, 'a', [1, 2]] [1, 'a', [1, 2]] \u003e\u003e\u003e id(listA), id(listB) (140441428382344, 140441428382408) \u003e\u003e\u003e id(listA[0]), id(listB[0]) (10914496, 10914496) 因为是拷贝后的变量listB是新开辟的内存，所以listA与listB内存地址不一致 这时如果改变listB，情况分为两种： 添加、删除或改动不可变对象，listA都不会随着改变 改动可变对象，listA会一起改变，比如在listB中第二个位置，向列表[1, 2]中添加一个元素，那么listA也会改变 ","date":"2021-01-02","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/:3:1","tags":["python","Coding","对象"],"title":"Python还债日记之对象(二)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/"},{"categories":["编程算法"],"content":"3.2 深拷贝 Python中的深拷贝操作，只有copy模块的 deepcopy 函数 深拷贝也可以理解成递归拷贝，在Python中，深拷贝对于子对象中的可变对象进行复制，而不可变对象则沿用之前的引用。 深拷贝的最终结果就是，即使改变原来的变量，新变量也不会改变，二者互不影响 \u003e\u003e\u003e import copy \u003e\u003e\u003e a = [1, 'a', [1, 2]] \u003e\u003e\u003e b = copy.deepcopy(a) \u003e\u003e\u003e print(a, b) [1, 'a', [1, 2]] [1, 'a', [1, 2]] \u003e\u003e\u003e b[2].append(0) \u003e\u003e\u003e print(a, b) [1, 'a', [1, 2]] [1, 'a', [1, 2, 0]] ","date":"2021-01-02","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/:3:2","tags":["python","Coding","对象"],"title":"Python还债日记之对象(二)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/"},{"categories":["编程算法"],"content":"4. 传值还是传引用？ 在函数传参时，我们都知道基本的参数传递机制有两种，传值以及传引用。我们先梳理一下传值以及传引用的异同，然后再分析python中是传值还是传引用。 首先回顾一下形参与实参的区别，形参是指被调用的函数的形式参数，其作为函数内部的局部变量。实参是指调用函数时，实际传递的参数。函数会在其对应的堆栈中开辟一块空间，来存放传递进来的实参的值。在这个过程中，值传递的特点是，对于形参的任何操作，都不会改变传递进来的实参的值。而引用传递，传递的是实参的引用，也可以理解为地址，即形参和实参指向同一个地址，这时改变形参，实参的值也会发生改变。 对于python中，前面我们分析了，由于其动态语言的特性，python中的变量都是引用，所以调用函数时，传递的都是引用！但是如果我们从改变形参实参是否发生改变的角度来分析，python中存在可变和不可变对象，所以对于不可变对象，形参改变，相当于重新开辟了空间以及再次进行引用的传递，并不会改变实参，相当于传值。对于可变对象，形参改变，指向的原对象也会改变，所以相当于传引用！ 总结一下： 从传递参数自身的性质来分析，python属于传引用 从形参与实参的关系来分析，python中不可变对象是传值，可变对象是传引用 ","date":"2021-01-02","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/:4:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(二)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/"},{"categories":["编程算法"],"content":"5. 总结 不可变对象在赋值时会开辟新空间 可变对象进行赋值前后，改变一个，另外一个也会改变 深浅拷贝对于不可变对象进行拷贝时，不开辟新空间，相当于赋值操作 浅拷贝拷贝的是浅层对象，深拷贝才会递归拷贝所有子对象（只针对可变对象才进行新建操作，直到最后所有对象都是不可变为止） python默认使用的是浅拷贝，因为其速度快、占用空间小、效率高 python中的传值还是传引用，要辩解地分析，可变与不可变对象，其传递过程的本质不同。 ","date":"2021-01-02","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/:5:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(二)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/"},{"categories":["编程算法"],"content":"6. 参考 https://mp.weixin.qq.com/s/VVKq40A4H6u4gFC1yoMB_w Python FAQ1：传值，还是传引用？ ","date":"2021-01-02","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/:6:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(二)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/"},{"categories":["编程算法"],"content":"Python中对象的概念与分类，包括对象与引用、变量之间的联系，可变对象与不可变对象的区分。 ","date":"2021-01-01","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/:0:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(一)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/"},{"categories":["编程算法"],"content":"1. 关于python中的对象 Python中万物皆对象 这是一个很通俗的说法，但却十分准确，python用对象的概念来解释程序中的元素，比如整数、字符串、元组等。甚至，表示对象类型的方法type也是一个对象。 ","date":"2021-01-01","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/:1:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(一)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/"},{"categories":["编程算法"],"content":"2. 对象、引用与变量 对象在创建时，Python解释器会为其分配内存空间，如果对象的值被传递给了一个变量，那么该变量就会通过引用的方式使用该对象，这时也可以称为，变量是对对象的引用。 ","date":"2021-01-01","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/:2:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(一)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/"},{"categories":["编程算法"],"content":"3. 对象的内存地址 其实在python中，变量的地位很尴尬，因为python动态语言的特性以及万物皆对象的特性，导致变量往往都是对对象的引用。这时变量与对象可以被理解成两部分，在存储时，二者也是分开的。变量代表着对象的地址，存储在栈区，而对象的实际内容存储在堆区。我们可以通过id()来获取对象或者说变量在堆区中的内存地址。也可以理解成返回当前对象在其生命周期内独一无二的标识符。 下图可以很好地说明在python中对象与变量的存储方式，以及堆区和栈区的内存分配。 栈区： 栈区存放真实的对象，当新对象创建时，堆区中就会被开辟出一块新的内存地址分配给这个新的对象。 此外，python还为一些特殊的数据独立分配了特定的空间，分别是小对象整数池、匿名列表、字典对象缓冲区以及短字符串缓冲区。这样做的原因在后文会详细说明，总结来说就是，为不可变对象（小整数、字符串）以及匿名对象（未赋值的字典和列表）提供一个固定的地址。 栈区： 栈区存放的是前面说的，地位很尴尬的变量，下图可以看到，变量A、B、C、D其实表示的是堆区对象的引用，其本身存放的也不是对象的值，而是对象在堆区的地址。可以通过id方法获取变量指向对象的地址 栈区和堆区之间，从对象指向变量的，就是引用 注意： 变量在栈中的地址与变量自身存储的地址是不同的，注意区分 可以思考下，变量与对象之间的关系是一一对应的么？ ","date":"2021-01-01","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/:3:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(一)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/"},{"categories":["编程算法"],"content":"4. 对象的类型 python中的对象都存储在堆区，但是其类型却不尽相同，根据是否可变，我们将对象分为可变对象和不可变对象。 注意：这里的可变与不可变，指的是变量指向的内存地址是否可以改变，如果指向一个对象地址的变量可以被修改，那么该对象就是可变的 ","date":"2021-01-01","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/:4:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(一)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/"},{"categories":["编程算法"],"content":"4.1 不可变对象 不可变对象，就是无法修改的对象，我们无法在内存中直接修改这个变量。必须断开原来的引用，才可以使这个变量拥有新的值。 所以在python中，当我们尝试修改不可变类型的值，比如初始化a = 5，然后再改变a的值，a = 4，这时，由于指向对象5的地址是不可变的，所以对象5到a的引用会断开，然后一个新的对象4的引用会分配给该变量。这个过程前后，变量a虽然没有改变变量名称，但是其指向的对象地址发生了变化，如果调用id()方法也可以证明这一点。 \u003e\u003e\u003e a = 5 \u003e\u003e\u003e id(a), id(5) 10914624, 10914624 \u003e\u003e\u003e a = 4 \u003e\u003e\u003e id(a), id(4) 10914592, 10914592 在Python中， 常见的不可变对象有： int float bool tuple string 再强调一遍，以上五种类型之所以被称为不可变对象，是因为一旦变量与对象通过引用绑定之后，再想修改变量的值，只能通过解除引用、重新引用的方式。所以我们可以发现，对于不可变对象，如果变量的值不同，其对应对象一定不同，同一个变量修改内容后，其指向的对象也一定是改变了的。 ","date":"2021-01-01","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/:4:1","tags":["python","Coding","对象"],"title":"Python还债日记之对象(一)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/"},{"categories":["编程算法"],"content":"4.2 特殊不可变对象 如果两个变量的值相同，那么他们在堆中的地址一定一样么？答案是不一定 再放一下关于对象存储在堆区中的图 python中关于对象的存储，有几处特殊的空间，这里只说两处，分别是短字符串缓冲区以及小对象整数池。二者的作用是，当字符串的长度较短或者是整数的数值较小时，python会将值相同的变量分配相同的引用，换句话说，值相同的变量指向相同的对象。 小对象整数池的作用范围是(-5, 256)，在这范围内的整数，只要值相同，堆中的内存地址也相同 \u003e\u003e\u003e a = 5 \u003e\u003e\u003e b = 5 \u003e\u003e\u003e id(a), id(b) 10914624, 10914624 \u003e\u003e\u003e a = 555 \u003e\u003e\u003e b = 555 \u003e\u003e\u003e id(a), id(b) 140122211533680, 140122211533712 短字符串指的是没有空格的字符串，不带空格的字符串，只要内容相同，其在堆中的地址就一致 \u003e\u003e\u003e a = 'dddddddddddddddddddddddddddddddddd' \u003e\u003e\u003e b = 'dddddddddddddddddddddddddddddddddd' \u003e\u003e\u003e id(a), id(b) 140599787760344, 140599787760344 \u003e\u003e\u003e a = 'a b' \u003e\u003e\u003e b = 'a b' \u003e\u003e\u003e id(a), id(b) 140599787781456, 140599787781400 ","date":"2021-01-01","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/:4:2","tags":["python","Coding","对象"],"title":"Python还债日记之对象(一)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/"},{"categories":["编程算法"],"content":"4.3 可变对象 明白了不可变对象的定义之后，可变对象的定义也就很清楚了，对于一个变量和其绑定的对象，如果是可变的，那么修改变量可以通过直接改变变量指向的堆中的内存地址来实现，不需要破坏对象与变量之间的引用。 在Python中，常见的可变对象有： list dict set 对于这三种可变对象，不管值是否相同，不同变量对应堆中的内存地址一定不同，同一变量对应的内存地址一定不变。 \u003e\u003e\u003e a = [1] \u003e\u003e\u003e b = [1] \u003e\u003e\u003e id(a) 140176052670856 \u003e\u003e\u003e id(b) 140176052699720 ","date":"2021-01-01","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/:4:3","tags":["python","Coding","对象"],"title":"Python还债日记之对象(一)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/"},{"categories":["编程算法"],"content":"4.4 特殊可变对象 依旧是这张图 对于可变对象，python中也有一些特殊的情况，比如匿名的可变对象。所以python同样给匿名的列表和字典对象准备了特殊待遇，对于这两类匿名对象，其在堆中的内存地址是一样的。（注，匿名表示的就是没有被赋值的对象，也可以理解为对象没有被变量引用） \u003e\u003e\u003e id([1, 2, 3]), id([1, 2, 3]) 139883205481032, 139883205481032 \u003e\u003e\u003e id({'a': 1}), id({'a': 1}) 139883230991992, 139883230991992 ","date":"2021-01-01","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/:4:4","tags":["python","Coding","对象"],"title":"Python还债日记之对象(一)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/"},{"categories":["编程算法"],"content":"5. 总结 本文内容总结如下： Python是一门动态语言 Python中万物皆对象 Python中变量存储的是对象的引用 Python中对象可以分为可变对象与不可变对象 对于不可变对象，小整数、短字符串以及布尔值这三类，只要值相同，那么变量指向的地址就相同，其余类型则值相同、地址也不同 对于可变对象，单个变量的值无论怎么改变，其内存地址都不变，但是多个变量的值就算相同，其内存地址也不同 ","date":"2021-01-01","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/:5:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(一)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/"},{"categories":["编程算法"],"content":"6. 参考 python3中各类变量的内存堆栈分配和函数传参区别实例详解 Python内存管理中的堆和栈以及id，is，== 的区别和使用 ","date":"2021-01-01","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/:6:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(一)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/"},{"categories":["系统装机"],"content":" 记录安装docker的过程。 nvidia-docker2已经弃用，现在都是装nvidia-container-toolkit 清除旧版本 sudo apt-get remove docker docker-engine docker-ce docker.io sudo rm -rf /var/lib/docker dpkg -l | grep docker sudo apt-get purge docker-ce 更新apt-get sudo apt-get update 安装添加使用 HTTPS 传输的软件包 sudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common 添加软件源的GPG密钥—清华源 curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository \"deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs)stable\" 更新apt-get，安装docker sudo apt-get update sudo apt-get install docker-ce 查看docker版本 docker version 这里docker安装初步完成，可以使用docker hello-world测试，如果出现权限问题报错，可以尝试如下方法： # 添加一个docker属组（如果没有） sudo groupadd docker # 将用户加入该group中，退出并重新登陆 sudo gpasswd -a ${USER} docker # 重启docker服务 sudo service docker restart # 切换当前会话到新group或重启会话 newgrp - docker 接下来安装深度学习相关的环境，首先安装docker-nvidia 参考官网git # Add the package repositories distribution=$(. /etc/os-release;echo $ID$VERSION_ID) curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list sudo apt-get update \u0026\u0026 sudo apt-get install -y nvidia-container-toolkit sudo systemctl restart docker 安装nvidia-container-runtime 参考官网git sudo apt-get install nvidia-container-runtime sudo mkdir -p /etc/systemd/system/docker.service.d sudo tee /etc/systemd/system/docker.service.d/override.conf \u003c\u003cEOF [Service] ExecStart= ExecStart=/usr/bin/dockerd --host=fd:// --add-runtime=nvidia=/usr/bin/nvidia-container-runtime EOF sudo systemctl daemon-reload sudo systemctl restart docker sudo tee /etc/docker/daemon.json \u003c\u003cEOF { \"runtimes\": { \"nvidia\": { \"path\": \"/usr/bin/nvidia-container-runtime\", \"runtimeArgs\": [] } } } EOF sudo pkill -SIGHUP dockerd sudo dockerd --add-runtime=nvidia=/usr/bin/nvidia-container-runtime [...] 修改镜像和容器的存放路径 指定镜像和容器存放路径的参数是–graph=/var/lib/docker，我们只需要修改配置文件指定启动参数即可。Docker 的配置文件可以设置大部分的后台进程参数，在各个操作系统中的存放位置不一致，在 Ubuntu 中的位置是：/etc/default/docker，在 CentOS 中的位置是：/etc/sysconfig/docker 打开/etc/default/docker sudo gedit /etc/default/docker # 如果是 CentOS 则添加下面这行： OPTIONS=--graph=\"/root/data/docker\" --selinux-enabled -H fd:// # 如果是 Ubuntu 则添加下面这行（因为 Ubuntu 默认没开启 selinux）： OPTIONS=--graph=\"/root/data/docker\" -H fd:// # 或者 DOCKER_OPTS=\"-g /root/data/docker\" 最后重新启动，service docker restart 通过docker info 查看 Docker 的路径是否改成 /root/data/docker 如果没有生效，按如下操作 mkdir -p /etc/systemd/system/docker.service.d cat /etc/systemd/system/docker.service.d/Using_Environment_File.conf 如果没有该文件则自行创建，添加以下内容 [Service] EnvironmentFile=-/etc/default/docker ExecStart= ExecStart=/usr/bin/docker daemon -H fd:// $DOCKER_OPTS 载入配置重启服务 systemctl daemon-reload service docker restart 修改为阿里的镜像仓库 # 这里我在注册阿里云之后，将镜像仓库更改为阿里的云仓库，使用如下命令 sudo tee /etc/docker/daemon.json \u003c\u003c-'EOF' \u003e { \u003e \"registry-mirrors\": [\"https://b68wbkqs.mirror.aliyuncs.com\"] \u003e } \u003e EOF ","date":"2020-09-26","objectID":"/%E5%AE%89%E8%A3%85docker/:0:0","tags":["docker"],"title":"docker安装记录","uri":"/%E5%AE%89%E8%A3%85docker/"},{"categories":["论文阅读"],"content":"《Leveraging_Shape_Completion_for_3D_Siamese_Tracking》论文\u0026代码阅读 ","date":"2020-06-26","objectID":"/00-sc3d/:0:0","tags":["论文阅读"],"title":"论文阅读00 SC3D","uri":"/00-sc3d/"},{"categories":["论文阅读"],"content":"简介 作者：Silvio Giancola, Jesus Zarzar*, and Bernard Ghanem* 机构：King Abdullah University of Science and Technology (KAUST) 论文水平：CVPR19 关键词：Shape Completion \u0026\u0026 Siamese Tracker \u0026\u0026 Model Update 代码 | 视频 ","date":"2020-06-26","objectID":"/00-sc3d/:1:0","tags":["论文阅读"],"title":"论文阅读00 SC3D","uri":"/00-sc3d/"},{"categories":["论文阅读"],"content":"论文摘要 本文提出了一种基于形状补全网络以及孪生网络的单目标跟踪器，借鉴了《Learning representations and generative models for 3d point clouds 》这篇论文的思想，将形状补全网络中的自编码器融入到孪生网络的框架中，使用自编码器的编码结构作为孪生网络的特征提取网络，通过编码之后解码这一过程将形状补全损失加入进来，训练编码器网络，使其编码的特征带有形状信息，更好的用于孪生网络的匹配。 ","date":"2020-06-26","objectID":"/00-sc3d/:2:0","tags":["论文阅读"],"title":"论文阅读00 SC3D","uri":"/00-sc3d/"},{"categories":["论文阅读"],"content":"论文解读 ","date":"2020-06-26","objectID":"/00-sc3d/:3:0","tags":["论文阅读"],"title":"论文阅读00 SC3D","uri":"/00-sc3d/"},{"categories":["论文阅读"],"content":"1. 网络框架 如图所示，整体的网络架构分为两部分， 分别是自编码器网络和孪生网络，自编码器就是将输入编码再解码得到形状更加丰富的点云, 孪生网络就是使用编码器的输出向量计算相似度. 网络的具体描述如下: 自编码器网络是借鉴形状补全网络的思想，对输入的一组模板点云(Model Shape)以及一组搜索点云(Candidate Shapes)进行编码(Φ)和解码(Ψ)，二者组成了自编码器。实际上，代码中作者只用了三层一维卷积作为编码器，将输入的(B, 3, 2048)维度的点云编码为(1, 128)维度的向量形式的潜在表述，进而通过两层的全连接层，将(1, 128)的向量输出为(1, 6144), 进而reshape为(3, 2048)作为解码器的输出。使用自编码器的作用在于，通过训练，构建形状补全损失(Shape Completion Loss)，进而让网络学习如何通过自编码来得到相对于输入点云的更好的形状表述，同时让编码器编码得到的向量拥有点云的几何形状信息， 也让解码器解码得到的点云对应的 bbox 更加精准。 编码器产生的带有形状信息的向量也对后面的孪生网络计算相似度有帮助。 孪生网络在本文中由两个编码器网络组成，输入的两组点云通过相同的编码器网络，输出两个代表着潜在几何信息的向量，对这两个向量进行相似度度量，就可以得到相似度最大的 Candidate pc，本文使用的是余弦相似度，孪生网络对应的跟踪损失是均方差损失(MSE Loss)。 这里还有一点要说明的是，因为本论文的主要目的是做跟踪，所以作者强调网络的主要结构是孪生网络，自编码网络只是帮助孪生网络的相似度计算更加精准。 ","date":"2020-06-26","objectID":"/00-sc3d/:3:1","tags":["论文阅读"],"title":"论文阅读00 SC3D","uri":"/00-sc3d/"},{"categories":["论文阅读"],"content":"2. 模型的训练 Example of model completion 输入输出分别是什么? 在训练阶段，网络的两个输入维度都是(1, 3, 2048)，经过 model 得到的输出是 当前搜索点云与模板点云的相似度: 其实也就是孪生网络的输出, 用来计算相似度损失 自编码之后的点云: 自编码器的输出, 输出维度也是(3, 2048), 可以用来计算形状补全损 输入的模板点云与搜索点云如何确定? Model Shape 是一个特定的 track_id 对应的所有帧的点云级联而成，级联之后还需要下采样到2048个点，以和模型的输入尺寸对齐，进而作为这一次训练的模板点云。 Candidate Shapes 则是在某一帧的真值框附近根据 Kalman filter 采样生成的一定数量的候选框内的点云，比如当前帧是1，采样数量是125，那么输入给 data_loader 的参数就会是 0-124 之间， 如果输入57，代表的就是在第一帧点云真值框附近，采样得到的第58个框，框中对应的点云作为这一次训练的搜索点云。 👉🏿 Loss是如何定义的? 在SC3D中, 总体的loss包括两部分, 第一个就是计算编码向量之间的相似度, 进而求得的相似度损失，这里其实就是典型的孪生网络结构，用两个编码器作为特征提取的网络，计算得到的向量之间的相似度，值得一提的是，本文在训练阶段使用的模板点云是一个序列所有帧级联之后下采样得到的点云，这样得到的点云形状信息更加完整，相比于以往的使用孪生网络跟踪的方法，这种方式可以尝试下，个人感觉应该能一定程度上解决三维点云感知中点云稀疏性带来的问题。(因为相当于训练时模板信息较为丰富，特征较为完整，进而提高搜索点云与模板点云之间的相似度) 第二个损失是算模型的形状完成损失，作者想让自编码器网络具有能够补全输入点云的形状的能力, 那么就需要在训练阶段通过监督信号不断纠正网络的学习结果, 让网络能够学习到足够匹配的参数, 进而达到形状补全的目的, 所以这里作者加了一个形状补全损失, 用来让模型拥有补全形状的能力。 在做 loss 回传时，取两种损失的加权和，如下： loss = loss1 + lambda_completion * loss2 ","date":"2020-06-26","objectID":"/00-sc3d/:3:2","tags":["论文阅读"],"title":"论文阅读00 SC3D","uri":"/00-sc3d/"},{"categories":["论文阅读"],"content":"4. 模型的测试 输入输出分别是什么? 与训练不同，测试阶段模型的输入是一组数据，前文也提到了测试数据集的构建以及搜索框的生成策略，测试阶段是将生成的一组 Candidate PCs 级联到一起，Model PC则是根据不同的策略更新之后，与 Candidate PCs 的维度对齐(其实就是将 Model PC 重复了若干次)，所以将这两组数据一起输入给网络。 输出得到的相似度得分同样是一组，在这一组得分中选择分数最高的，根据对应的id找到在 Candidate Boxes 中的Bbox， 作为当前帧的搜索结果，这样就完成了一次测试的过程。 输入的模板点云与搜索点云如何确定? 在测试阶段，第一帧的 Model Shape 是由真值得到的，并且只有一帧的数据，在后续帧中不断融合新的信息，这里的数据融合分为两种思路，要么融合点云，要么融合编码之后的向量，作者提出融合 latent vector 会降低内存的消耗，但是论文给出的测试数据显然融合点云更为精准。对于融合之后如何更新模板点云，可以选定第一帧、选定前一帧或者选定前面所有帧进行级联，如果选择融合向量，同样有不同的融合方案，详见代码 Candidate Shapes 的选择同样也有几种不同的方案，因为作者提出的更新搜索空间的方式，是基于某一帧的bbox，在其周围根据不同的方式(KalmanFilteringr / GaussianMixtureModel / ParticleFiltering / ExhaustiveSearch) 生成若干个 *Candidate boxes，*而这个bbox的选取也有三种方式，分别是取前一帧的跟踪结果，前一帧的真值以及当前帧的真值来计算 *Candidate boxes，*详见代码 测试结果如何得到？ 得到相似度向量，取得分最高的 id，就可以找到在搜索点云中对应的 id，这样就可以把这个 id 对应的 bbox 作为最终的跟踪结果。 ","date":"2020-06-26","objectID":"/00-sc3d/:3:3","tags":["论文阅读"],"title":"论文阅读00 SC3D","uri":"/00-sc3d/"},{"categories":["论文阅读"],"content":"代码阅读 ","date":"2020-06-26","objectID":"/00-sc3d/:4:0","tags":["论文阅读"],"title":"论文阅读00 SC3D","uri":"/00-sc3d/"},{"categories":["论文阅读"],"content":"1. class kittiDataset() getSceneID(self, split): 针对 Kitti 数据集的 tracking下的序列，将 train下的 00-16 作为了训练集， 17-18作为验证集，19-20作为测试集 getListOfAnno(self, sceneID, category_name=“Car”): 获取 scene 列表，然后遍历每一个 scene，得到对应的label 先通过 pandas 读取label，存为 Dataframe格式 label_file = os.path.join(self.KITTI_label, scene + \".txt\") #读取标签txt文件 df = pd.read_csv( label_file, sep=' ', names=[ \"frame\", \"track_id\", \"type\", \"truncated\", \"occluded\", \"alpha\", \"bbox_left\", \"bbox_top\", \"bbox_right\", \"bbox_bottom\", \"height\", \"width\", \"length\", \"x\", \"y\", \"z\", \"rotation_y\" ]) 筛选出当前跟踪的类别 df = df[df[\"type\"] == category_name] # 筛选出类别是car的标签 在label中插入 scene df.insert(loc=0, column=\"scene\", value=scene) # 在标签中插入一列表示这是哪个场景 遍历 Dataframe 中的每一个 id，将所有帧的label 根据不同的 track_id 进行存储 for track_id in df.track_id.unique(): # 找到所有属于当前id的数据,保留下来 df_tracklet = df[df[\"track_id\"] == track_id] # 因为行标签(行号)在前面的筛选中错乱了,这里重置一下,避免不必要的错误 # drop=True: 把原来的索引index列去掉，丢掉。 # drop=False: 保留原来的索引（以前的可能是乱的） df_tracklet = df_tracklet.reset_index(drop=True) # 使用df_tracklet.iterrows() 来进行迭代的生成, 返回值是对应的行号以及标签,这里舍弃行号,只保留了标签信息 tracklet_anno = [anno for index, anno in df_tracklet.iterrows()] # 再存进列表中 list_of_tracklet_anno.append(tracklet_anno) 注意：这里遍历结束之后,因为循环时是取 df.track_id.unique() 中的元素, 其没有固定的排列顺序,所以得到的 list_of_tracklet_anno 的索引,与track_id没什么关系 getBBandPC(self, anno): 根据传入的label标签，得到calib文件，以及对应的 transf_mat 根据 anno 和 transf_mat 读取对应的点云以及 box getPCandBBfromPandas(self, anno, calib): 根据 label 以及 transf_mat 矩阵（传入的calib实际上就是 transf_mat 矩阵）得到整帧点云和box 这里将点云和box抽象成了两个类，将读取到的数据以这两个类的形式存储，便于后面处理 PointCloud 类 通过点云数据创建，点云的shape是（4，n）注意这里直接将点云进行了transform，坐标系变换为相机坐标系 velodyne_path = os.path.join(self.KITTI_velo, anno[\"scene\"], '%06d.bin'%(anno[\"frame\"])) #f'{box[\"frame\"]:06}.bin') #从点云的.bin文件中读取点云数据并且转换为4*x的矩阵，且去掉最后的一行的点云的密度表示数据 PC = PointCloud( np.fromfile(velodyne_path, dtype=np.float32).reshape(-1, 4).T) #将点云转换到相机坐标系下　因为label中的坐标和h,w,l在相机坐标系下的 PC.transform(calib) Box 类 通过（center，size，orientation）创建，这里将读取到 yaw角转换成了四元数 center = [anno[\"x\"], anno[\"y\"] - anno[\"height\"] / 2, anno[\"z\"]] size = [anno[\"width\"], anno[\"length\"], anno[\"height\"]] #下面这个函数是将roy角转换成四元数吧 orientation = Quaternion( axis=[0, 1, 0], radians=anno[\"rotation_y\"]) * Quaternion( axis=[1, 0, 0], radians=np.pi / 2) # 用中心点坐标和w,h,l以及旋转角来初始化BOX这个类 BB = Box(center, size, orientation) 注意：kitti数据集的坐标系定义为 y轴向下为正，并且center是底面的中心（向下为正，所以也就是上面的中心） 这里计算center的时候，计算的是box的中心，所以y方向坐标减去了半个高度，也是方便后续corners的计算 Box类中存放了四元数作为角度，也可以调用类中的属性 rotation_matrix 返回对应的角度 Box类中也有返回 corners 坐标的方法，返回（3，8）的坐标值 这里的corners方法，分为以下三步 根据长宽高，建立一个坐标在原点的 box 根据 rotation_matrix 将box旋转对应的角度 根据 center 的坐标将box平移至对应位置，这样就得到了最终的带有角度的corners Box类中还有一些操作，旋转、坐标系变换、平移等 ","date":"2020-06-26","objectID":"/00-sc3d/:4:1","tags":["论文阅读"],"title":"论文阅读00 SC3D","uri":"/00-sc3d/"},{"categories":["论文阅读"],"content":"2. class SiameseDataset(Dataset) list_of_tracklet_anno 装有所有 scene 下的每个track_id 的 label list_of_anno 获取所有标签，不考虑track_id：根据得到的 self**.list_of_tracklet_anno， 不论 id， 把每一帧的数据顺序放入一个列表中，得到 self.list_of_anno， 这里的 self.list_of_anno 就是把 list_of_tracklet_anno 的 shape 从(track_id, frames) 变成 (track_idframes*, ) ","date":"2020-06-26","objectID":"/00-sc3d/:4:2","tags":["论文阅读"],"title":"论文阅读00 SC3D","uri":"/00-sc3d/"},{"categories":["论文阅读"],"content":"3. class SiameseTrain(SiameseDataset) SiameseTrain class SiameseTrain(SiameseDataset): \"\"\" 用来训练SC3D的数据集, 几个重要函数说明如下: __init__ : 初始化各种参数,并且获得list_of_BBs以及list_of_PCs,注意这里的list_of_PCs指的是bbox中的点云,不是整帧点云 __getitem__ : 调用getitem, 这里就是根据传入的index获得对应的训练数据并返回 __len__ : 获取数据集的长度, 这里将实际的长度乘了一个数字, 这个数字是在每一帧的搜索区域周围生成候选区域的数量 几个重要数据说明如下: num_candidates_perframe: [Int]在当前搜索点云框周围生成的候选框的数量 list_of_anno: [List] 存放label的列表, 里面有 track_id*frames 个数据, 按顺序从第一个序列的第一个track_id开始,存放每一帧的label model_PC: [List] 存放模板点云的列表, 里面有 track_id 个PointCloud类的点云数据,将每一个id的所有帧级联在一起作为模板 list_of_PCs: [List] 存放搜索点云的列表, 里面有 track_id*frames 个点云数据, 这里的不是整帧点云,是bbox内的点云 list_of_BBs: [List] 存放label的列表, 里面有 track_id*frames 个label数据,对应label文件中的一行label数据 \"\"\" def __init__(self, model, path, output, split=\"\", category_name=\"Car\", regress=\"GAUSSIAN\", sigma_Gaussian=1, offset_BB=0, scale_BB=1.0): super().__init__( model=model, path=path, split=split, category_name=category_name, regress=regress, offset_BB=offset_BB, scale_BB=scale_BB) self.sigma_Gaussian = sigma_Gaussian self.offset_BB = offset_BB self.scale_BB = scale_BB self.num_candidates_perframe = 147 logging.info(\"preloading PC...\") self.list_of_PCs = [None] * len(self.list_of_anno) self.list_of_BBs = [None] * len(self.list_of_anno) # 遍历,找到每一帧对应的label for index in tqdm(range(len(self.list_of_anno))): anno = self.list_of_anno[index] # NOTE 获取对应的点云和bbox信息,注意这里的点云是整帧点云! PC, box = self.getBBandPC(anno) # 将得到的点云处理,通过bbox,裁剪出在bbox里面的点,这里扩充了点云的边界 new_PC = utils.cropPC(PC, box, offset=10) # NOTE 将所有帧中的bbox以及bbox中的点云存成列表,这里的所有帧指的是不考虑track_id的情况,全部的点云帧 self.list_of_PCs[index] = new_PC self.list_of_BBs[index] = box logging.info(\"PC preloaded!\") logging.info(\"preloading Model..\") # 将一个track_id轨迹中的所有帧的点云汇集到一个bbox下，作为模板点云， 也就是这里的 self.model_PC self.model_PC = [None] * len(self.list_of_tracklet_anno) # 遍历每一个track_id 这里的 len(self.list_of_tracklet_anno) 就是track_id的种类数量 for i in tqdm(range(len(self.list_of_tracklet_anno))): list_of_anno = self.list_of_tracklet_anno[i] PCs = [] BBs = [] cnt = 0 # 遍历同一个track_id下的每一帧 for anno in list_of_anno: #　获取整帧点云以及bbox信息 this_PC, this_BB = self.getBBandPC(anno) PCs.append(this_PC) BBs.append(this_BB) # NOTE model_idx相当于是track_id, 但是不同, 其代表着排序之后的索引,每一个索引对应一个track_id, 但是具体对应哪个id, 随机 anno[\"model_idx\"] = i # reletive_idx相当于是对每一帧进行编号,一个轨迹序列的开始到结束 anno[\"relative_idx\"] = cnt cnt += 1 # 通过这个函数获取模板点云, 模板点云是将同一个track_id的所有点云帧的bbox中的点云级联在一起的 self.model_PC[i] = utils.getModelAndSave(PCs, BBs, offset=self.offset_BB, scale=self.scale_BB, save=True, path=os.path.join(output, category_name), name=category_name + str(i)) logging.info(\"Model preloaded!\") def __getitem__(self, index): return self.getitem(index) def getAnnotationIndex(self, index): # 每一个anno对应num_candidates_perframe个index, 所以需要除以num_candidates_perframe return int(index / self.num_candidates_perframe) def getSearchSpaceIndex(self, index): # 计算搜索空间的id,其实这个id没什么实际意义,如果非零, 那么代表当前这一批的搜索空间的序号 return int(index % self.num_candidates_perframe) def getPCandBBfromIndex(self, anno_idx): this_PC = self.list_of_PCs[anno_idx] this_BB = self.list_of_BBs[anno_idx] return this_PC, this_BB # NOTE 这里传入的index, 实际上取决于构建的数据集的长度,在这个数据集类中,__len__对应的长度是将所有点云帧的长度乘以了 num_candidates_perframe # NOTE num_candidates_perframe的含义就是 \"要生成的候选区域的数量\", 而传入的index就是按照点云帧长度乘以num_candidates_perframe来计算的 # NOTE 所以在通过index计算对应的label以及搜索空间的索引时,需要将index的数值除以 num_candidates_perframe def getitem(self, index): \"\"\"根据index的传入,计算并得到 当前的点云(this_pc)\\候选区域的点云(sample_pc)\\上一帧的点云(gt_pc)\\一整个序列的点云(model_pc) 几个重要的变量说明如下: anno_idx: 搜索点云的id, 通过传入的index计算得到, 用来得到搜索点云的label以及bbox等信息 sample_idx: 搜索空间的id, 用来计算sample_offsets,如果不是0,就需要通过滤波方法计算sample_offsets sample_offsets: 在搜索点云的周围采样一定数量的bbox, 这个offset相当于是一个偏置, 可以根据offset的值来计算当前搜索点云框周围的候选框 \"\"\" # 得到id anno_idx = self.getAnnotationIndex(index) sample_idx = self.getSearchSpaceIndex(index) # 计算得到sample_offsets if sample_idx == 0: sample_offsets = np.zeros(3) else: # PROBLEM 这里如何得到采样偏置的?具体没太看懂 gaussian = KalmanFiltering(bnd=[1, 1, 5]) sample_offsets = gaussian.sample(1)[0] # 搜索点云的label this","date":"2020-06-26","objectID":"/00-sc3d/:4:3","tags":["论文阅读"],"title":"论文阅读00 SC3D","uri":"/00-sc3d/"},{"categories":["论文阅读"],"content":"4. class SiameseTest(SiameseDataset) SiameseTest class SiameseTest(SiameseDataset): def __init__(self, model, path, split=\"\", #\"Test\" category_name=\"Car\", regress=\"GAUSSIAN\", offset_BB=0, scale_BB=1.0): # offset_BB = 0 scale_BB = 1.25 super().__init__( model=model, path=path, split=split, category_name=category_name, regress=regress, offset_BB=offset_BB, scale_BB=scale_BB) self.split = split self.offset_BB = offset_BB self.scale_BB = scale_BB def getitem(self, index): list_of_anno = self.list_of_tracklet_anno[index] PCs = [] BBs = [] for anno in list_of_anno: # this_PC里面是当前帧的所有点云转换到相机坐标系下的点云数据 # this_BB是一个字典　里面的键对对应着中心点，whl,以及四元数角 this_PC, this_BB = self.getBBandPC(anno) PCs.append(this_PC) BBs.append(this_BB) return PCs, BBs, list_of_anno def __len__(self): # 返回label中要跟踪的车辆的个数 return len(self.list_of_tracklet_anno) 测试数据集的构建同样基于上面得到的 SiameseDataset 类，创建 SiameseTest 测试阶段输入的index与训练不同,这里只需要输入一个index, 这个index代表着 list_of_tracklet_anno 中的索引 ","date":"2020-06-26","objectID":"/00-sc3d/:4:4","tags":["论文阅读"],"title":"论文阅读00 SC3D","uri":"/00-sc3d/"},{"categories":["必备工具"],"content":"本工作记录常用的Git学习指令。 ","date":"2020-05-26","objectID":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:0:0","tags":["Git","Tools"],"title":"git学习记录","uri":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["必备工具"],"content":"git常用命令 全局配置 # 配置用户名 git config --global user.name \"your_user_name\" # 配置用户邮箱 git config --global user.email \"your_email_address\" # 查看当前git状态 git status # 查看git日志 git log 版本控制 #　回退到上一个版本 git reset --hard HEAD^ #　回退到上上个版本 git reset --hard HEAD^^ #　查看相对日志，这个是相对于clone仓库之后的，就是说如果你从网上克隆一个仓库，那么reflog应该是空的 git reflog # 查看所有日志，也包括克隆仓库的以前代码版本信息 git log #　回退到任意版本 git reset --hard 版本号 分支操作 # 查看分支 git branch # 创建分支 git branch name # 跳转分支 git checkout name # 创建并跳转分支 git checkout –b name # 合并某分支到当前分支 git merge name # 删除分支 git branch –d name # 重命名本地分支 git branch -m oldName newName # 重命名本地分支后，如果想删除远程分支，那么 git push --delete origin oldName 更多 ","date":"2020-05-26","objectID":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:0:1","tags":["Git","Tools"],"title":"git学习记录","uri":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["必备工具"],"content":"创建git仓库的几种方式 通过本地空文件创建，使用以下命令 git init 通过克隆远程仓库到本地，使用以下命令 git clone your_repos_address 通过pull远程仓库到本地，使用以下命令 git init git remote add origin your_repos_address git pull origin your_branch_name ","date":"2020-05-26","objectID":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:0:2","tags":["Git","Tools"],"title":"git学习记录","uri":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["必备工具"],"content":"提交本地仓库到远程仓库的方式 git add -A git commit -m \"your_commit_message\" git remote add origin your_repos_address git push origin your_branch_name 如果push报错，可能需要先pull，在进行push 提交时注意要提交的分支以及本地当前所在的分支是否一致，若不一致，需要切换到对应分支 ","date":"2020-05-26","objectID":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:0:3","tags":["Git","Tools"],"title":"git学习记录","uri":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["必备工具"],"content":"删除远程分支的方式 # 首先切换到要删除的分支，若本地没有对应分支，则创建 git checkout your_branch_name git branch -r -d origin/branch-name git push origin :branch-name ","date":"2020-05-26","objectID":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:0:4","tags":["Git","Tools"],"title":"git学习记录","uri":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["必备工具"],"content":"自动保存账户密码 有两种方式设置 第一种是设置当前git仓库的配置文件，这样只对当前仓库有效 git config -e 第二种是设置全局git配置文件，对所有仓库均有效 git config --global -e 无论哪一种，在打开的配置文件中，添加上以下命令 [credential] helper = store 保存后，重启终端，输入一次密码后就会自动保存，以后就不需要再输入密码啦～ ","date":"2020-05-26","objectID":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:0:5","tags":["Git","Tools"],"title":"git学习记录","uri":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["必备工具"],"content":"常见错误记录 RPC failed 如果在 git commit 时出现以下错误，可以尝试重新清空 git 全局配置 error: RPC failed; curl 56 GnuTLS recv error (-12): A TLS fatal alert has been received. 使用 git config --global -e 来查看全局配置文件 使用 git config -e 来查看当前仓库的配置文件 ","date":"2020-05-26","objectID":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:0:6","tags":["Git","Tools"],"title":"git学习记录","uri":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["必备工具"],"content":"2021.8.13之后不可以使用password执行git操作 大概意思是，原有的git pull或者git push 操作时，使用的用户名+密码的方式，改成了用户名+token，所以需要我们做一些改动 生成token Settings =\u003e Developer Settings  Personal Access Token  Generate New Token  Fillup the form Generate token Copy the generated Token, it will be something like ghp_sFhFsSHhTzMDreGRLjmks4Tzuzgthdvfsrta 配置git 自动缓存 注意，这里如果使用 cache 的话，过段时间会自动忘记的，默认是15分钟，所以为了方便，可以存储密码到本地，将cache改为store，这个看自己选择了 “store” 模式可以接受一个 --file \u003cpath\u003e 参数，可以自定义存放密码的文件路径（默认是 ~/.git-credentials ） “cache” 模式有 --timeout \u003cseconds\u003e 参数，可以设置后台进程的存活时间（默认是 “900”，也就是 15 分钟） $ git config --global user.name \"\" $ git config --global user.email \"\" $ git config -l $ git config --global credential.helper cache # 设置自动缓存 再次上传，第一次输入token 后续git就会自己记住的 ","date":"2020-05-26","objectID":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:0:7","tags":["Git","Tools"],"title":"git学习记录","uri":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["学习笔记"],"content":"本文要完成的工作是将KITTI数据集中的点云信息投影到图像中，以达到信息融合的目的.　使用KITTI中的经过时钟同步和校准后的数据文件 raw_data 来进行投影变换。其主要操作就是坐标系之间的变换。 ","date":"2020-03-22","objectID":"/kitti%E6%95%B0%E6%8D%AE%E9%9B%86%E7%82%B9%E4%BA%91%E6%8A%95%E5%BD%B1%E5%88%B0%E5%9B%BE%E5%83%8F/:0:0","tags":["KITTI","DeepLearning","点云投影"],"title":"KITTI数据集点云图像的投影","uri":"/kitti%E6%95%B0%E6%8D%AE%E9%9B%86%E7%82%B9%E4%BA%91%E6%8A%95%E5%BD%B1%E5%88%B0%E5%9B%BE%E5%83%8F/"},{"categories":["学习笔记"],"content":"1. KITTI数据集介绍 kitti的数据采集平台，配置有四个摄像机和一个激光雷达，四个摄像机中有两个灰度摄像机，两个彩色摄像机 从图中可看出，关于相机坐标系(camera)的方向与雷达坐标系(velodyne)的方向规定 camera: x = right, y = down, z = forward velodyne: x = forward, y = left, z = up 那么velodyne所采集到的点云数据中，各点的x轴坐标，即为所需的深度信息。 更多详细的简介网络上都能搜索到，这里只列举了与当前目的相关的必要信息。 ","date":"2020-03-22","objectID":"/kitti%E6%95%B0%E6%8D%AE%E9%9B%86%E7%82%B9%E4%BA%91%E6%8A%95%E5%BD%B1%E5%88%B0%E5%9B%BE%E5%83%8F/:0:1","tags":["KITTI","DeepLearning","点云投影"],"title":"KITTI数据集点云图像的投影","uri":"/kitti%E6%95%B0%E6%8D%AE%E9%9B%86%E7%82%B9%E4%BA%91%E6%8A%95%E5%BD%B1%E5%88%B0%E5%9B%BE%E5%83%8F/"},{"categories":["学习笔记"],"content":"2. KITTI数据集中的raw_data raw_data对于每个序列都提供了同步且校准后的数据、标定数据。 同步且校准后的数据： ./imageXX 包含有各个摄像机采集到的图像序列 ‘image_00’: left rectified grayscale image sequence ‘image_01’: right rectified grayscale image sequence ‘image_02’: left rectified color image sequence ‘image_03’: right rectified color image sequence ./velodyne_points 包含有雷达扫描到的数据，点云形式，每个点以 (x,y,z,i) 格式存储，i为反射值 雷达采集数据时，是绕着竖直轴旋转扫描，只有当雷达旋转到与相机的朝向一致时会触发相机采集图像。不过在这里无需关注这一点，直接使用给出的同步且校准后的数据即可，它已将雷达数据与相机数据对齐，也就是可以认为同一文件名对应的图像数据与雷达点云数据属于同一个场景。 标定数据： ./cam_to_cam 包含有各个摄像机的标定参数 ./velo_to_cam 包含有雷达到摄像机的变换参数 对于raw_data，kitti还提供了样例工具，方便读取各种数据文件并输出，参见官网raw_data下载页的development kit ","date":"2020-03-22","objectID":"/kitti%E6%95%B0%E6%8D%AE%E9%9B%86%E7%82%B9%E4%BA%91%E6%8A%95%E5%BD%B1%E5%88%B0%E5%9B%BE%E5%83%8F/:0:2","tags":["KITTI","DeepLearning","点云投影"],"title":"KITTI数据集点云图像的投影","uri":"/kitti%E6%95%B0%E6%8D%AE%E9%9B%86%E7%82%B9%E4%BA%91%E6%8A%95%E5%BD%B1%E5%88%B0%E5%9B%BE%E5%83%8F/"},{"categories":["学习笔记"],"content":"3. 利用kitti提供的devkit以及相应数据集的calib文件 解读calib文件夹 cam_to_cam，包含各相机的标定参数 S_xx: 1x2 矫正前xx号相机的图片尺寸 K_xx: 3x3 矫正前xx号相机的标定参数 D_xx: 1x5 矫正前xx号相机的畸变系数 R_xx: 3x3 外参，xx号相机的旋转矩阵 T_xx: 3x1 外参，xx号相机的平移矩阵 S_rect_xx: 1x2 矫正后XX号相机的图片尺寸 R_rect_xx: 3x3 旋转矩阵，用于矫正xx号相机，使得图像平面共面(原话是make image planes co-planar)。 P_rect_0x: 3x4 投影矩阵，用于从矫正后的0号相机坐标系 投影到 X号相机的图像平面。 这里只用到最后两个矩阵R_rect和P_rect velo_to_cam，从雷达坐标系到0号相机坐标系的转换 R: 3x3 旋转矩阵 T: 3x1 平移矩阵 delta_f 和delta_c 已被弃用 由此可以得出从雷达坐标系变换到xx号相机的图像坐标系的公式： 设X为雷达坐标系中的齐次坐标 X = [x y z 1]'，对应于xx号相机的图像坐标系的齐次坐标Y = [u v 1]'，则： Y = P_rect_xx * R_rect_00 * (R|T)_velo_to_cam * X (R|T) ： 雷达坐标系 -\u003e 0号相机坐标系 R_rect_00： 0号相机坐标系 -\u003e 矫正后的0号相机坐标系 P_rect_0x： 矫正后的0号相机坐标系 -\u003e 0号相机的图像平面 解读devkit 官网提供的样例代码中 run_demoVelodyne.m 实现了将雷达点云投影到相机图像 大致说一下步骤： 从所给路径中读取标定文件，获取具体矩阵数值 根据上述公式，计算投影矩阵 P_velo_to_img，即 Y = P_velo_to_img * X 从所给路径中读取相机图片，并加载雷达的点云数据。由于只做展示用，为了加快运行速度，对于雷达点云，每隔5个点只保留1个点 移除那些距离雷达5米之内(雷达的x方向)的点 (猜测这些点落在相机和雷达之间，故不会出现在图像平面上) 作投影计算，得到投影到二维图像上的点 在图像上画出投影后的点，按照深度(雷达点的x方向值)确定颜色，彩色则是暖色越近，冷色越远；灰度则是深色越近，浅色越远。 ","date":"2020-03-22","objectID":"/kitti%E6%95%B0%E6%8D%AE%E9%9B%86%E7%82%B9%E4%BA%91%E6%8A%95%E5%BD%B1%E5%88%B0%E5%9B%BE%E5%83%8F/:0:3","tags":["KITTI","DeepLearning","点云投影"],"title":"KITTI数据集点云图像的投影","uri":"/kitti%E6%95%B0%E6%8D%AE%E9%9B%86%E7%82%B9%E4%BA%91%E6%8A%95%E5%BD%B1%E5%88%B0%E5%9B%BE%E5%83%8F/"},{"categories":["编程算法"],"content":"1. python与ros兼容性问题 如果使用了conda环境或者是系统本身的python环境，但是在运行某一条命令时，显示在某一个路径下找不到固定的模块，类似 (python3) $ CUDA_VISIBLE_DEVICES=0 python -u train.py --work-path ./experiments/cifar10/lenet Traceback (most recent call last): File \"train.py\", line 9, in \u003cmodule\u003e import yaml File \"/opt/ros/kinetic/lib/python2.7/dist-packages/yaml/__init__.py\", line 1, in \u003cmodule\u003e from error import * ModuleNotFoundError: No module named 'error' 使用pip list查找之后，发现对应的yaml包是有安装的 这种问题的原因就是：在sys的路径中，混入了ros的python路径，导致找不到对应的包，所以我们可以在对应的python文件最上面，加入以下代码： import sys ros_path = '/opt/ros/kinetic/lib/python2.7/dist-packages' if ros_path in sys.path: sys.path.remove(ros_path) ","date":"2020-03-06","objectID":"/python%E4%B8%8Eros%E5%85%BC%E5%AE%B9%E6%80%A7%E9%97%AE%E9%A2%98/:1:0","tags":["python","ros"],"title":"Python与ros兼容问题记录","uri":"/python%E4%B8%8Eros%E5%85%BC%E5%AE%B9%E6%80%A7%E9%97%AE%E9%A2%98/"},{"categories":["编程算法"],"content":"2. python3、ros以及cv_bridge的兼容性问题 在使用python3以及ros中的cv包的时候，想要通过python3来创建一个节点接收话题形式的图像信息，然而在消息回调中如果想要通过cv_bridge来将消息格式进行转换，则会报错，形式如下： [ERROR] [1520780674.845066]: bad callback: \u003cbound method ViewsBuffer.update of \u003c__main__.ViewsBuffer object at 0x7f5f45a07f28\u003e\u003e Traceback (most recent call last): File \"/opt/ros/kinetic/lib/python2.7/dist-packages/rospy/topics.py\", line 750, in _invoke_callback cb(msg) File \"test.py\", line 48, in update im = self.bridge.imgmsg_to_cv2(im, \"bgr8\") File \"/opt/ros/kinetic/lib/python2.7/dist-packages/cv_bridge/core.py\", line 163, in imgmsg_to_cv2 dtype, n_channels = self.encoding_to_dtype_with_channels(img_msg.encoding) File \"/opt/ros/kinetic/lib/python2.7/dist-packages/cv_bridge/core.py\", line 99, in encoding_to_dtype_with_channels return self.cvtype2_to_dtype_with_channels(self.encoding_to_cvtype2(encoding)) File \"/opt/ros/kinetic/lib/python2.7/dist-packages/cv_bridge/core.py\", line 91, in encoding_to_cvtype2 from cv_bridge.boost.cv_bridge_boost import getCvType ImportError: dynamic module does not define module export function (PyInit_cv_bridge_boost) 这里我尝试了stackflow中给出的解决方案，如下： # `python-catkin-tools` is needed for catkin tool # `python3-dev` and `python3-catkin-pkg-modules` is needed to build cv_bridge # `python3-numpy` and `python3-yaml` is cv_bridge dependencies # `ros-kinetic-cv-bridge` is needed to install a lot of cv_bridge deps. Probaply you already have it installed. sudo apt-get install python-catkin-tools python3-dev python3-catkin-pkg-modules python3-numpy python3-yaml ros-kinetic-cv-bridge # Create catkin workspace mkdir catkin_workspace cd catkin_workspace catkin init # Instruct catkin to set cmake variables catkin config -DPYTHON_EXECUTABLE=/usr/bin/python3 -DPYTHON_INCLUDE_DIR=/usr/include/python3.5m -DPYTHON_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.5m.so # Instruct catkin to install built packages into install place. It is $CATKIN_WORKSPACE/install folder catkin config --install catkin config --space-suffix _cb # Clone cv_bridge src git clone https://github.com/ros-perception/vision_opencv.git src/vision_opencv # Find version of cv_bridge in your repository apt-cache show ros-kinetic-cv-bridge | grep Version Version: 1.12.8-0xenial-20180416-143935-0800 # Checkout right version in git repo. In our case it is 1.12.8 cd src/vision_opencv/ git checkout 1.12.8 cd ../../ # Build catkin build cv_bridge # Extend environment with new package source install/setup.bash --extend 还有一种方案,需要替换系统中的libboost_python到指定的环境下，因为我使用的是connda 环境，所以测试之后并不好用。 最终方案 使用ubuntu16.04 以及系统环境中的python3 解决思路：下载cv_bridge的源码到对应的ros工作空间中,　然后使用catkin config进行单独编译，其余的package可以使用catkin_make进行编译，仅需在catkin config时配置新的编译输出文件夹即可。 解决详细步骤如下： 首先更改系统的~/.bashrc文件，取消conda的环境变量配置，并且设置python为python3 #__conda_setup=\"$('/home/echo/anaconda2/bin/conda' 'shell.bash' 'hook' 2\u003e /dev/null)\" #if [ $? -eq 0 ]; then # eval \"$__conda_setup\" #else # if [ -f \"/home/echo/anaconda2/etc/profile.d/conda.sh\" ]; then # . \"/home/echo/anaconda2/etc/profile.d/conda.sh\" # else # export PATH=\"/home/echo/anaconda2/bin:$PATH\" # fi #fi #unset __conda_setup alias python=python3 #切换系统默认的python3.5　屏蔽以后默认为python2.7 安装对应的python3和ros功用的依赖，具体参考 接下来catkin config 配置cv_bridge # `python-catkin-tools` is needed for catkin tool # `python3-dev` and `python3-catkin-pkg-modules` is needed to build cv_bridge # `python3-numpy` and `python3-yaml` is cv_bridge dependencies # `ros-kinetic-cv-bridge` is needed to install a lot of cv_bridge deps. Probaply you already have it installed. sudo apt-get install python-catkin-tools python3-dev python3-catkin-pkg-modules python3-numpy python3-yaml ros-kinetic-cv-bridge # Create catkin workspace mkdir catkin_workspace cd catkin_workspace catkin init # Instruct catkin to set cmake variables catkin config -DPYTHON_EXECUTABLE=/usr/bin/python3 -DPYTHON_INCLUDE_DIR=/usr/include/python3.5m -DPYTHON_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.5m.so # Instruct catkin to install built packages into install place. It is $CATKIN_WORKSPACE/install fol","date":"2020-03-06","objectID":"/python%E4%B8%8Eros%E5%85%BC%E5%AE%B9%E6%80%A7%E9%97%AE%E9%A2%98/:2:0","tags":["python","ros"],"title":"Python与ros兼容问题记录","uri":"/python%E4%B8%8Eros%E5%85%BC%E5%AE%B9%E6%80%A7%E9%97%AE%E9%A2%98/"},{"categories":null,"content":" Hi，这里是jiayao的博客，我是一名普通的程序员，热衷于各种科技内容的探索以及尝试，目前处于研究生阶段，研究内容侧重于深度学习与移动机器人感知。 关于本博客，我的定位是用来展示思考以及总结的内容，包括学习和平时的生活，虽然大多是来源于自己的所思所感，但我也十分希望它们能给屏幕前的你提供一些帮助。对于博客内容，也欢迎大家转载，不过前提是注明出处及作者。后续可能也会考虑加入RSS订阅的功能，看心情~ 关于我本人，除了本博客外，你还可以通过Email以及github联系到我，如有机会，非常开心能和各位交流~ ","date":"2020-02-14","objectID":"/about/:0:0","tags":null,"title":"关于","uri":"/about/"},{"categories":["编程算法"],"content":"使用python中的time模块计算代码运行时间 在计算算法的耗时性时，需要通过一些方法计算代码实际运行的时间，在python中time模块集成了一些方法，可以很方便的计算耗时。 ","date":"2020-01-11","objectID":"/python%E4%B8%AD%E7%9A%84time%E6%A8%A1%E5%9D%97/:1:0","tags":["Python"],"title":"python中的time模块","uri":"/python%E4%B8%AD%E7%9A%84time%E6%A8%A1%E5%9D%97/"},{"categories":["编程算法"],"content":"几种函数简介 time模块提供各种与时间相关的功能，如当前时间、时间戳等，下面只说明用来计算代码运行时间的几种常用函数，python环境为python3 time.time() 返回当前时间的时间戳(1970元年后的浮点秒数)，这个函数容易收到系统时间的影响，所以一般计算代码耗时都不会选择time函数。 time.perf_counter() 返回计时器的精准时间(系统的运行时间)，包含整个系统的睡眠时间．这里的睡眠时间指的是人工使用类似 time.sleep() 的额外时间。 使用时需计算两次之间差值。计算耗时时，如果没有人为的睡眠时间，可以使用这个函数。 time.process_time() 返回当前进程执行CPU的时间总和，不包含睡眠时间．使用时需计算两次之间差值作为代码运行时间。 ","date":"2020-01-11","objectID":"/python%E4%B8%AD%E7%9A%84time%E6%A8%A1%E5%9D%97/:1:1","tags":["Python"],"title":"python中的time模块","uri":"/python%E4%B8%AD%E7%9A%84time%E6%A8%A1%E5%9D%97/"},{"categories":["编程算法"],"content":"代码测试 from time import time, perf_counter, process_time, sleep class TimeDemo: def __init__(self): pass def test_time(self): time0 = time() for i in range(10000000): i = 0 sleep(2) time1 = time() print(\"time function : {0}\".format(time1 - time0)) def test_perf_cnt(self): time0 = perf_counter() for i in range(10000000): i = 0 sleep(2) time1 = perf_counter() print(\"perf_counter function : {0}\".format(time1 - time0)) def test_process_time(self): time0 = process_time() for i in range(10000000): i = 0 sleep(2) time1 = process_time() print(\"process_time function : {0}\".format(time1 - time0)) if __name__ == '__main__': timedemo = TimeDemo() timedemo.test_time() timedemo.test_perf_cnt() timedemo.test_process_time() ","date":"2020-01-11","objectID":"/python%E4%B8%AD%E7%9A%84time%E6%A8%A1%E5%9D%97/:1:2","tags":["Python"],"title":"python中的time模块","uri":"/python%E4%B8%AD%E7%9A%84time%E6%A8%A1%E5%9D%97/"},{"categories":null,"content":"工具 ","date":"0001-01-01","objectID":"/collections/:1:0","tags":null,"title":"工具\u0026资源收集","uri":"/collections/"},{"categories":null,"content":"在线工具 Convertio 各种格式转换都可以在这上面找到 Remove.bg 移除图片背景的神器，使用时尽量选取前景背景相差明显的图片，毕竟要对AI宽容一点 Draw.io 在线画流程图 ProcessOn 在线画流程图，个人感觉比draw.io更美观 QuickRef.ME 编程\u0026IDE速查表 ProtonMail 匿名邮箱 voxelize-image 图像体素化 Tables Grnerator 在线生成各种表格源码，包括Latex、HTML以及Markdown，极其强大 Tables Convert 在线转换各种表格， 包括csv、json、latex、html、excel等 zamzar 图片格式转换，可以将SVG转成PDF，转换效果较好，但是每天有次数限制 cloudconvert.com 同格式转换，无次数限制，但是有时候转换效果不是很好，可以备用 ","date":"0001-01-01","objectID":"/collections/:1:1","tags":null,"title":"工具\u0026资源收集","uri":"/collections/"},{"categories":null,"content":"chrome插件 GitZip for github github下载助手，可以下载单独文件 Enhanced GitHub github功能拓展，可以显示仓库大小等，也可以辅助下载 Proxy SwitchyOmega 好用的代理管理工具 ImageAssistant 网页图片抓取 Web Clipper 屏幕截图 HTML5 Outliner 网页目录提取、跳转等 Find Code for Research Papers 代码搜索工具，在arxiv等论文网站上可以显示对应论文是否有代码，并提供链接 ","date":"0001-01-01","objectID":"/collections/:1:2","tags":null,"title":"工具\u0026资源收集","uri":"/collections/"},{"categories":null,"content":"Lidar-based 3D Object Tracking ","date":"0001-01-01","objectID":"/projects/:1:0","tags":null,"title":"项目","uri":"/projects/"},{"categories":null,"content":"Transformer \u0026 Tracking [conference paper]. [code]. [Youtube]. [Bilibili] [1] J. Shan, S. Zhou, Z. Fang and Y. Cui, “PTT: Point-Track-Transformer Module for 3D Single Object Tracking in Point Clouds,” 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2021, pp. 1310-1316, doi: 10.1109/IROS51168.2021.9636821. [2] J. S. Jiayao, S. Zhou, Y. Cui and Z. Fang, “Real-time 3D Single Object Tracking with Transformer,” in IEEE Transactions on Multimedia, doi: 10.1109/TMM.2022.3146714. ","date":"0001-01-01","objectID":"/projects/:1:1","tags":null,"title":"项目","uri":"/projects/"}]