[{"categories":["读书观影"],"content":" 若能避开猛烈的欢喜，自然也不会有悲痛的来袭。我尝试绕开那些悲痛，却也错过了所有欢喜，倘若真的无从避免，倒不如先享受那顽固的欢喜。《人间失格》 长情不过一杯酒，早春不过一棵树 年龄是时间的箭头，往前延伸，总会遇到更多的事 不管那些事是你想遇到的，还是不想遇到的，但它就在那里，你的心态自然会发生变化 不要说自我控制、消解、努力或者别的什么，因为当我们连评价的标准都还找不到的时候，这样做是无意义的 那么只能就此刻来说，我们做自己喜欢的事便好，快活就好 须尽欢，无论享乐还是工作 ——来自猫腻的书 逝者如斯，故不舍昼夜，须尽欢！ 我们总会担心，当面临人生的岔路口时，是不是拥有足够的认知来选择一条足够适合自己的路；但，世事往往多变，如果没办法确定地做一个一定正确的选择，那就在以后的日子里，学会忠于自己的选择吧！ 生死之间无小事，生离，或是死别 大都好物不坚牢，彩云易散琉璃脆 人生不得行胸臆，纵年百岁犹为夭 Sidere mens eadem mutato. 繁星纵变，智慧永恒。 ——悉尼大学校训 Die Luft der Freiheit weht. 自由之风永远吹拂。——斯坦福校训 Je pense, donc je suis. 我思故我在。——笛卡尔 Facta non verba. 行胜于言 Eadem mutata resurgo. 纵使改变，依然故我。——伯努利墓志铭 Velut arbor aevo. 像参天大树一样成长/百年树人。——加拿大多伦多大学校训 Hinc itur ad astra. 此处通往繁星。 ——立陶宛维尔纽斯大学校训 ","date":"2022-01-13","objectID":"/%E7%BE%8E%E6%96%87%E6%94%B6%E5%BD%95/:0:0","tags":["美文收录"],"title":"美文收录","uri":"/%E7%BE%8E%E6%96%87%E6%94%B6%E5%BD%95/"},{"categories":["深度学习"],"content":"数据集简介 nuScenes数据集是由Motional（以前为nuTonomy）的团队开发的用于自动驾驶的公共大型数据集，其中，Motional是由现代汽车集团(Hyundai Motor Group)和Aptiv PLC的合资企业，在2020年成立后，将原有的nuTonomy团队进行了扩展。哦对，这个团队还是PointPainting以及PointPillars的作者。 数据集部分，目前全部的nuScenes数据集包含四部分，分别是nuPlan、nuScenes、nuImages以及nuReality，其中nuReality是用作VR(Virtual Reality)的数据集。 对于nuScenes这部分三维场景的数据集来说， 2019 年 3 月，发布了包含全部 1000 个场景的完整 nuScenes 数据集，其数据量大概是KITTI数据集的7倍左右。 2020 年 7 月，发布了 nuScenes-lidarseg。在 nuScenes-lidarseg 中，共有 32 种语义标签（即激光雷达语义分割）对 nuScenes 中关键帧中的每个激光雷达点进行注释。因此，nuScenes-lidarseg 在 40,000 个点云和 1000 个场景（850 个用于训练和验证的场景，以及 150 个用于测试的场景）中包含 14 亿个注释点。 ","date":"2022-01-12","objectID":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/:1:0","tags":["Dataset"],"title":"NuScenes数据集笔记","uri":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/"},{"categories":["深度学习"],"content":"Features 这里只关注数据集中一些三维数据的feature，更多信息可以自行查阅官网. 传感器部署 lidar x 1 20Hz 32 channels 水平FOV360° , 竖直FOV +10° 到 -30° 点云范围在 80m-100m左右, 最远70m左右仍可以保证点云具有 ± 2 cm 的精度 每秒点云最多 ~139万个点 radar x 5 77GHz的波频 13Hz 采样频率 最远可测250m 测速精度大概 ±0.1 km/h camera x 6 12Hz 采样频率 1/1.8'' CMOS，1600x1200 分辨率 像素编码格式为 Bayer8 imu x 1 gps x 1 数据量信息 1000个场景，每个场景20s，地点在波士顿和新加坡这两个城市；20s时长以显示各种驾驶操作，交通状况和意外行为 140万帧相机的图片 39万帧lidar点云 覆盖23种类别的目标以及1.4M的手动标注的3D bounding boxes 覆盖了32种类别以及1.1B个手动标注的lidar points 各传感器时间同步 为了在 LIDAR 和摄像头之间实现良好的跨模态数据对齐，当顶部 LIDAR 扫过摄像头 FOV 的中心时，会触发摄像头的曝光。图像的时间戳为曝光触发时间；而激光雷达扫描的时间戳是当前激光雷达帧实现全旋转的时间。鉴于相机的曝光时间几乎是瞬时的，这种方法通常会产生良好的数据对齐。请注意，相机以 12Hz 运行，而 LIDAR 以 20Hz 运行。12 次相机曝光尽可能均匀地分布在 20 次激光雷达扫描中，因此并非所有激光雷达扫描都有相应的相机帧。 ","date":"2022-01-12","objectID":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/:1:1","tags":["Dataset"],"title":"NuScenes数据集笔记","uri":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/"},{"categories":["深度学习"],"content":"Benchmarks 由于NuScenes包含了时序信息，所以除了常见的检测跟踪分割任务，还有一些轨迹预测以及规划的任务benchmarks，具体包括：detection、tracking、prediction、lidar segmentation、panoptic、planning ","date":"2022-01-12","objectID":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/:1:2","tags":["Dataset"],"title":"NuScenes数据集笔记","uri":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/"},{"categories":["深度学习"],"content":"数据集下载 需要注册账号并登陆后才可下载，界面如下： ","date":"2022-01-12","objectID":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/:2:0","tags":["Dataset"],"title":"NuScenes数据集笔记","uri":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/"},{"categories":["深度学习"],"content":"数据集使用以及devkit说明 官方给了非常详细的使用教程，具体可以参考github上的devkit ","date":"2022-01-12","objectID":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/:3:0","tags":["Dataset"],"title":"NuScenes数据集笔记","uri":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/"},{"categories":["深度学习"],"content":"数据集文件结构 我这里只下载了nuScenes部分的数据集，下载好的目录结构如下： /data/sets/nuscenes samples - 关键帧的传感器数据. sweeps - 所有帧的传感器数据. maps - 地图相关文件. v1.0-* - trainval对应的元数据以及标注文件，json格式 值得注意的是，nuScenes采用了token的方式，将传感器、时间戳、帧id等都抽象成token，对应地，上述目录结构中，sweeps以及samples中也是根据不同传感器的名称来存放的，如下所示。 . ├── CAM_BACK ├── CAM_BACK_LEFT ├── CAM_BACK_RIGHT ├── CAM_FRONT ├── CAM_FRONT_LEFT ├── CAM_FRONT_RIGHT ├── LIDAR_TOP ├── RADAR_BACK_LEFT ├── RADAR_BACK_RIGHT ├── RADAR_FRONT ├── RADAR_FRONT_LEFT └── RADAR_FRONT_RIGHT ","date":"2022-01-12","objectID":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/:3:1","tags":["Dataset"],"title":"NuScenes数据集笔记","uri":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/"},{"categories":["深度学习"],"content":"架构中的基础概念 此外，nuScenes中的一些基础概念如下： log - Log information from which the data was extracted. scene - 20 second snippet of a car’s journey. sample - An annotated snapshot of a scene at a particular timestamp. sample_data - Data collected from a particular sensor. ego_pose - Ego vehicle poses at a particular timestamp. sensor - A specific sensor type. calibrated sensor - Definition of a particular sensor as calibrated on a particular vehicle. instance - Enumeration of all object instance we observed. category - Taxonomy of object categories (e.g. vehicle, human). attribute - Property of an instance that can change while the category remains the same. visibility - Fraction of pixels visible in all the images collected from 6 different cameras. sample_annotation - An annotated instance of an object within our interest. map - Map data that is stored as binary semantic masks from a top-down view. ","date":"2022-01-12","objectID":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/:3:2","tags":["Dataset"],"title":"NuScenes数据集笔记","uri":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/"},{"categories":["深度学习"],"content":"架构示意图解析 nuScenes数据集中的架构是基于token的机制，将上述13个概念连接起来，如下图所示： 首先，我们可以从左到右看，采集数据的车在运行时会直接记录一些实时的信息，比如车辆编号，地点，日期，地图文件名，传感器之间的内外参等。 接着，我们可以对采集到的数据做解析，将所有数据分成一个又一个的scene，每个场景20s。场景之下是sample，表示的是某个特定时间戳在场景中的关键帧，它是有标注的（注意，在nuScenes中对每个scene，只以2hz的频率标注，也就是说，20Hz的lidar，10Hz只有一帧是有label的）。与sample对应的是sample data，其关联了底层的传感器数据源文件以及一些标定数据和ego的位姿信息。 最后，就是对数据的整理和标注，对于一个scene中不同帧之间相同的object，其表示为一个instance。此外还会有一些属性、类别和可见性的表达。注意，可见程度是根据目标在6个相机视野中的状态来衡量的。 ","date":"2022-01-12","objectID":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/:3:3","tags":["Dataset"],"title":"NuScenes数据集笔记","uri":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/"},{"categories":["深度学习"],"content":"数据集中类别定义 ","date":"2022-01-12","objectID":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/:3:4","tags":["Dataset"],"title":"NuScenes数据集笔记","uri":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/"},{"categories":["深度学习"],"content":"Tutorial示例（超详细） https://www.nuscenes.org/nuscenes?tutorial=nuscenes ","date":"2022-01-12","objectID":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/:3:5","tags":["Dataset"],"title":"NuScenes数据集笔记","uri":"/nuscenes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B/"},{"categories":["踩坑尝试"],"content":"出于对新鲜实物的好奇，我曾经探索过很多版本的主题样式，比如fluid以及butterfly，他们都是基于hexo框架的主题，其功能大多异常丰富，让初始者观之眼花缭乱。但使用过一段时间后，还是觉得自己需求的是一款简洁为主的主题，因此有了这款loveit主题的尝试，特此记录如下。 ","date":"2022-01-11","objectID":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/:0:0","tags":["Misc"],"title":"基于hugo的Loveit主题博客搭建记录","uri":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/"},{"categories":["踩坑尝试"],"content":"明确自己的需求喜好 既然想换主题，那么明确自己需求的主题样式很重要，所以我找了大量的博客以及网页推荐，主要渠道来源于以下几个方面： 知乎等平台的总结推荐 github直接搜索主题字样 寻找一些关注度较高的博客网站， 查看他们的友链；或者是在诸如butterfly这种主题主页会有一些博客的展示 那么看过了大多数的主题之后，我越发确定自己想要的就是偏简洁风的样式。在这期间，我还尝试过使用Notion搭配一些软件或者是网站直接创建博客，但是相关的生态不是很多，仅有的几种方案列举如下： nobelium 界面较为简洁, 使用vercel托管github的项目，可以与notion联动, 自动更新同步notion中的内容 Potion 看起来不错，但是使用就需要付费 Super 使用较为简单, 可以自己定义很多css代码块, 以定义header navbar等，但是稍微高级一点的功能就需要付费 看起来唯一可行的就是nobelium这个项目，我也在少数派上发现了对应的文章教程，大概尝试了之后发现还是有很多bug需要改进的，所以最终不得不放弃了使用Notion这个想法~ 放两个我觉得还算不错的博客主题: https://geekplux.com/posts https://hugoloveit.com/posts/ 所以初步选定loveit作为要配置的主题样式~ ","date":"2022-01-11","objectID":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/:1:0","tags":["Misc"],"title":"基于hugo的Loveit主题博客搭建记录","uri":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/"},{"categories":["踩坑尝试"],"content":"配置过程记录 ","date":"2022-01-11","objectID":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/:2:0","tags":["Misc"],"title":"基于hugo的Loveit主题博客搭建记录","uri":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/"},{"categories":["踩坑尝试"],"content":"下载hugo 因为loveit是基于hugo的，所以需要先下载，这里考虑到一些拓展功能，建议下载extend版本。 sudo dpkg -i xxx.deb ","date":"2022-01-11","objectID":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/:2:1","tags":["Misc"],"title":"基于hugo的Loveit主题博客搭建记录","uri":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/"},{"categories":["踩坑尝试"],"content":"使用hugo创建自己的博客文件夹 安装之后，在终端敲hugo 就可以有以下的输出了 \u003e hugo Error: Unable to locate config file or config directory. Perhaps you need to create a new site. Run `hugo help new` for details. Total in 4 ms 接下来就是按照loveit的主题教程操作，使用以下命令新建博客文件夹 hugo new site my_website cd my_website ","date":"2022-01-11","objectID":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/:2:2","tags":["Misc"],"title":"基于hugo的Loveit主题博客搭建记录","uri":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/"},{"categories":["踩坑尝试"],"content":"安装主题 git clone https://github.com/dillonzq/LoveIt.git themes/LoveIt 关于主题的配置，自行参考教程即可。 ","date":"2022-01-11","objectID":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/:2:3","tags":["Misc"],"title":"基于hugo的Loveit主题博客搭建记录","uri":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/"},{"categories":["踩坑尝试"],"content":"创建博客 这部分在my_website目录下的content下面，可以自行创建，或使用hugo命令在终端创建。 hugo new posts/first_post.md 此外，我们还可以创建自己的专属内容，比如定义一个收藏页面，那就在content目录下创建一个collections的文件夹，再在其中创建一个index.md文件，这部分可以通过自定义manu bar的方式，将这个index对应的网页链接到导航栏。 我的改动如下： 改动config.toml，添加以下内容： [[menu.main]] identifier = \"collections\" pre = \"\" post = \"\" name = \"收集\" url = \"/collections/\" title = \"\" weight = 5 对应地，需要在content目录下创建collections文件夹，这样我们就完成了导航栏到自定义页面的链接。 综上，具体的config配置我就不记录太多了，各凭喜好~ ","date":"2022-01-11","objectID":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/:2:4","tags":["Misc"],"title":"基于hugo的Loveit主题博客搭建记录","uri":"/%E5%9F%BA%E4%BA%8Ehugo%E7%9A%84loveit%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/"},{"categories":["思考总结"],"content":"在平时的学习生活中，工具软件是我们必不可少的，我个人也热衷于探究各种新奇的软件APP，在这里总结一下平时学习生活涉及到的软件以及工作流。 ","date":"2022-01-10","objectID":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/:0:0","tags":["工作流","效率"],"title":"工作流总结","uri":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/"},{"categories":["思考总结"],"content":"工作流的不同阶段 我个人喜欢将学习生活的工作流分为四个阶段，分别是：信息输入 -\u003e 信息整理 -\u003e 回顾总结 -\u003e 创作输出。 ","date":"2022-01-10","objectID":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/:1:0","tags":["工作流","效率"],"title":"工作流总结","uri":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/"},{"categories":["思考总结"],"content":"信息输入 其中，信息输出包括从各种能接触到的信息源中获取的自身感兴趣的知识点，比如平时阅读论文的笔记以及看网课的笔记等，我会选择在Notion中编辑他们，这样方便各个设备之间同步。 除了笔记、论文等较为集中的信息摄入外，一般会涉及到一个概念就是稍后阅读 。我一般会将微信公众号的推送、medium以及知乎等博文的推送等碎片化的知识点整理到一个临时存储平台中，这里就是pocket，然后定期清理一波，将他们划线批注，提取其中较为重点且易忘的部分。为了减少手动操作，我使用Readwise软件，绑定pocket以及我的知识库Notion，这样我在pocket中的阅读结果就可以自动同步到Notion中。 ","date":"2022-01-10","objectID":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/:1:1","tags":["工作流","效率"],"title":"工作流总结","uri":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/"},{"categories":["思考总结"],"content":"信息整理 接下来就是较为重量的软件，Notion，我对它的定位是一个知识库，我会将形形色色的内容放在其中，并且分门别类，定期整理一次。 此外，为了更好地对学过的内容做总结和回顾，我还会在Notion中做一些初步的内容收集以及内容整理。比如想要确定深度学习中BN相关的知识点，我会先在Notion中创建一个page，然后根据BN涉及到的内容，创建不同的标题，每一部分标题对应的资料则是靠平时的浏览学习进行收集。最终，资料内容丰富到一定程度或者个人理解到达一定程度后，我会对这些内容进行初步的整理，以实现个人学习的内容输出。 ","date":"2022-01-10","objectID":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/:1:2","tags":["工作流","效率"],"title":"工作流总结","uri":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/"},{"categories":["思考总结"],"content":"回顾总结 经过Notion做初步的收集和整理之后，我选择使用Obsidian这款软件做我的内容回顾与总结。其实对我个人来说，从功能上来看，Notion与Obsidian存在很多重合的地方，比如Obsidian中的日记功能在Notion中也可以通过Calendar实现。但是考虑到Notion自身的同步以及对各种网址和文件等较为友好，在很多功能方面我都选择了Notion，唯独回顾总结这里我选择了使用Obsidian，原因在于其本地化的设定正好可以与我的个人博客相关联，这样我就不需要在Notion中写一遍总结之后为了博客再将其导出到单独的Markdown文件中。 因此，我对于Obsidian的定义更加纯粹，就是单纯的内容整理以及总结的平台，其附带的关系图谱也可以帮我较好地管理输出的内容。 ","date":"2022-01-10","objectID":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/:1:3","tags":["工作流","效率"],"title":"工作流总结","uri":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/"},{"categories":["思考总结"],"content":"创作输出 其实这部分已经在回顾总结的阶段做好了，由于Obsidian的本地化以及各种强大的插件，可以让我很简单地将Obsidian中的笔记应用到博客的发布上。举个例子，我会将Obsidian中的内容按照类别分类，然后放入不同的路径中，再通过超链接关联到博客发布时要读取的路径。接下来在编辑时，借助Templater这些插件，保证Obsidian中的样式与博客需求的一致即可。 而说到博客，我使用github进行版本管理，使用hugo将Markdown文件编译成静态的网页内容，主题则是选用LoveIt（这是我对比各种主题风格之后唯一较为喜爱的），然后使用github pages的功能，将生成的静态网页文件上传到远端之后，对应地就可以通过 xxx.github.io来访问到我的博客内容，为了使其更具备个人属性，我还为它买了一个专属的域名。 OK，综上，这就是我日常的工作流过程～ ","date":"2022-01-10","objectID":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/:1:4","tags":["工作流","效率"],"title":"工作流总结","uri":"/%E5%B7%A5%E4%BD%9C%E6%B5%81%E6%80%BB%E7%BB%93/"},{"categories":["编程算法"],"content":" 本文主要记录python中的一些零散琐碎的知识点，便于之后整理成系统性的学习笔记～ 在个人的角度来看，Python作为一门被深度学习、数据处理等领域大力推广的编程语言，其很多语法糖都是很有意思的，特此记录～ ","date":"2021-07-10","objectID":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/:0:0","tags":["python","Coding"],"title":"Python中的奇奇怪怪","uri":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/"},{"categories":["编程算法"],"content":"python中的奇奇怪怪 ","date":"2021-07-10","objectID":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/:1:0","tags":["python","Coding"],"title":"Python中的奇奇怪怪","uri":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/"},{"categories":["编程算法"],"content":"1. a+=b和a=a+b的区别 二者的区别与否，取决于a和b的对象类型，如果是不可变对象，这两种表达相同；如果是可变对象，两种表达不同，不同之处在于： a+=b 会调用 __iadd__方法，没有该方法时，再尝试调用__add__方法 a=a+b 会调用__add__方法 对于两种内置的方法接口，不同在于： __iadd__返回值是None，直接在原对象上进行更新，也就是说，原有的变量a和对象之间的引用并没有被打破 __add__会返回一个新的对象，原对象不做修改，但是这里会将变量a的引用破坏，将返回的新的对象与变量a建立引用 ","date":"2021-07-10","objectID":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/:1:1","tags":["python","Coding"],"title":"Python中的奇奇怪怪","uri":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/"},{"categories":["编程算法"],"content":"2. Python中的幂运算 Python 中常见有三种幂计算函数： * 和 pow() 的时间复杂度均为 O(\\log a)O(loga) ；而 math.pow() 始终调用 C 库的 pow() 函数，其执行浮点取幂，时间复杂度为 O(1)O(1) 。 ","date":"2021-07-10","objectID":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/:1:2","tags":["python","Coding"],"title":"Python中的奇奇怪怪","uri":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/"},{"categories":["编程算法"],"content":"3. Python中变量的作用域（变量的查找顺序） Python中的变量名可以指代变量、函数、类、对象等 python解释器查找变量的顺序，总结起来可以分为LEGB四种，分别是 Local -\u003e Enclosed -\u003e Global -\u003e Built-in Local 定义在函数内部的变量、定义在函数声明中的形式参数，视为局部变量。 Enclosed 定义在函数中，嵌套函数外，且被嵌套函数引用的变量，视为自由变量。 Global 定义在 .py 文件内的，且函数、类之外的变量，视为全局变量。 Built-in 定义在built in中的变量，视为内置变量。 定义变量的位置决定了变量的作用域; 为了在局部作用域中修改全局变量和自由变量，引入了 global 关键字和 nonlocal 关键字 global用于调用全局变量 nonlocal用于调用 闭包变量，也就是自由变量 此外，对于函数内部再定义一个函数，以形成闭包的情况，在内部函数中调用内部函数外的变量时，是否修改也是一个值得注意的问题 内部函数，不修改全局变量可以访问全局变量，不需要nonlocal或global 内部函数，修改同名全局变量，则python会认为它是一个局部变量 在内部函数修改同名全局变量之前调用变量名称（如print sum），则引发Unbound-LocalError，解决办法就是，加上nonlocal或者global关键字，具体用哪个视情况而定。 ","date":"2021-07-10","objectID":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/:1:3","tags":["python","Coding"],"title":"Python中的奇奇怪怪","uri":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/"},{"categories":["编程算法"],"content":"4. Python的加速运行 参考：https://zhuanlan.zhihu.com/p/143052860 ","date":"2021-07-10","objectID":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/:1:4","tags":["python","Coding"],"title":"Python中的奇奇怪怪","uri":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/"},{"categories":["编程算法"],"content":"5. Python中的闭包 需要明确的是，闭包是一个函数，可以理解为特殊的函数，并且闭包的说法并不是Python特有的，javascript等语言也涉及闭包的概念。 具体地，参考Wiki上对闭包的解释： 在计算机科学中，闭包（英语：Closure），又称词法闭包（Lexical Closure）或函数闭包（function closures），是引用了自由变量的函数。这个被引用的自由变量将和这个函数一同存在，即使已经离开了创造它的环境也不例外。所以，有另一种说法认为闭包是由函数和与其相关的引用环境组合而成的实体。闭包在运行时可以有多个实例，不同的引用环境和相同的函数组合可以产生不同的实例。 总的来看就是，闭包等同于函数引用了函数外定义地变量，并且该函数可以在其定义环境外被执行。这样地函数叫做闭包，类似地，C++中地static关键字定义的就是一个独立函数外地变量，二者有异曲同工之妙。 闭包的一些特性 闭包中的引用的自由变量只和具体的闭包有关联，闭包的每个实例引用的自由变量互不干扰。 一个闭包实例对其自由变量的修改会被传递到下一次该闭包实例的调用。 具体见：https://www.cnblogs.com/yssjun/p/9887239.html ","date":"2021-07-10","objectID":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/:1:5","tags":["python","Coding"],"title":"Python中的奇奇怪怪","uri":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/"},{"categories":["编程算法"],"content":"6. Python中的__new__与__init_ __new__(cls[, ...]) 是在一个对象实例化的时候所调用的第一个方法，在调用__init__初始化前，先调用__new__。 __new__至少要有一个参数cls，代表要实例化的类，此参数在实例化时由 Python 解释器自动提供，后面的参数直接传递给__init__。 __new__对当前类进行了实例化，并将实例返回，传给__init__的self。但是，执行了__new__，并不一定会进入__init__，只有__new__返回了，当前类cls的实例，当前类的__init__才会进入。 若__new__没有正确返回当前类cls的实例，那__init__是不会被调用的，即使是父类的实例也不行，将没有__init__被调用。 __new__方法主要是当你继承一些不可变的 class 时（比如int, str, tuple）， 提供给你一个自定义这些类的实例化过程的途径。 ","date":"2021-07-10","objectID":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/:1:6","tags":["python","Coding"],"title":"Python中的奇奇怪怪","uri":"/python%E4%B8%AD%E7%9A%84%E5%A5%87%E5%A5%87%E6%80%AA%E6%80%AA/"},{"categories":["编程算法"],"content":"本文是学习排序系列的第五篇，主要对比三种基本排序算法以及三种进阶排序算法，对应的排序算法学习笔记如下 基础排序(冒泡、插入、选择) 希尔排序 归并排序 快速排序 ","date":"2021-05-27","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%8E%92%E5%BA%8F%E4%BB%A3%E7%A0%81/:0:0","tags":["Sorting","Algorithms"],"title":"算法学习之排序算法对比","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%8E%92%E5%BA%8F%E4%BB%A3%E7%A0%81/"},{"categories":["编程算法"],"content":"0. 常见排序算法性能对比 再贴一张常见排序算法的性能对比，方便查看~ ","date":"2021-05-27","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%8E%92%E5%BA%8F%E4%BB%A3%E7%A0%81/:1:0","tags":["Sorting","Algorithms"],"title":"算法学习之排序算法对比","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%8E%92%E5%BA%8F%E4%BB%A3%E7%A0%81/"},{"categories":["编程算法"],"content":"1. 代码 import numpy as np from time import process_time from typing import List import matplotlib.pyplot as plt import random class Sorting: def __init__(self, method: str): self.easy_samples = np.random.randint(0, 100000, 5000) self.medium_samples = np.random.randint(0, 100000, 50000) self.hard_samples = np.random.randint(0, 100000, 100000) self.start_time = process_time() self.method = getattr(self, method) def timeit(self): return float('%.4f' % (process_time() - self.start_time)) def sort(self): # print('---------------- Easy Test -------------------') easy_nums = self.method(self.easy_samples) t1 = self.timeit() # print('---------------- Medium Test -------------------') medium_nums = self.method(self.medium_samples) t2 = self.timeit() # print('---------------- Hard Test -------------------') hard_nums = self.method(self.hard_samples) t3 = self.timeit() assert self.checksort(easy_nums) assert self.checksort(medium_nums) assert self.checksort(hard_nums) return [t1, t2, t3], [self.easy_samples.shape, self.medium_samples.shape, self.hard_samples.shape] @staticmethod def checksort(nums): for i in range(len(nums) - 1): if nums[i] \u003e nums[i + 1]: return False return True @staticmethod def bubblesort(nums: List) -\u003e List: length = len(nums) for i in range(1, length): sort_over = True for j in range(length - i): if nums[j] \u003e nums[j + 1]: nums[j], nums[j + 1] = nums[j + 1], nums[j] sort_over = False if sort_over: return nums return nums @staticmethod def selectsort(nums: List) -\u003e List: length = len(nums) for i in range(length): min_id = i for j in range(i, length): min_id = j if nums[j] \u003c nums[min_id] else min_id if min_id != i: # 判断是否是当前元素最小，是的话就不用交换 nums[min_id], nums[i] = nums[i], nums[min_id] return nums @staticmethod def insertsort(nums: List) -\u003e List: length = len(nums) for i in range(length): cur_val = nums[i] last_id = i - 1 while last_id \u003e= 0 and nums[last_id] \u003e cur_val: nums[last_id + 1] = nums[last_id] last_id -= 1 nums[last_id + 1] = cur_val return nums @staticmethod def shellsort(nums: List) -\u003e List: length = len(nums) gap = length while gap \u003e 0: for i in range(gap, length): cur_val = nums[i] last_id = i - gap while last_id \u003e= 0 and nums[last_id] \u003e cur_val: nums[last_id + gap] = nums[last_id] last_id -= gap nums[last_id + gap] = cur_val gap //= 2 return nums @staticmethod def mergesort(nums: List) -\u003e List: def merge(arr_, left_, mid_, right_, tmp_): ptr1, ptr2, index = left_, mid_+1, 0 # 遍历ptr1和ptr2，装填res_数组，直到ptr1或ptr2到头 for i in range(right_-left_+1): if ptr1 \u003e mid_ or ptr2 \u003e right_: break if arr_[ptr1] \u003c= arr_[ptr2]: # 注意 '=' 才能让排序稳定 tmp_[index] = arr_[ptr1] ptr1, index = ptr1+1, index+1 else: tmp_[index] = arr_[ptr2] ptr2, index = ptr2+1, index+1 # 调用extend将剩余元素都装入数组res中 if ptr1 \u003e mid_: tmp_[index:right_-left_+1] = arr_[ptr2:right_+1] if ptr2 \u003e right_: tmp_[index:right_-left_+1] = arr_[ptr1:mid_+1] # 改变arr_区间中的元素顺序 arr_[left_:right_+1] = tmp_[:right_-left_+1] def mergesort_rec(arr, left, right, tmp): if left \u003e= right: return mid = (right + left) // 2 mergesort_rec(arr, left, mid, tmp) mergesort_rec(arr, mid+1, right, tmp) merge(arr, left, mid, right, tmp) length = len(nums) mergesort_rec(nums, 0, length-1, [0]*length) return nums @staticmethod def quicksort(nums: List) -\u003e List: def partition(left, right): i, pivot = left, nums[left] # 这里记录下左指针指向的值，后面比较时不需要重复索引，可以有效节省时间 while left \u003c right: while left \u003c right and nums[right] \u003e= pivot: right -= 1 while left \u003c right and nums[left] \u003c= pivot: left += 1 nums[left], nums[right] = nums[right], nums[left] nums[i], nums[left] = nums[left], pivot return left def sort(start, end): if start \u003e= end: return [] pivot = partition(start, end) sort(start, pivot-1) sort(pivot+1, end) sort(0, len(nums)-1) return nums def plot_and_show(sorting_algo, res, size): x = size # 点的横坐标 def randomcolor(): colorArr = ['1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F'] color = \"\" for i in range(6): color += colorArr[random.randint(0, 14)] return \"#\" + color for i, cur in enume","date":"2021-05-27","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%8E%92%E5%BA%8F%E4%BB%A3%E7%A0%81/:2:0","tags":["Sorting","Algorithms"],"title":"算法学习之排序算法对比","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%8E%92%E5%BA%8F%E4%BB%A3%E7%A0%81/"},{"categories":["编程算法"],"content":"2. 算法运行时间对比 横轴为数据量级，纵轴为运行时间 六种算法共同对比 希尔、归并、快排详细对比 ","date":"2021-05-27","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%8E%92%E5%BA%8F%E4%BB%A3%E7%A0%81/:3:0","tags":["Sorting","Algorithms"],"title":"算法学习之排序算法对比","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%8E%92%E5%BA%8F%E4%BB%A3%E7%A0%81/"},{"categories":["编程算法"],"content":"本文是学习排序系列的第四篇，主要介绍较为常用的排序算法：快速排序 前文学习了归并排序，该排序算法采用了分治(divide and conquer, D\u0026C)的思想，我们可以使用递归对输入序列进行排序。但是归并排序与输入序列的有序程度无关，并且需要额外创建线性的空间，这对于数据规模较大的场景不是很友好。 本文要学习的快速排序同样也是基于分治思想的排序算法，相比于归并，快排的空间复杂度为常数级别，在C中，sort方法的底层实现的原型就是qsort快速排序~ 注：本文的排序算法默认升序 ","date":"2021-05-25","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:0:0","tags":["Sorting","Algorithms"],"title":"算法学习之快速排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"0. 常见排序算法性能对比 再贴一张常见排序算法的性能对比，方便查看~ ","date":"2021-05-25","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:1:0","tags":["Sorting","Algorithms"],"title":"算法学习之快速排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"1. 快速排序 快排是使用分治思想的排序算法，其巧妙地使用哨兵节点(pivot)，递归地将待排序的序列分为大于pivot和小于pivot两部分，进而达到分而治之，化大为小的目的。快速排序就是个二叉树的前序遍历 ","date":"2021-05-25","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:2:0","tags":["Sorting","Algorithms"],"title":"算法学习之快速排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"排序的简化情况 因为快排使用了递归的方法，所以为了明确递归思路，我们先对排序任务进行简单的剖析。 如果待排序的序列长度小于2，那么可以直接返回 如果待排序的序列长度等于2，那么比较两个元素即可 如果待排序的序列长度大于2，可以递归到小于等于2的情况 以上就是递归的想法雏形，其实递归的终止条件就是将大问题简化，简化到极端的情况，进而使用简化来反推复杂情况。 ","date":"2021-05-25","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:2:1","tags":["Sorting","Algorithms"],"title":"算法学习之快速排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"如何递归且O(1)？ 前面说过，归并排序同样使用了分治与递归，但是空间复杂度为O(N)，所以快排应该如何将空间复杂度降低为常数级别的呢？ 快排的思路就是原地分组，通过定义一个哨兵节点来实现。具体操作是将所有元素与哨兵节点的值相比较，小于哨兵节点的放在左侧，大于哨兵节点的放在右侧，这样逐层递归，就完成了排序的过程。 如下图所示，展示的是两次递归完成排序的过程，每次都取第一个元素为哨兵节点： 从上图可以发现，其实快排的基本思想可以认为是一个二叉树的模型，从上面不断地将当前数组分为两部分，直到达到递归终止条件。所以快排与归并排序的不同点在计算方式上也有体现， 归并是直接分组，然后从子问题开始处理，最后归并，是自下而上的算法，先处理子问题，再归并 但是快排是分组时就进行比较，一直到子问题无法继续划分，这时数组就排序完成了，是自上而下的算法，快速排序通过哨兵节点以及原地分组的方式，解决了归并排序中的内存占用 ","date":"2021-05-25","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:2:2","tags":["Sorting","Algorithms"],"title":"算法学习之快速排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"快速排序初版 根据上述思路，我们可以总结一下算法步骤 确定递归终止条件，也称为 base case 这里的终止条件是排序数组为空，否则继续向下递归 确定哨兵节点 为了简单容易理解，这里先将哨兵节点设为输入数组的第一个元素 根据哨兵节点进行递归排序 此时我们可以宏观地将数组分为两部分，比pivot小的，比pivot大的，与pivot相等的。分组完毕后，我们就可以调用自身进一步地对比pivot小的以及pivot大的两组进行再一次的划分，直到达到终止条件。 python版本代码如下 def quicksort(nums: List) -\u003e List: def sort(nums): if nums == []: return [] pivot = nums[0] nums = nums[1:] left = sort([num for num in nums if num \u003c= pivot]) right = sort([num for num in nums if num \u003e pivot]) return left + [pivot] + right return sort(nums) ","date":"2021-05-25","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:2:3","tags":["Sorting","Algorithms"],"title":"算法学习之快速排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"复杂度分析 递归时间以及空间复杂度计算方式如下： 时间复杂度 = 递归调用栈深度 × 每次递归操作次数 空间复杂度 = 递归调用栈深度 × 每次递归开辟的空间 所以为了分析递归的复杂度，我们需要确定递归调用栈的深度。 那么仔细思考一下，其实上述代码中的递归调用栈的深度是不确定的，因为我们的哨兵节点与其余元素的大小关系未知，我们可以分两种情况讨论，设待排序序列长度为N 最好情况，每次的哨兵节点都恰巧是当前序列的中位数，那么我们每次都可以完美地将输入序列分成近乎均等的两部分，这时的递归调用栈的深度为log2(N)，每次递归操作次数为N，开辟空间为常数级别。 那么时间复杂度就是 O(Nlog2(N))，空间复杂度为O(log2(N)) 最坏情况，每次的哨兵节点都恰巧是当前序列中的极值，要么极大要么极小，这时我们的分治处理模型就从二叉树退化成了一维的结构，对应的递归调用栈深度为N，每次递归操作次数为N，开辟空间为常数级别。 那么对应的时间复杂度为O(N^2)，空间复杂度为O(N) 由此可见，上述快速排序可以称之为乞丐版，因为它不能很好地控制复杂度，所以我们可以进一步地改进，改进方案就是哨兵节点的选取。 ","date":"2021-05-25","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:2:4","tags":["Sorting","Algorithms"],"title":"算法学习之快速排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"优化方案：动态选取哨兵节点[双指针] 想要尽可能地分组均匀，哨兵节点的值应该尽可能地接近当前数组的中值 目的已经很明确了，就是要在当前数组中，遍历一遍，然后选取哨兵节点，我们可以使用双指针的方法来完成这个任务。 先假定基准值是数组中的第一个元素 定义两个指针left和right，分别指向第二个元素以及最后一个元素，规定left只能向右移动，right只能向左移动，且left不能超过right (这里再说明一下双指针的作用，左指针负责维护一个小于基准值的区间，右指针则负责维护一个大于基准值的区间) 右指针先向左移动，每移动一位，都和基准值比较，如果遇到比基准值小的元素，停止，反之继续移动。移动左指针，同样边移动边比较，直到遇到比基准值大的元素，停止，与右指针交换位置(为了保证各自维护区间的元素值符合预期要求) 重复3直到左右指针相遇，将相遇位置的元素与基准值交换位置 这里借用袁厨的动图来可视化整个过程，侵删哈 经过以上过程，基准值所在的位置就是我们想要的哨兵节点，这时哨兵节点左侧都是较小元素，右侧都是较大元素，当前区间分组完毕！继续进行下一次递归的分组即可 python代码如下： def quicksort(nums: List) -\u003e List: def partition(arr, left, right): base = left while left \u003c right: while left \u003c right and arr[right] \u003e= arr[base]: right -= 1 while left \u003c right and arr[left] \u003c= arr[base]: left += 1 nums[left], nums[right] = nums[right], nums[left] nums[base], nums[left] = nums[left], nums[base] return left def sort(nums, start, end): if start \u003e= end: return [] pivot = partition(nums, start, end) sort(nums, start, pivot-1) sort(nums, pivot+1, end) sort(nums, 0, len(nums) - 1) return nums ","date":"2021-05-25","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:2:5","tags":["Sorting","Algorithms"],"title":"算法学习之快速排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"优化后复杂度分析 如果不考虑极端情况的话，时间复杂度为O(NlogN)，空间复杂度为O(log2N) 但是不妨想一下，尽管我们使用双指针来优化了哨兵节点的选取，从而使每次哨兵节点的选择都尽可能靠近中间，但是如果输入的序列原本就是顺序或者倒序，那么退化的问题依旧会存在，所以极端情况下，时间复杂度依旧是O(N^2)，空间复杂度依旧是O(N) 为了解决上述问题，一般来讲都会将输入的序列进行打乱（shuffle），如果输入的序列规模很大，那么其实也可以尝试下随机选取一个哨兵节点，平均下来的时间复杂度是最优的。 ","date":"2021-05-25","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:2:6","tags":["Sorting","Algorithms"],"title":"算法学习之快速排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"稳定性分析 不稳定，因为分组时会发生随机的数据交换，从而导致值相同的元素相对位置变化 ","date":"2021-05-25","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:2:7","tags":["Sorting","Algorithms"],"title":"算法学习之快速排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"总结 快速排序一般比归并排序要快 快速排序是不稳定的，因为在分组时会发生随机的数据位置交换 上述优化过后的快排代码针对数组中大量重复数据的情况效果不是那么地好(比如从0-200范围内随机选取50000个数值，快排的速度可能比希尔排序还慢，更别说归并排序了)，如果重复数据较多，可以单独处理 最后，贴一张快排和归并排序耗时比较的图~ ","date":"2021-05-25","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:3:0","tags":["Sorting","Algorithms"],"title":"算法学习之快速排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"python中的列表解析式 ","date":"2021-05-13","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%88%97%E8%A1%A8%E8%A7%A3%E6%9E%90%E5%BC%8F/:1:0","tags":["python","Coding","列表解析式"],"title":"Python还债日记之列表解析式","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%88%97%E8%A1%A8%E8%A7%A3%E6%9E%90%E5%BC%8F/"},{"categories":["编程算法"],"content":"1. 列表解析式 python中的列表解析式可以帮助我们用简短的语言来创建一个列表，形如： [x*y for x in range(1,5) if x \u003e 2 for y in range(1,4) if y \u003c 3] 这里相当于两层循环，外加一些条件判断 for x in range(1,5) if x \u003e 2 for y in range(1,4) if y \u003c 3 x*y ","date":"2021-05-13","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%88%97%E8%A1%A8%E8%A7%A3%E6%9E%90%E5%BC%8F/:1:1","tags":["python","Coding","列表解析式"],"title":"Python还债日记之列表解析式","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%88%97%E8%A1%A8%E8%A7%A3%E6%9E%90%E5%BC%8F/"},{"categories":["编程算法"],"content":"2. 问题描述 但是今天偶尔在刷题时，想要用列表解析式创建一个列表，这里给定了第一个元素的值，然后之后每个元素都是前面元素数值的二倍，我们想要借用列表解析式的话，可能会这么写 [a[i-1]*2 for i in range(len(a))] 但是！！！问题就出在这里，出现的结果并不是想象的[1, 2, 4, 8, …] \u003e\u003e\u003e a = [1] * 5 \u003e\u003e\u003e a[1:] = [a[i-1]*2 for i in range(len(a))] \u003e\u003e\u003e print(a) [1, 2, 2, 2, 2, 2] 可见，列表解析式针对这种情况，应该是新建了一个对象，存储 a[i-1]的值，也就是说，这里的a[i-1]并不是我们想象的是可变的，而是一个定值！！！ 所以之后要注意，此类写法应该使用普通for循环来填充a ","date":"2021-05-13","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%88%97%E8%A1%A8%E8%A7%A3%E6%9E%90%E5%BC%8F/:1:2","tags":["python","Coding","列表解析式"],"title":"Python还债日记之列表解析式","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%88%97%E8%A1%A8%E8%A7%A3%E6%9E%90%E5%BC%8F/"},{"categories":["编程算法"],"content":" 本文是学习排序系列的第三篇，主要介绍归并排序 注：本文的排序算法默认升序 ","date":"2021-05-08","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/:0:0","tags":["Sorting","Algorithms"],"title":"算法学习之归并排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"0. 常见排序算法性能对比 再贴一张常见排序算法的性能对比，方便查看~ ","date":"2021-05-08","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/:1:0","tags":["Sorting","Algorithms"],"title":"算法学习之归并排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"1. 归并排序 ","date":"2021-05-08","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/:2:0","tags":["Sorting","Algorithms"],"title":"算法学习之归并排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"定义与可视化 归并排序的算法思想是分治，即先将待排序的序列划分成若干子序列，对子序列排序，然后再合并子序列的排序结果。归并排序就是个二叉树的后序遍历 再放一张K神的图，比较清晰，来源 算法步骤 给定一个待排序的序列，归并排序将主要分为两步，拆分、合并： 将序列递归地分成两份，直到子序列的长度为2，拆分停止。如果序列总长度为奇数N，则一份是(N+1)/2，一份是(N-1)/2 对子序列进行合并，每个子序列的合并规则如下 定义两个指针，循环对比指针指向元素的大小，取较小的放入原数组，注意更新指针位置。循环停止条件是有一个指针走到了子序列的末尾，这时剩余元素一定是较大值，直接插入原数组后面即可。 代码 每次递归都将序列一份为二，直到当前序列长度小于或等于2，对两个元素进行比较交换，那么对于长度大于2的子序列，每次都会创建与原序列相同长度的空间，以作为临时的排序结果。python代码如下 def mergesort(nums: List) -\u003e List: def merge(arr_, left_, mid_, right_): ptr1, ptr2, res_ = left_, mid_+1, [] # 遍历ptr1和ptr2，装填res_数组，直到ptr1或ptr2到头 for i in range(right_-left_+1): if ptr1 \u003e mid_ or ptr2 \u003e right_: break if arr_[ptr1] \u003c= arr_[ptr2]: # 注意 '=' 才能让排序稳定 res_.append(arr_[ptr1]) ptr1 += 1 else: res_.append(arr_[ptr2]) ptr2 += 1 # 调用extend将剩余元素都装入数组res_中 if ptr1 \u003e mid_: res_.extend(arr_[ptr2:right_+1]) if ptr2 \u003e right_: res_.extend(arr_[ptr1:mid_+1]) # 替换arr_区间中对应的区域 arr_[left_:right_+1] = res_ def mergesort_rec(arr, left, right): if left \u003e= right: return mid = (right + left) // 2 mergesort_rec(arr, left, mid) mergesort_rec(arr, mid+1, right) merge(arr, left, mid, right) length = len(nums) mergesort_rec(nums, 0, length-1) return nums 空间优化： 我们可以对空间进行优化，实际上一共迭代了log2(N)次， 每次空间占用最大就是N，所以可以创建一个长度与原序列相同的数组，这样就只需维护这一个数组即可，避免频繁开辟空间。当前序列长度小于N时，可以只使用一部分。 def mergesort(nums: List) -\u003e List: def merge(arr_, left_, mid_, right_, tmp_): ptr1, ptr2, index = left_, mid_+1, 0 # 遍历ptr1和ptr2，装填tmp数组，直到ptr1或ptr2到头 for i in range(right_-left_+1): if ptr1 \u003e mid_ or ptr2 \u003e right_: break if arr_[ptr1] \u003c= arr_[ptr2]: # 注意 '=' 才能让排序稳定 tmp_[index] = arr_[ptr1] ptr1, index = ptr1+1, index+1 else: tmp_[index] = arr_[ptr2] ptr2, index = ptr2+1, index+1 # 调用extend将剩余元素都装入数组tmp中 if ptr1 \u003e mid_: tmp_[index:right_-left_+1] = arr_[ptr2:right_+1] if ptr2 \u003e right_: tmp_[index:right_-left_+1] = arr_[ptr1:mid_+1] # 改变arr_区间中的元素顺序 arr_[left_:right_+1] = tmp_[:right_-left_+1] def mergesort_rec(arr, left, right, tmp): if left \u003e= right: return mid = (right + left) // 2 mergesort_rec(arr, left, mid, tmp) mergesort_rec(arr, mid+1, right, tmp) merge(arr, left, mid, right, tmp) length = len(nums) mergesort_rec(nums, 0, length-1, [0]*length) return nums 归并排序特点 归并排序的时间复杂度与空间复杂度和原序列是否有序无关 复杂度分析 设定序列长度为N 时间复杂度 因为需要不断地拆分数组，递归的次数为log2(N)，每次都需要遍历N个元素进行比较和交换，所以总的时间复杂度为𝑂(Nlog2(N)) 空间复杂度 因为使用了额外空间，且极端情况下，大小为N，且递归调用栈的空间复杂度为O(log2(N))，所以总的空间复杂度取较大值，为O(N) 稳定性分析 归并排序是稳定的，因为在比较时，对于相等的元素，优先采用索引较小的，所以保持了相对位置不变 可视化网站 Merge Sort visualize | Algorithms | HackerEarth ","date":"2021-05-08","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/:2:1","tags":["Sorting","Algorithms"],"title":"算法学习之归并排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":" 本文是学习排序系列的第二篇，主要介绍插入排序的进阶版-\u003e希尔排序 注：本文的排序算法默认升序 ","date":"2021-04-28","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/:0:0","tags":["Sorting","Algorithms"],"title":"算法学习之希尔排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"0. 常见排序算法性能对比 再贴一张常见排序算法的性能对比，方便查看~ ","date":"2021-04-28","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/:1:0","tags":["Sorting","Algorithms"],"title":"算法学习之希尔排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"1. 希尔排序(插入)(In-place) ","date":"2021-04-28","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/:2:0","tags":["Sorting","Algorithms"],"title":"算法学习之希尔排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"定义与可视化 希尔排序也叫递减增量排序，其在直接插入排序的基础上，巧妙使用增量的概念，让插入排序的作用对象逐层有序，而递减增量指的是增量的数值依次减小最终为1 ","date":"2021-04-28","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/:2:1","tags":["Sorting","Algorithms"],"title":"算法学习之希尔排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"定义(人话版) OK，说人话，上一篇总结了插入排序的原理和特点，我们知道插入排序在输入序列基本有序的情况下是蛮快的，时间复杂度可以达到O(N)级别，只不过插入排序针对基本逆序的输入处理依旧不够简洁。那么希尔排序，则是插入排序的升级版，通过预处理+插入排序的方案，最优情况下可以达到O(N)的时间复杂度。输入不够有序？先处理成相对有序，再进行插入排序操作就好~ 那么具体如何实现呢？希尔排序中用到了一个名词，叫做增量，记做gap，这个增量的作用是将原输入序列分批，与其直接处理原输入，先处理第1个元素与第gap+1个元素，将二者作为一组进行插入排序，原数组不够有序？其实减小输入规模，也相当于间接地减小无序程度。此外，希尔排序的定义中为什么说递减增量呢？其实换个角度理解，增量越大，每批处理的元素越多，那么增量递减相当于逐渐增加插入排序每次处理的数据规模，而且当前的数据又是在上一个增量时已经提前预处理过了，所以插入排序处理起来会更简单。 ","date":"2021-04-28","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/:2:2","tags":["Sorting","Algorithms"],"title":"算法学习之希尔排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"增量设定\u0026如何递减 最简单的增量方案(折半) 我们先以折半的方案为例，熟悉希尔排序的具体操作过程，便于写代码实现 首先，给定一些定义，我们设定增量为gap，输入序列长度为N，gap初始值为N//2 根据gap的值进行分批插入排序 遍历的起止索引是gap -\u003e (len(N)-1) 当前索引如果是cur，那么当前批的索引是 …, cur-3gap, cur-2gap, cur-gap, cur 将当前批索引对应的元素进行插入排序 将索引cur右移一位，重复上一过程 更新gap的值为 gap = gap//2 gap为0时，遍历结束 在上述过程中，折半增量的作用就是每次都将插入排序的对象数量扩大一倍，而且扩大前后的两批数据并不是相互独立的，而是扩大前的数据已经是有序的。一直到最后，gap为1时，插入排序拿到的数据已经是近乎有序的了，这就是预处理的作用。 极端情况 折半增量虽然简单容易理解，但是存在一种极端的情况，那就是当gap的值等于1之前，可能每批数据都是有序的，这时gap=1，插入排序拿到的序列顺序与原始顺序一致，相当于gap等于1之前的操作都是额外的，这样反而比直接插入排序还要耗时 如上图，gap初始为4，然后为2，你会发现这两种情况对应的数据都已经是有序的。 造成这种情况的原因就是：增量方案不够严谨。事实上，希尔排序的时间复杂度的确取决于增量递减的方案，那么，为了保证分组粗调没有盲区，每一轮的增量需要彼此“互质”，也就是没有除1之外的公约数，这样才能保证希尔排序不会好心办坏事。 所以，为了使增量互质，人们又提出了Hibbard增量：2^k-1[1, 3, 7, 15, …]，后续还有很多其他方案被提出，不过这不是我们关注的重点了。 比较 相比于直接插入排序 希尔排序是不稳定的，数据交换过程中可能丢失稳定性 希尔排序的比较次数和移动次数比直接插入排序要少，N越大效果越明显 希尔排序中增量gap的取法必须满足最后一个步长为1 代码 以折半增量为例 def shellsort(nums: List) -\u003e List: length = len(nums) gap = length while gap \u003e 0: for i in range(gap, length): cur_val = nums[i] last_id = i - gap while last_id \u003e= 0 and nums[last_id] \u003e cur_val: nums[last_id + gap] = nums[last_id] last_id -= gap nums[last_id + gap] = cur_val gap //= 2 return nums 复杂度分析 设定序列长度为N 时间复杂度 最坏时间复杂度为𝑂(𝑁^(3/2))，平均时间复杂度约为𝑂(𝑁^(5/4)) 空间复杂度 因为是原地操作，所以空间复杂度为O(1) 稳定性分析 希尔排序是不稳定的，因为其在插入元素的过程中可能会交换相等元素的顺序。 可视化网站 SORTING ","date":"2021-04-28","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/:2:3","tags":["Sorting","Algorithms"],"title":"算法学习之希尔排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":" 本文是学习排序系列的第一篇，主要介绍一些基本概念，对常见排序算法进行总结，以及介绍三种初级排序算法：冒泡、选择、插入 注：本文的排序算法默认升序 ","date":"2021-04-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/:0:0","tags":["Sorting","Algorithms"],"title":"算法学习之基础排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"0. 写在前面 ","date":"2021-04-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/:1:0","tags":["Sorting","Algorithms"],"title":"算法学习之基础排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"关于排序 排序算法是算法中较为基础的知识，给定一个无需序列，如何使其有序？这个问题目前拥有很多种解决方案，并且不同的方法也会涉及到不同的算法知识，比如常见的比较与非比较策略、迭代与递归的实现、分治策略、对算法的时间复杂度分析等 ","date":"2021-04-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/:1:1","tags":["Sorting","Algorithms"],"title":"算法学习之基础排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"大O表示法 ","date":"2021-04-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/:1:2","tags":["Sorting","Algorithms"],"title":"算法学习之基础排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"排序算法的稳定性 衡量一个排序算法的性能，我们不仅可以使用上述的大O表示法来表示算法的时间和空间复杂度，还可以判断其是否稳定。 如果Ai= Aj，排序前Ai在Aj之前，排序后Ai还在Aj之前，则称这种排序算法是稳定的。通俗地讲就是保证排序前后两个相等的数的相对顺序不变 对于不稳定的排序算法，只要举出一个实例，即可说明它的不稳定性；而对于稳定的排序算法，必须对算法进行分析从而得到稳定的特性。 排序算法是否为稳定的是由具体算法决定的，不稳定的算法在某种条件下可以变为稳定的算法，而稳定的算法在某种条件下也可以变为不稳定的算法。例如，对于冒泡排序，原本是稳定的排序算法，如果将记录交换的条件改成A[i] \u003e= A[i + 1]，则两个相等的记录就会交换位置，从而变成不稳定的排序算法。 排序算法稳定性的好处。排序算法如果是稳定的，那么从一个键上排序，然后再从另一个键上排序，前一个键排序的结果可以为后一个键排序所用。基数排序就是这样，先按低位排序，逐次按高位排序，低位排序后元素的顺序在高位也相同时是不会改变的 ","date":"2021-04-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/:1:3","tags":["Sorting","Algorithms"],"title":"算法学习之基础排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"1. 常见排序算法概览 ","date":"2021-04-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/:2:0","tags":["Sorting","Algorithms"],"title":"算法学习之基础排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"1.1 按照排序方式分类 一种是比较排序，时间复杂度O(nlogn) ~ O(n^2) 基于比较的排序算法，都免不了两种操作：比较与交换，所以在排序的过程中，我们可以通过计算比较操作与交换操作的次数来进一步衡量算法的有效性 交换：冒泡排序、快速排序 插入：简单插入排序、希尔排序 选择：简单选择排序、堆排序 归并：二路归并排序、多路归并排序 另一种是非比较排序，时间复杂度可以达到O(n) 计数排序 桶排序 基数排序 ","date":"2021-04-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/:2:1","tags":["Sorting","Algorithms"],"title":"算法学习之基础排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"1.2 各排序算法对比 ","date":"2021-04-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/:2:2","tags":["Sorting","Algorithms"],"title":"算法学习之基础排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"2. 常见排序算法学习 ","date":"2021-04-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/:3:0","tags":["Sorting","Algorithms"],"title":"算法学习之基础排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"2.1 初级排序算法 先来看三种基于比较的排序算法，这三种算法较容易实现，但却不是最有效的，因为时间复杂度是平方级别。 冒泡排序(交换)(In-place) 冒泡排序是较为初级的排序算法，思想简单，易实现，但其算法复杂度不友好，一般仅做为入门学习。算法核心思想就是通过不断的比较以及交换，使极值元素向一端移动，类似冒泡的过程 给定一个N个元素的数组，冒泡排序将： 比较一对相邻元素（a，b） 如果元素大小关系不正确，交换这两个数（在本例中为a\u003e b）， 重复步骤1和2，直到我们到达数组的末尾（最后一对是第（N-2）和（N-1）项，因为我们的数组从零开始） 到目前为止，最大的元素将在最后的位置。 然后我们将N减少1，并重复步骤1，直到N = 1。 问题分析及优化 原始冒泡排序较为耗时，且其比较次数与序列无序程度无关，即使输入完全有序的序列，比较次数还是N * (N-1) / 2 次 针对上述问题，可以维护一个标志位，如果当前这一层的迭代过程中，没有发生元素位置的交换，那么说明前面所有元素都已经是有序的，就可以结束排序了 代码 def bubblesort(nums: List) -\u003e List: length = len(nums) for i in range(1, length): sort_over = True for j in range(length-i): if nums[j] \u003e nums[j+1]: nums[j], nums[j+1] = nums[j+1], nums[j] sort_over = False if sort_over: return nums return nums 讨论 虽然优化后，冒泡排序在一般情况下运行得更快，但这种改进的想法并没有改变冒泡排序的 O(n^2) 时间复杂性…为什么？ 优化的情况只是针对有序的条件，当序列完全逆序时，冒泡排序的比较次数和交换次数仍然非常多，不够有效 复杂度分析 针对优化后的冒泡排序，设定序列长度为N 时间复杂度 最好情况下，序列完全有序，仅需比较 N-1 次，即可完成排序，无需交换，故时间复杂度为O(N) 最坏情况下，序列完全逆序，需要比较(N-1) + (N-2) + ... + 1 + 0 = N*(N-1)/2，同理，需要交换N*(N-1)/2次，故时间复杂度为O(N^2) 空间复杂度 因为是原地操作，所以空间复杂度为O(1) 是否稳定 冒泡排序是稳定的，因为其不改变相对顺序 选择排序(选择)(In-place) 选择排序也是基于比较的排序，其核心思想是比较(选择)、交换。相比与冒泡排序，选择排序大大减少了交换操作的次数，虽然时间复杂度与冒泡排序相同，但却更加高效 给定一个N个元素的数组，选择排序将从前向后遍历，假设当前元素为L，那么选择排序的方法是维护两部分内容，第一部分是L左侧的序列，该序列是升序有序的，第二部分是L以及L右侧的数据，可以理解为未排序的元素。所谓选择，就是每次都遍历从L到最后一个元素，选择最小的元素，并使其与L的位置交换。宏观上来看就是从L右边找到一个最小的，放到左边，然后不断右移L直到整个序列完全有序。具体可以分为三步 在 [L … N-1]范围内找出最小项目X的位置 用第 L 项交换X 将下限 L 增加1并重复步骤1直到 L = N-2 看到这里，不难发现，相比于冒泡排序，选择排序的比较次数与冒泡排序一致，都是O(n^2)级别，但是实际交换的次数却只有O(n)次，这也是为什么选择排序会比冒泡排序快的原因。 代码 def selectsort(nums: List) -\u003e List: length = len(nums) for i in range(length): min_id = i for j in range(i, length): min_id = j if nums[j] \u003c nums[min_id] else min_id if min_id != i: # 判断是否是当前元素最小，是的话就不用交换 nums[min_id], nums[i] = nums[i], nums[min_id] return nums 复杂度分析 设定序列长度为N 时间复杂度 最好情况下，序列完全有序，需比较 (N-1) + (N-2) + ... + 1 + 0 = N*(N-1)/2 次，即可完成排序，无需交换，故时间复杂度为O(N^2) 最坏情况下，序列完全逆序，需要比较(N-1) + (N-2) + ... + 1 + 0 = N*(N-1)/2，同理，需要交换N-1次(无重复元素)，故时间复杂度为O(N^2) 空间复杂度 因为是原地操作，所以空间复杂度为O(1) 是否稳定 选择排序是不稳定的，因为其在交换元素时可能改变相对顺序 插入排序(插入)(In-place) 插入排序类似‘打扑克’中我们抓牌码牌的过程，并且插入的思想使其平均操作次数小于选择排序，依据比较(交换)、插入的流程，插入排序的速度是三种基础排序算法中最快的 给定一个N个元素的数组，插入排序将从前向后遍历，假设当前元素为L，那么插入排序的方法是维护两部分内容，第一部分是L左侧的序列，该序列是升序有序的，第二部分是L以及L右侧的数据，可以理解为未排序的元素。所谓插入，就是在左侧有序序列中找到当前元素L的位置，使插入L后的序列依旧有序，然后依次右移L。可以总结为两步： 将L依次与L左侧第n个元素比较(n=1,2,…)，我们称被比较的元素叫Ln，如果L大于Ln，交换二者位置，并继续向前比较，直到L小于或等于Ln，设定当前Ln的位置后一位为L，这时插入完毕 更新L，重复1，直到遍历结束 代码 def insertsort(nums: List) -\u003e List: length = len(nums) for i in range(length): cur_val = nums[i] last_id = i - 1 while last_id \u003e= 0 and nums[last_id] \u003e cur_val: nums[last_id + 1] = nums[last_id] last_id -= 1 nums[last_id + 1] = cur_val return nums 复杂度分析 设定序列长度为N 时间复杂度 最好情况下，序列完全有序，外循环需N-1次，内循环主需要比较1次就会发现不需要交换，即可完成排序，故时间复杂度为O(N) 最坏情况下，序列完全逆序，外循环需N-1次，内循环需要比较和交换O(n)级别的次数，故时间复杂度为O(N^2) 空间复杂度 因为是原地操作，所以空间复杂度为O(1) 分析 上述过程说明了，插入排序在输入基本有序的情况下，时间复杂度可以达到O(N)级别，这已经很快了，但是当序列基本逆序的情况下，插入排序较为耗时的步骤在于，不断地比较与交换的操作，我们假设当前元素为L，L前面有K个元素已经处于有序状态，那么序列完全逆序时，L需要与这K个元素逐一比较并交换，对应的时间复杂度就是O(2K)，约等于O(K)级别，这依旧是较为耗时的，改进的方案有两种： 二分 将插入步骤中的比较过程，改为二分法，二分查找的方案比线性查找的时间复杂度低，毕竟是O(logK)与O(K)级别的对比，规模越大越明显，通过二分查找得到当前元素L应该插入的位置后，再将这个位置后面的元素统一后移一位，将L插入即可 预处理 这个思想仅需记住一点，插入排序对基本有序的输入，时间是很快的。 那么所谓的预处理，我们可以通过某种方式使输入先变得相对有序一些，再进行插入排序，这样就会大大降低处理的耗时啦，这个思想其实就对应着插入排序的升级版本—希尔排序，下篇文章会详细介绍～ 是否稳定 插入排序是稳定的，因为其在比较插入的过程中，遇到相等的元素并不进行交换 可视化网页 https://visualgo.net/zh/sorting ","date":"2021-04-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/:3:1","tags":["Sorting","Algorithms"],"title":"算法学习之基础排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"总结 衡量排序算法好坏的标准有两个：复杂度以及稳定性 冒泡排序通过不断比较、交换来使序列中的极值元素向序列的一端移动，形如冒泡 选择排序则是通过选择操作取代了冒泡排序中冗余的交换次数，但却牺牲了稳定性 插入排序在小数量级且序列基本有序时，表现的最快，原因是其在基本有序情况下，时间复杂度最小可以是O(N)级别，且操作次数少于冒泡排序。 注意，复杂度分析是针对数量级进行的，同等数量级下，插入排序的操作次数就比冒泡排序少很多 最后，贴出个人测试的三种排序方式的时间对比，可见插入排序还是厉害的呀 ","date":"2021-04-26","objectID":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/:4:0","tags":["Sorting","Algorithms"],"title":"算法学习之基础排序","uri":"/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F/"},{"categories":["编程算法"],"content":"总结 比较项目 数组 链表 大小定义 声明时给定好，增删会重新定义数组大小 无需指定，在执行过程中自行增长和收缩 元素位置 编译时分配 运行时分配 元素顺序 连续空间 随机空间 增 时间复杂度O(n)， 空间复杂度O(n) 时间复杂度O(1)， 空间复杂度O(1) 删 时间复杂度O(n)， 空间复杂度O(n) 时间复杂度O(1)， 空间复杂度O(1) 查 时间复杂度O(1)， 空间复杂度O(1) 时间复杂度O(n)， 空间复杂度O(1) 注： 数组的增删操作，平均时间复杂度最好情况是在最后一个元素，最坏情况是在第一个元素，平均为O(n/2)，所以等同于O(n)，空间复杂度类似 链表的增删操作，不考虑遍历到需要更改的元素位置所需要的时间复杂度的，所以时间复杂度可以认为是O(1) 因为数组在内存空间是连续的，所以内存利用率，数组要低于链表 注重数据的随机访问效率的话，不考虑数据的增删操作，选择数组 经常增加删除数据，又不是太在意数据访问时间，选择链表 下面内容转自Difference Between Array and Linked List (with Comparison Chart) - Tech Differences 侵删 The major difference between Array and Linked list regards to their structure. Arrays are index based data structure where each element associated with an index. On the other hand, Linked list relies on references where each node consists of the data and the references to the previous and next element. Basically, an array is a set of similar data objects stored in sequential memory locations under a common heading or a variable name. While a linked list is a data structure which contains a sequence of the elements where each element is linked to its next element. There are two fields in an element of linked list. One is Data field, and other is link field, Data field contains the actual value to be stored and processed. Furthermore, the link field holds the address of the next data item in the linked list. The address used to access a particular node is known as a pointer. Another significant difference between an array and linked list is that Array has a fixed size and required to be declared prior, but Linked List is not restricted to size and expand and contract during execution. ","date":"2021-03-17","objectID":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/:1:0","tags":["DataStructure","Coding"],"title":"总结数组与链表的区别[转载]","uri":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["编程算法"],"content":"Comparison Chart ","date":"2021-03-17","objectID":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/:2:0","tags":["DataStructure","Coding"],"title":"总结数组与链表的区别[转载]","uri":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["编程算法"],"content":"Definition of Array An array is defined as a set of a definite number of homogeneous elements or data items. It means an array can contain one type of data only, either all integers, all floating-point numbers, or all characters. Declaration of an array is as follows: int a [10]; Where int specifies the data type or type elements array stores. “a” is the name of an array, and the number specified inside the square brackets is the number of elements an array can store, this is also called size or length of the array. ","date":"2021-03-17","objectID":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/:2:1","tags":["DataStructure","Coding"],"title":"总结数组与链表的区别[转载]","uri":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["编程算法"],"content":"Points to Ponder Let us look at some of the concepts to be remembered about arrays: The individual elements of an array can be accessed by describing the name of the array, followed by index or subscript (determining the location of the element in the array) inside the square brackets. For example, to retrieve 5th element of the array, we need to write a statement a[4]. In any case the elements of an array will be stored in a consecutive memory location. The very first element of the array has index zero [0]. It means the first and last element will be specified as a[0], and a[9] respectively. The number of elements that can be stored in an array, i.e., the size of an array or its length is given by the following equation: (upper bound-lower bound) + 1 For the above array, it would be (9-0) + 1 =10. Where 0 is the lower bound of the array, and 9 is the upper bound of the array. Arrays can be read or written through the loop. If we read the one-dimensional array, it requires one loop for reading and other for writing (printing) the array, for example: a. For reading an array for ( i= 0; i \u003c= 9; i++) { scanf ( “%d”, \u0026a[ i ] ) ; } b. For writing an array for (i = 0 ; i \u003c= 9 ; i++) {printf ( “%d”, a[ i ] ) ; } In the case of a 2-D array, it would require two loops and similarly n-dimensional array would need n loops. ","date":"2021-03-17","objectID":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/:2:2","tags":["DataStructure","Coding"],"title":"总结数组与链表的区别[转载]","uri":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["编程算法"],"content":"Operations performed on arrays Creation of array Traversing an array Insertion of new elements Deletion of required elements. Modification of an element. Merging of arrays ","date":"2021-03-17","objectID":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/:2:3","tags":["DataStructure","Coding"],"title":"总结数组与链表的区别[转载]","uri":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["编程算法"],"content":"Example The following program illustrates the reading and writing of the array. #include\u003cstdio.h\u003e#include\u003cconio.h\u003e void main () { int a[10],i; printf(\"Enter the array\"); for ( i= 0; i \u003c= 9; i++) { scanf ( \"%d\", \u0026a[ i ] ) ; } printf( \"Enter the array\" ); for (i = 0 ; i \u003c= 9 ; i++) { printf ( \"%d\\n\", a[ i ] ) ; } getch (); } ","date":"2021-03-17","objectID":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/:2:4","tags":["DataStructure","Coding"],"title":"总结数组与链表的区别[转载]","uri":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["编程算法"],"content":"Definition of Linked List Linked list is a particular list of some data elements linked to one other. In this every element point to the next element which represents the logical ordering. Each element is called a node, which has two parts. INFO part which stores the information and POINTER which points to the next element. As you know for storing address, we have a unique data structures in C called pointers. Hence the second field of the list must be a pointer type. Types of linked lists are Singly-linked list, Doubly linked list, Circular linked list, Circular double linked list. ","date":"2021-03-17","objectID":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/:2:5","tags":["DataStructure","Coding"],"title":"总结数组与链表的区别[转载]","uri":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["编程算法"],"content":"Operations performed on Linked List Creation Traversing Insertion Deletion Searching Concatenation Display ","date":"2021-03-17","objectID":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/:2:6","tags":["DataStructure","Coding"],"title":"总结数组与链表的区别[转载]","uri":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["编程算法"],"content":"Example The following snippet illustrates the creation of a linked list: struct node { int num; stuct node *next; } start = NULL; void create() { typedef struct node NODE; NODE *p, *q; char choice; first = NULL; do { p = (NODE *) malloc (sizeof (NODE)); printf (\"Enter the data item\\n\"); scanf (\"%d\", \u0026 p -\u003e num); if (p == NULL) { q = start; while (q -\u003e next ! = NULL) { q = q -\u003e next } p -\u003e next = q -\u003e next; q -\u003e = p; } else { p -\u003e next = start; start = p; } printf (\"Do you want to continue (type y or n) ? \\n\"); scanf (\"%c\", \u0026choice) ; } while ((choice == \u0026#39;y\u0026#39;) || (choice == \u0026#39;Y\u0026#39;)); } ","date":"2021-03-17","objectID":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/:2:7","tags":["DataStructure","Coding"],"title":"总结数组与链表的区别[转载]","uri":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["编程算法"],"content":"Key Differences Between Array and Linked List An array is the data structure contains a collection of similar type data elements whereas the Linked list is considered as non-primitive data structure contains a collection of unordered linked elements known as nodes. In the array the elements belong to indexes, i.e., if you want to get into the fourth element you have to write the variable name with its index or location within the square bracket. In a linked list though, you have to start from the head and work your way through until you get to the fourth element. While accessing an element array is fast while Linked list takes linear time so, it is quite bit slower. Operations like insertion and deletion in arrays consume a lot of time. On the other hand, the performance of these operations in Linked lists is fast. Arrays are of fixed size. In contrast, Linked lists are dynamic and flexible and can expand and contract its size. In an array, memory is assigned during compile time while in a Linked list it is allocated during execution or runtime. Elements are stored consecutively in arrays whereas it is stored randomly in Linked lists. The requirement of memory is less due to actual data being stored within the index in the array. As against, there is a need for more memory in Linked Lists due to storage of additional next and previous referencing elements. In addition memory utilization is inefficient in the array. Conversely, memory utilization is efficient in the array. ","date":"2021-03-17","objectID":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/:3:0","tags":["DataStructure","Coding"],"title":"总结数组与链表的区别[转载]","uri":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["编程算法"],"content":"Conclusion Array and Linked lists are the types of data structures differ in their structure, accessing and manipulation methods, memory requirement and utilization. And have particular advantage and disadvantage over its implementation. Consequently, either one can be used as per need. ","date":"2021-03-17","objectID":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/:3:1","tags":["DataStructure","Coding"],"title":"总结数组与链表的区别[转载]","uri":"/%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["系统装机"],"content":"1. 系统安装 关闭secure boot 插上系统盘，开机后狂按ESC，暂停启动，然后弹出BIOS设置，选择启动设备，使用U盘启动 在选择‘Install UBUNTU’之前，按E进入设置，在quiet splash —那处,把—替换为nomodeset,再按F10进入系统进行安装，否则会报错acpi bios error以及花屏！！！ 然后正常选择，我选的最小系统安装，免去安装多余的游戏软件等 分区设置，先选择something else，自己设置分区，如下 设置swap空间:主分区/空间起始/交换空间/大小一般是实际内存1-2倍 设置引导EFI:逻辑分区/空间起始/EFI分区/大小一般1GB 设置挂载的/:这个是ubuntu计算机的安装位置,逻辑分区/空间起始/EXT4/挂载点为/ 最后设置引导,最下面的那个选项,选择之前设置的EFI引导在的那个分区 注意，这里建议不单独分出来/home的空间，直接全都放在/下面就好，免得空间不够难以重新分区 进入安装,完成后会重启,重启后同样按e进入,在quiet splash后加nomodeset再按F10进入 ","date":"2021-03-07","objectID":"/ubuntu_install/:1:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"2. 换源，更新，升级 进入系统后第一步操作应该就是将源改成国内的清华或者阿里，然后运行以下命令 sudo apt update sudo apt upgrade ","date":"2021-03-07","objectID":"/ubuntu_install/:2:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"3. Nvidia驱动安装 上述操作装完系统后，没有显卡驱动是无法进入的，所以必须加上nomodeset 除此之外，进系统后的分辨率应该也不对，会更大一些，这一切的原因都是显卡没有驱动程序，以及没有集显导致的 装一个独显驱动即可，方法： 进入Software \u0026 Updates 在第一个选项卡，ubuntu software处，勾选source code 在第五个选项卡，additional drivers处，选择nvidia驱动 using nvidia driver metapackage from nvidia-driver-450（proprietary） 点击右下角的apply changes，重启即可 ","date":"2021-03-07","objectID":"/ubuntu_install/:3:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"4. 安装常用软件 sudo apt install python python3 gconf-service-backend gconf-service gconf2 ","date":"2021-03-07","objectID":"/ubuntu_install/:4:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"5. 安装小飞机 先确保安装python以及python3 建议使用appimage，方便开机自启动 #! /bin/bash cd ~/Softwares ./electron-ssr-0.2.6.AppImage 自启动 将以上写成脚本，在start application里面添加启动程序，直接查找脚本位置即可，不需要 . 或者 sh 注意权限 ","date":"2021-03-07","objectID":"/ubuntu_install/:5:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"6. 挂载其它ntfs磁盘，实现开机自动挂载 查看磁盘 sudo fdisk -l 安装包 sudo apt install ntfs-3g sudo apt install ntfs-config 查看uuid sudo blkid ​ 创建要挂载的文件夹 mkdir /home/disks sudo mkdir /media/echo/Docs sudo mkdir /media/echo/Storage ​ 修改fstab sudo gedit /etc/fstab 添加以下内容 #Entry for /dev/sda5 : UUID=10AA0A8510AA0A85 /media/echo/Docs ntfs defaults,nodev,nosuid,uid=1000,gid=1000,uhelper=udisks2 0 0 #Entry for /dev/sda1 : UUID=10A8073A10A8073A /media/echo/Storage ntfs defaults,nodev,nosuid,uid=1000,gid=1000,uhelper=udisks2 0 0 #Entry for /dev/nvme0n1p4 : UUID=0BE104A20BE104A2 /home/echo/disks ntfs defaults 0 0 ​ ​ 测试挂载，不报错即为没问题 sudo umount -a sudo mount -a ","date":"2021-03-07","objectID":"/ubuntu_install/:6:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"7. 安装ipgw 找到对应ipgw安装包 sudo chmod +x ipgw sudo mv ipgw /usr/local/bin ipgw version ipgw login -u 1901938 -p xxx -s ","date":"2021-03-07","objectID":"/ubuntu_install/:7:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"8. 安装chrome sudo dpkg -i google-chrome-stable_current_amd64.deb sudo apt upgrade ","date":"2021-03-07","objectID":"/ubuntu_install/:8:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"9. 安装搜狗输入法 先装fcitx sudo apt install fcitx # 如果报错，使用 sudo apt-get install -f 再执行 sudo dpkg -i sogoupinyin_2.3.1.0112_amd64.deb reboot 打开设置，找到 language-\u003e Manage Installed Languages, 將“Keyboard input method system”設定為“fcitx” 在系統中搜索fcitx configuration，點選左下角新增輸入法，在彈出的對話方塊中將Only Show Current Language取消，即可看到sogou Pinyin，選擇新增即可 ","date":"2021-03-07","objectID":"/ubuntu_install/:9:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"10. 安装terminator sudo apt install terminator 刷新配置 cp terminator_config ~/.config/terminator/config ","date":"2021-03-07","objectID":"/ubuntu_install/:10:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"11. 安装typora or run: sudo apt-key adv –keyserver keyserver.ubuntu.com –recv-keys BA300B7755AFCFAE wget -qO - https://typora.io/linux/public-key.asc | sudo apt-key add - add Typora’s repository sudo add-apt-repository ‘deb https://typora.io/linux ./’ sudo apt-get update install typora sudo apt-get install typora ","date":"2021-03-07","objectID":"/ubuntu_install/:11:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"12. 安装CUDA\\CUDNN ","date":"2021-03-07","objectID":"/ubuntu_install/:12:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"cuda10.2 cuda下载列表 https://developer.nvidia.com/cuda-toolkit-archive 选择18.04 cuda10.2 使用deb安装 wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin sudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600 wget https://developer.download.nvidia.com/compute/cuda/10.2/Prod/local_installers/cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb sudo dpkg -i cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb sudo apt-key add /var/cuda-repo-10-2-local-10.2.89-440.33.01/7fa2af80.pub sudo apt-get update sudo apt-get -y install cuda 在bashrc或者zshrc中加入 cuda add export CPATH=/usr/local/cuda/targets/x86_64-linux/include:$CPATH export LD_LIBRARY_PATH=/usr/local/cuda/targets/x86_64-linux/lib:$LD_LIBRARY_PATH export PATH=/usr/local/cuda/bin:$PATH export CUDA_HOME=/usr/local/cuda 使用nvcc -V测试 nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2019 NVIDIA Corporation Built on Wed_Oct_23_19:24:38_PDT_2019 Cuda compilation tools, release 10.2, V10.2.89 安装patch https://developer.nvidia.com/cuda-10.2-download-archive?target_os=Linux\u0026target_arch=x86_64\u0026target_distro=Ubuntu\u0026target_version=1804\u0026target_type=deblocal patch1 sudo dpkg -i cuda-repo-ubuntu1804-10-2-local_10.2.1-1_amd64.deb sudo apt update sudo apt -y upgrade patch2 sudo dpkg -i cuda-repo-ubuntu1804-10-2-local_10.2.2-1_amd64.deb sudo apt update sudo apt -y upgrade ","date":"2021-03-07","objectID":"/ubuntu_install/:12:1","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"cudnn 需要登录，使用google账号登录， 下载 cudnn-10.2-linux-x64-v8.1.1.33 source安装，先解压，出现一个cuda的文件夹 tar -zxf cudnn-10.2-linux-x64-v8.1.1.33.tgz sudo cp cuda/include/cudnn.h /usr/local/cuda/include sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64 sudo chmod a+r /usr/local/cuda/include/cudnn.h sudo chmod a+r /usr/local/cuda/lib64/libcudnn* deb安装-未尝试 要下载的文件也是两个，分别是cuDNN Runtime Library for Ubuntu18.04 (Deb和 [cuDNN Developer Library for Ubuntu18.04 (Deb)] 下载完成后一次安装这两个文件就可以了**（先安装runtime library，再安装developer library）** 至此，CUDA10.2+cuDNN8就成功的在Ubuntu18.04上安装成功了。 更换安装方法！！！！ 由于源码安装的cudnn无法被找到，所以换deb安装 sudo rm /usr/local/cuda/include/cudnn.h sudo rm /usr/local/cuda/lib64/libcudnn* sudo dpkg -i libcudnn8_8.1.0.77-1+cuda10.2_amd64.deb sudo dpkg -i libcudnn8-dev_8.1.0.77-1+cuda10.2_amd64.deb sudo dpkg -i libcudnn8-samples_8.1.0.77-1+cuda10.2_amd64.deb 由于8.1.0无法通过cudnn测试，所以换成7.6.5 又安装了源码tar格式的cudnn 关于查看GPU显卡的状态，除了使用显卡驱动中提供的命令 nvidia-smi 外，推荐使用 https://github.com/Syllo/nvtopgithub.com ","date":"2021-03-07","objectID":"/ubuntu_install/:12:2","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"13. 安装pycharm 由于ubuntu自带了snap，使用snap安装 sudo snap install [pycharm-professional|pycharm-community] –classic sudo snap install pycharm-professional –classic ","date":"2021-03-07","objectID":"/ubuntu_install/:13:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"14. 安装openvpn ","date":"2021-03-07","objectID":"/ubuntu_install/:14:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"补充在ubuntu18.04安装的记录 sudo apt update sudo apt install openvpn 接下来和ubuntu16.04一致，运行脚本以及ovpn文件即可 ","date":"2021-03-07","objectID":"/ubuntu_install/:15:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"15. 安装anaconda wget https://repo.anaconda.com/archive/Anaconda3-2020.11-Linux-x86_64.sh 给权限, 运行 sudo chmod 777 Anaconda3-2020.07-Linux-x86_64.sh bash Anaconda3-2020.07-Linux-x86_64.sh 安装过程中, 在安装目录处修改目录, 第二个问题选yes ","date":"2021-03-07","objectID":"/ubuntu_install/:16:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"16. 安装git sudo apt install -y git 自动保存账户密码 git config –global -e -\u003e 添加以下行 [credential] helper = store ","date":"2021-03-07","objectID":"/ubuntu_install/:17:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"17. 安装zsh 确保安装了git https://ohmyz.sh/#install https://github.com/romkatv/powerlevel10k sudo apt-get install zsh sh -c “$(wget https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -)” git clone –depth=1 https://gitee.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions ","date":"2021-03-07","objectID":"/ubuntu_install/:18:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"18. 安装opencv ","date":"2021-03-07","objectID":"/ubuntu_install/:19:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"19. 安装ros sudo sh -c ‘echo “deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main” \u003e /etc/apt/sources.list.d/ros-latest.list’ sudo apt-key adv –keyserver ‘hkp://keyserver.ubuntu.com:80’ –recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654 Executing: /tmp/apt-key-gpghome.GnF5MH9S4s/gpg.1.sh –keyserver hkp://keyserver.ubuntu.com:80 –recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654 gpg: key F42ED6FBAB17C654: public key “Open Robotics info@osrfoundation.org” imported gpg: Total number processed: 1 gpg: imported: 1 报错 /sbin/ldconfig.real: /usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8 is not a symbolic link /sbin/ldconfig.real: /usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudnn_adv_train.so.8 is not a symbolic link /sbin/ldconfig.real: /usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8 is not a symbolic link /sbin/ldconfig.real: /usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudnn_ops_train.so.8 is not a symbolic link /sbin/ldconfig.real: /usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8 is not a symbolic link /sbin/ldconfig.real: /usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudnn.so.8 is not a symbolic link /sbin/ldconfig.real: /usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8 is not a symbolic link sudo ln -sf libcudnn_adv_infer.so.8.1.1 libcudnn_adv_infer.so.8 sudo ln -sf libcudnn_adv_infer.so.8 libcudnn_adv_infer.so sudo ln -sf libcudnn_adv_train.so.8.1.1 libcudnn_adv_train.so.8 sudo ln -sf libcudnn_adv_train.so.8 libcudnn_adv_train.so sudo ln -sf libcudnn_cnn_train.so.8.1.1 libcudnn_cnn_train.so.8 sudo ln -sf libcudnn_cnn_train.so.8 libcudnn_cnn_train.so sudo ln -sf libcudnn_ops_infer.so.8.1.1 libcudnn_ops_infer.so.8 sudo ln -sf libcudnn_ops_train.so.8.1.1 libcudnn_ops_train.so.8 sudo ln -sf libcudnn_ops_train.so.8 libcudnn_ops_train.so sudo ln -sf libcudnn.so.8.1.1 libcudnn.so.8 sudo ln -sf libcudnn.so.8 libcudnn.so 执行 sudo rosdep init 报错 sudo: rosdep: command not found 执行 sudo apt install rospack-tools 开代理 sudo rosdep init rosdep update 写入bashrc以及zshrc alias ros=‘source /opt/ros/melodic/setup.zsh’ ","date":"2021-03-07","objectID":"/ubuntu_install/:20:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"20. 安装hexo\u0026Gitbook\u0026slidev ","date":"2021-03-07","objectID":"/ubuntu_install/:21:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"1. 安装nodejs v10.x https://github.com/nodesource/distributions curl -fsSL https://deb.nodesource.com/setup_10.x | sudo -E bash - sudo apt-get install -y nodejs ","date":"2021-03-07","objectID":"/ubuntu_install/:21:1","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"2. 安装Git[略] ","date":"2021-03-07","objectID":"/ubuntu_install/:21:2","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"3. 安装Hexo npm install hexo PATH=\"$PATH:/home/echo/disks/HexoBlogs/node_modules/.bin\" ","date":"2021-03-07","objectID":"/ubuntu_install/:21:3","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"4. 安装Gitbook sudo npm install -g gitbook-cli gitbook init 将node升级到了14，但是发现hexo不好用，无法hexo d，所以降级到12，但是gitbook还不好使，于是修改gitbook 查看和更改node版本 node -v sudo n 查看hexo版本 hexo -v ","date":"2021-03-07","objectID":"/ubuntu_install/:21:4","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"6. 重装hexo以及部署新的博客主题，还有gitbook[2021-6-10] 解决npm全局安装的问题 在 /home 下 mkdir ~/.npm-global npm config set prefix ‘~/.npm-global’ # 设置npm全局包的安装路径: export PATH=~/.npm-global/bin:$PATH # 在用户的根目录下查看有没有.profile文件, 如果没有就创建 source ~/.profile 安装hexo npm install -g hexo-cli | 注：还有第二种安装方式 在blog目录下安装 npm install hexo 然后在 ~/.profile中添加路径，就可以在终端启动hexo命令了 PATH=\"$PATH:/home/echo/disks/blog/node_modules/.bin\" 接下来就可以初始化并创建博客了，新建一个博客文件夹（原来的HexoBlogs被我弄的坏了，运行命令报错） hexo init blog #初始化博客站点 cd blog npm install #安装依赖 把原来的博客文件夹 HexoBlogs路径下的 source 拷贝到新建的 blog对应的source下面 运行命令 hexo g \u0026 hexo s 这时没改config里面的主题，还应该是可以显示原来博客内容的，只是主题不对 更改主题为butterfly 在blog目录下，开终端，先下载，然后安装渲染器 git clone -b master https://github.com/jerryc127/hexo-theme-butterfly.git themes/butterfly npm install hexo-renderer-pug hexo-renderer-stylus –save npm install hexo-deployer-git –save npm install –save hexo-word-counter ","date":"2021-03-07","objectID":"/ubuntu_install/:21:5","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"21. 安装deepin相关 deepin wine基础框架，星外之神那个不好用，下载下面的安装 https://github.com/chenyingzhou/deepin-wine-ubuntu deepin wine相关软件 http://packages.deepin.com/deepin/pool/non-free/d/ 下载里面的deepin.com.wechat/ 以及 deepin.com.qq.office/ 这两个是好用的 dpkg安装 sudo apt install chrome-gnome-shell sudo apt install gnome-shell-extensions 除此之外，还需要安装topicons plus插件，然后使用tweak打开插件，方便图标显示 ","date":"2021-03-07","objectID":"/ubuntu_install/:22:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"微信 解决中文乱码问题 装完后中文乱码，按照下列教程 sudo gedit /opt/deepinwine/tools/run.sh sudo gedit /opt/deepinwine/tools/run_v2.sh 找到WINE_CMD 修改为： WINE_CMD=“LC_ALL=zh_CN.UTF-8 deepin-wine” 然后下载字体，更换 修改字体 下载字体msyh.ttc, 下载地址一：蓝奏云 （推荐）https://www.lanzous.com/i5wivmd 下载地址二：百度网盘 链接: https://pan.baidu.com/s/1rkjkmGJlpdaijCEWi7TZIw 提取码: btxw 将下载的字体解压，然后： cp msyh.ttc ~/.deepinwine/Deepin-WeChat/drive_c/windows/Fonts 修改系统注册表 gedit ~/.deepinwine/Deepin-WeChat/system.reg 更改以下两行内容为： “MS Shell Dlg”=“msyh” “MS Shell Dlg 2”=“msyh” gedit msyh_config.reg 在文件msyh_config.reg内添加如下内容： REGEDIT4 [HKEY_LOCAL_MACHINE\\Software\\Microsoft\\Windows NT\\CurrentVersion\\FontLink\\SystemLink] “Lucida Sans Unicode”=“msyh.ttc” “Microsoft Sans Serif”=“msyh.ttc” “MS Sans Serif”=“msyh.ttc” “Tahoma”=“msyh.ttc” “Tahoma Bold”=“msyhbd.ttc” “msyh”=“msyh.ttc” “Arial”=“msyh.ttc” “Arial Black”=“msyh.ttc” 注册字体 deepin-wine regedit msyh_config.reg 解决中心黑框问题 https://blog.diqigan.cn/posts/wine-wechat-black-square-fix.html 按照操作，做一遍，调试了一下sleep的值，改为0的话就成功了 ","date":"2021-03-07","objectID":"/ubuntu_install/:22:1","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"22. 定制Mac主题 未尝试 安装gnome-tweak-tool 和 chrome-gnome-shell 插件 (sudo aptitude install [name]) 安装GTK3主题 =\u003e X-Arc-Collection 使用tweak载入应用程序主题 =\u003e tweak — 外观 — 应用程序 — 选择X-Arc-Collection 安装gnome-shell 主题 =\u003e macOS High Sierra 安装gnome-shell 插件 =\u003e User Themes ( 之后重启Gnome =\u003e [Alt + F2] \u0026 [输入 r] \u0026 [点击 Enter] ) 使用tweak载入shell主题 =\u003e tweak — 外观 — shell — 选择Sierra shell主题 下载Mac图标主题 la-capitaine-icon-theme 或 McMojave-circle 图标文件夹移动到 ~/.icons目录下(没有则新建目录) 使用tweak载入icon主题 =\u003e tweak — 外观 — 图标 — 选择对应的图标主题 安装gnome-shell插件 =\u003e Dash to dock (将原生dock转变为可定制的浮动dock) 定制firefox主题 =\u003e Majave-gtk-theme ","date":"2021-03-07","objectID":"/ubuntu_install/:23:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"23. 安装handbrake sudo add-apt-repository ppa:stebbins/handbrake-releases sudo apt update sudo apt-get install handbrake-gtk ","date":"2021-03-07","objectID":"/ubuntu_install/:24:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"24. 安装ffmpeg https://octopuslian.github.io/2019/11/13/ubuntu1804-ffmpeg-install/ 安装在/home/echo/softwares下 可执行文件在ffmerg_install/bin下，将两个文件复制到/usr/local/bin下面 ","date":"2021-03-07","objectID":"/ubuntu_install/:25:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"25.安装视频播放软件 vlc ","date":"2021-03-07","objectID":"/ubuntu_install/:26:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"26. 安装notion https://appmaker.xyz/web2desk/将notion桌面化 解压后，找到notion，./执行即可 因难于使用，放弃 使用snap安装软件版notion sudo snap install notion-snap sudo apt install fonts-wqy-zenhei # 解决部分字体变为楷体的问题 ","date":"2021-03-07","objectID":"/ubuntu_install/:27:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"27. 其他appimage 将其放在/home/echo/softwares下，使用terminator右键执行 ","date":"2021-03-07","objectID":"/ubuntu_install/:28:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"28. 安装mendeley 下载软件deb，安装 由于使用了sudo打开，导致正常权限无法打开软件 sudo chown -R $(whoami) ~/.local/share/data/Mendeley Ltd. 运行，注意空格 sudo chown -R echo ~/.local/share/data/Mendeley\\ Ltd. 解决！ 此外，由于1.19.8版本没有文献搜索，所以最好使用1.19.6 https://www.mendeley.com/autoupdates/installers/1.19.6 ","date":"2021-03-07","objectID":"/ubuntu_install/:29:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"29. 安装flameshot sudo apt install flameshot 更改默认截图键为flameshot On Ubuntu (Tested on 18.04) To use Flameshot instead of the default screenshot application in Ubuntu we need to remove the binding on Prt Sc key, and then create a new binding for /usr/bin/flameshot gui (adaptated from Pavel’s answer on AskUbuntu). Remove the binding on Prt Sc using the following command. gsettings set org.gnome.settings-daemon.plugins.media-keys screenshot ‘[]’ Go to Settings \u003e Device \u003e Keyboard and press the ‘+’ button at the bottom. Name the command as you like it, e.g. flameshot. And in the command insert /usr/bin/flameshot gui. Then click “Set Shortcut..” and press Prt Sc. This will show as “print”. Now every time you press Prt Sc, it will start the Flameshot GUI instead of the default application. ","date":"2021-03-07","objectID":"/ubuntu_install/:30:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"30. 安装filezilla sudo apt-get install filezilla ","date":"2021-03-07","objectID":"/ubuntu_install/:31:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"31. 安装youtube-dl \u0026\u0026 annie ","date":"2021-03-07","objectID":"/ubuntu_install/:32:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"youtube-dl sudo curl -L https://yt-dl.org/downloads/latest/youtube-dl -o /usr/local/bin/youtube-dl sudo chmod a+rx /usr/local/bin/youtube-dl ","date":"2021-03-07","objectID":"/ubuntu_install/:32:1","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"annie wget https://github.com/iawia002/annie/releases/download/0.10.3/annie_0.10.3_Linux_64-bit.tar.gz tar zxvf annie_*.tar.gz mv annie /usr/local/bin/ ","date":"2021-03-07","objectID":"/ubuntu_install/:32:2","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"32. 安装Tex相关 sudo apt update sudo apt install texlive-full sudo apt install texstudio ","date":"2021-03-07","objectID":"/ubuntu_install/:33:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"33.右键打开terminator https://blog.csdn.net/bestBT/article/details/81221378 ","date":"2021-03-07","objectID":"/ubuntu_install/:34:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"34.更新cmake 不知什么原因，cmake版本是3.10，无法安装pcdet里需要的spconv 故升级到3.19.6 ./bootstrap –prefix=/usr make -jproc sudo make install 使用cmake --version查看版本 ","date":"2021-03-07","objectID":"/ubuntu_install/:35:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"35. 安装tensorrt 在官网下载对应的版本，TensorRT-7.0.0.11.Ubuntu-18.04.x86_64-gnu.cuda-10.2.cudnn7.6 下载tar版本以及deb版本 ","date":"2021-03-07","objectID":"/ubuntu_install/:36:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"安装tar到python tar版本的解压到 /home/echo/misc/extra_libs/ 同时在zshrc中加入 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/echo/misc/extra_libs/TensorRT-7.0.0.11.Ubuntu-18.04.x86_64-gnu.cuda-10.2.cudnn7.6/TensorRT-7.0.0.11/lib 进入到python环境，然后到TensorRT-7.0.0.11目录下，打开终端执行： cd python pip install tensorrt-7.0.0.11-cp37-none-linux_x86_64.whl cd .. cd uff pip install uff-0.6.5-py2.py3-none-any.whl cd .. cd graphsurgeon pip install graphsurgeon-0.4.1-py2.py3-none-any.whl 测试下 python import tensorrt # 无反应即为成功 ","date":"2021-03-07","objectID":"/ubuntu_install/:36:1","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"安装deb版本到c++ $ sudo dpkg -i nv-tensorrt-repo-ubuntu1804-cuda10.2-trt7.0.0.11-ga-20191216_1-1_amd64.deb $ sudo apt-key add /var/nv-tensorrt-repo-cuda10.2-trt7.0.0.11-ga-20191216/7fa2af80.pub $ sudo apt-get update $ sudo apt-get install tensorrt ","date":"2021-03-07","objectID":"/ubuntu_install/:36:2","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"$ dpkg -l | grep TensorRT ii libnvinfer-bin 7.0.0-1+cuda10.2 amd64 TensorRT binaries ii libnvinfer-dev 7.0.0-1+cuda10.2 amd64 TensorRT development libraries and headers ii libnvinfer-doc 7.0.0-1+cuda10.2 all TensorRT documentation ii libnvinfer-plugin-dev 7.0.0-1+cuda10.2 amd64 TensorRT plugin libraries ii libnvinfer-plugin7 7.0.0-1+cuda10.2 amd64 TensorRT plugin libraries ii libnvinfer-samples 7.0.0-1+cuda10.2 all TensorRT samples ii libnvinfer7 7.0.0-1+cuda10.2 amd64 TensorRT runtime libraries ii libnvonnxparsers-dev 7.0.0-1+cuda10.2 amd64 TensorRT ONNX libraries ii libnvonnxparsers7 7.0.0-1+cuda10.2 amd64 TensorRT ONNX libraries ii libnvparsers-dev 7.0.0-1+cuda10.2 amd64 TensorRT parsers libraries ii libnvparsers7 7.0.0-1+cuda10.2 amd64 TensorRT parsers libraries ii tensorrt 7.0.0.11-1+cuda10.2 amd64 Meta package of TensorRT 说明安装成功 ","date":"2021-03-07","objectID":"/ubuntu_install/:37:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"36. 安装苹果主题 https://zhuanlan.zhihu.com/p/71588449 按照以上链接执行即可 sudo apt install gnome-tweak-tool gnome-shell-extensions chrome-gnome-shell sudo apt-get install gtk2-engines-murrine gtk2-engines-pixbuf sudo add-apt-repository ppa:dyatlov-igor/sierra-theme sudo apt update sudo apt install sierra-gtk-theme git clone https://github.com/USBA/Cupertino-iCons sudo unzip -o Cupertino-iCons.zip -d /usr/share/icons 安装gnome插件的方法如下 https://zhuanlan.zhihu.com/p/36265103 ","date":"2021-03-07","objectID":"/ubuntu_install/:38:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"37. 安装惠普打印机驱动 sudo apt-get install hplip hplip-gui 然后找到hplip toolsbox，按照提示安装即可 ","date":"2021-03-07","objectID":"/ubuntu_install/:39:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"其他小工具 小火车 sudo apt install sl # 使用sl调用 代码雨 sudo apt install cmatrix CPU内存等显示插件 https://www.sohu.com/a/301992941_495675 sudo apt-get install gir1.2-gtop-2.0 gir1.2-networkmanager-1.0 gir1.2-clutter-1.0 打开Ubuntu软件，然后搜索“system monitor extension” 选择system monitor 可以显示network的那一个 ","date":"2021-03-07","objectID":"/ubuntu_install/:40:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"更改锁屏输入密码时的壁纸 sudo cp /usr/share/gnome-shell/theme/ubuntu.css /usr/share/gnome-shell/theme/ubuntu.css.bak sudo gedit /usr/share/gnome-shell/theme/ubuntu.css 修改配置文件，记得修改路径 #lockDialogGroup { background: #2c001e url(resource:///org/gnome/shell/theme/noise-texture.png); background-repeat: repeat; } —————- 改为 ———————– #lockDialogGroup { background: #2c001e url(file:///home/echo/.lock.jpg); height: 100%; background-size: contain; background-attachment: fixed; background-position: 0px 0px; background-repeat: repeat; } 这个版本可以解决多显示器问题 注意壁纸的分辨率应该符合显示器分辨率 ","date":"2021-03-07","objectID":"/ubuntu_install/:41:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"安装Ceres http://ceres-solver.org/installation.html 官网安装教程 http://ceres-solver.org/ceres-solver-2.0.0.tar.gz 下载最新的 2.0.0 的压缩包 CMake sudo apt-get install cmake google-glog + gflags sudo apt-get install libgoogle-glog-dev libgflags-dev BLAS \u0026 LAPACK sudo apt-get install libatlas-base-dev Eigen3 sudo apt-get install libeigen3-dev SuiteSparse and CXSparse (optional) sudo apt-get install libsuitesparse-dev tar zxf ceres-solver-2.0.0.tar.gz mkdir ceres-bin cd ceres-bin cmake ../ceres-solver-2.0.0 make -j3 make test sudo make install # 这个和官网安装教程不一致，需要sudo 2.0.0版本不满足，安装1.14 进入 ceres-bin 执行sudo make uninstall 然后解压 mkdir ceres-bin cd ceres-bin cmake ../ceres-solver-1.14.0 make -j3 make test sudo make install # 这个和官网安装教程不一致，需要sudo ","date":"2021-03-07","objectID":"/ubuntu_install/:42:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["系统装机"],"content":"安装网络可视化工具zetane https://github.com/shanjiayao/viewer ","date":"2021-03-07","objectID":"/ubuntu_install/:43:0","tags":["ubuntu"],"title":"ubuntu18_04升级记录","uri":"/ubuntu_install/"},{"categories":["编程算法"],"content":"转载自： https://liam.page/2017/06/30/understanding-yield-in-python/ 生成器 = 迭代器 + yeild ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:0:0","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"概述 逐个获取元素的过程，就是「迭代」 迭代器中没有元素时，调用 next() 方法会抛出 StopIteration 异常 如果提供了 __iter__() 或者 __getitem__() 方法，那么该类的对象就是可迭代的 如果一个函数包含 yield 表达式，那么它是一个生成器函数；调用它会返回一个特殊的迭代器，称为生成器 对生成器执行next()：从上一次在 yield 表达式暂停的状态恢复，继续执行到下一次遇见 yield 表达式 在 Python 3 中，range 相当于 Python 2 中的 xrange，大大节省了内存占用 python3.3以后，新增了yeild from语法， yield from g相当于for v in g: yield v 对于一个生成器对象g，可以使用list(g)将其转换成列表 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:1:0","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"迭代、可迭代、迭代器 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:2:0","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"迭代（iteration）与可迭代（iterable） 迭代是一种操作，是遍历方式的一种（另一种是递归）；可迭代是对象的一种特性。 很多数据都是「容器」；它们包含了很多其他类型的元素。实际使用容器时，我们常常需要逐个获取其中的元素。逐个获取元素的过程，就是「迭代」。 # iteration a_list = [1, 2, 3] for i in a_list: print(i) 如果我们可以从一个对象中，逐个地获取元素，那么我们就说这个对象是「可迭代的」。 Python 中的顺序类型，都是可迭代的（list, tuple, string）。其余包括 dict, set, file 也是可迭代的。对于用户自己实现的类型，如果提供了 __iter__() 或者 __getitem__() 方法，那么该类的对象也是可迭代的。 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:2:1","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"迭代器（iterator） 迭代器是一种对象。 迭代器抽象的是一个「数据流」，是只允许迭代一次的对象。对迭代器不断调用 next() 方法，则可以依次获取下一个元素；当迭代器中没有元素时，调用 next() 方法会抛出 StopIteration 异常。迭代器的 __iter__() 方法返回迭代器自身；因此迭代器也是可迭代的。 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:2:2","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"迭代器协议（iterator protocol） 迭代器协议指的是容器类需要包含一个特殊方法。 如果一个容器类提供了 __iter__() 方法，并且该方法能返回一个能够逐个访问容器内所有元素的迭代器，则我们说该容器类实现了迭代器协议。 Python 中的迭代器协议和 Python 中的 for 循环是紧密相连的。 # iterator protocol and for loop for x in something: print(x) Python 处理 for 循环时，首先会调用内建函数 iter(something)，它实际上会调用 something.__iter__()，返回 something 对应的迭代器。而后，for 循环会调用内建函数 next()，作用在迭代器上，获取迭代器的下一个元素，并赋值给 x。此后，Python 才开始执行循环体。 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:2:3","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"生成器、yield 表达式 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:3:0","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"生成器函数（generator function）和生成器（generator） 生成器函数是一种特殊的函数；生成器则是特殊的迭代器。 如果一个函数包含 yield 表达式，那么它是一个生成器函数；调用它会返回一个特殊的迭代器，称为生成器。 def func(): return 1 def gen(): yield 1 print(type(func)) # \u003cclass 'function'\u003e print(type(gen)) # \u003cclass 'function'\u003e print(type(func())) # \u003cclass 'int'\u003e print(type(gen())) # \u003cclass 'generator'\u003e 如上，生成器 gen 看起来和普通的函数没有太大区别。仅只是将 return 换成了 yield。用 type() 函数打印二者的类型也能发现，func 和 gen 都是函数。然而，二者的返回值的类型就不同了。func() 是一个 int 类型的对象；而 gen() 则是一个迭代器对象。 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:3:1","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"yield 表达式 如前所述，如果一个函数定义中包含 yield 表达式，那么该函数是一个生成器函数（而非普通函数）。实际上，yield 仅能用于定义生成器函数。 与普通函数不同，生成器函数被调用后，其函数体内的代码并不会立即执行，而是返回一个生成器（generator-iterator）。当返回的生成器调用成员方法时，相应的生成器函数中的代码才会执行。 def square(): for x in range(4): yield x ** 2 square_gen = square() for x in square_gen: print(x) 前面说到，for 循环会调用 iter() 函数，获取一个生成器；而后调用 next() 函数，将生成器中的下一个值赋值给 x；再执行循环体。因此，上述 for 循环基本等价于： genitor = square_gen.__iter__() while True: x = geniter.next() # Python 3 是 __next__() print(x) 注意到，square 是一个生成器函数；作为它的返回值，square_gen 已经是一个迭代器；迭代器的 __iter__() 返回它自己。因此 geniter 对应的生成器函数，即是 square。 每次执行到 x = geniter.next() 时，square 函数会从上一次暂停的位置开始，一直执行到下一个 yield 表达式，将 yield 关键字后的表达式列表返回给调用者，并再次暂停。注意，每次从暂停恢复时，生成器函数的内部变量、指令指针、内部求值栈等内容和暂停时完全一致。 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:3:2","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"生成器的方法 生成器有一些方法。调用这些方法可以控制对应的生成器函数；不过，若是生成器函数已在执行过程中，调用这些方法则会抛出 ValueError 异常。 generator.next()：从上一次在 yield 表达式暂停的状态恢复，继续执行到下一次遇见 yield 表达式。当该方法被调用时，当前 yield 表达式的值为 None，下一个 yield 表达式中的表达式列表会被返回给该方法的调用者。若没有遇到 yield 表达式，生成器函数就已经退出，那么该方法会抛出 StopIterator 异常。 generator.send(value)：和 generator.next() 类似，差别仅在与它会将当前 yield 表达式的值设置为 value。 generator.throw(type[, value[, traceback]])：向生成器函数抛出一个类型为 type 值为 value 调用栈为 traceback 的异常，而后让生成器函数继续执行到下一个 yield 表达式。其余行为与 generator.next() 类似。 generator.close()：告诉生成器函数，当前生成器作废不再使用。 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:3:3","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"举例和说明 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:3:4","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"如果你看不懂生成器函数 如果你还是不太能理解生成器函数，那么大致上你可以这样去理解。 在函数开始处，加入 result = list()； 将每个 yield 表达式 yield expr 替换为 result.append(expr)； 在函数末尾处，加入 return result。 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:3:5","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"关于「下一个」yield 表达式 介绍「生成器的方法」时，我们说当调用 generator.next() 时，生成器函数会从当前位置开始执行到下一个 yield 表达式。这里的「下一个」指的是执行逻辑的下一个。因此 def f123(): yield 1 yield 2 yield 3 for item in f123(): # 1, 2, and 3, will be printed print(item) def f13(): yield 1 while False: yield 2 yield 3 for item in f13(): # 1 and 3, will be printed print(item) ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:3:6","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"使用 send() 方法与生成器函数通信 def func(): x = 1 while True: y = (yield x) x += y geniter = func() geniter.next() # 1 geniter.send(3) # 4 geniter.send(10)# 14 此处，生成器函数 func 用 yield 表达式，将处理好的 x 发送给生成器的调用者；与此同时，生成器的调用者通过 send 函数，将外部信息作为生成器函数内部的 yield 表达式的值，保存在 y 当中，并参与后续的处理。 这一特性是使用 yield 在 Python 中使用协程的基础。 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:3:7","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["编程算法"],"content":"yield 的好处 Python 的老用户应该会熟悉 Python 2 中的一个特性：内建函数 range 和 xrange。其中，range 函数返回的是一个列表，而 xrange 返回的是一个迭代器。 在 Python 3 中，range 相当于 Python 2 中的 xrange；而 Python 2 中的 range 可以用 list(range()) 来实现。 Python 之所以要提供这样的解决方案，是因为在很多时候，我们只是需要逐个顺序访问容器内的元素。大多数时候，我们不需要「一口气获取容器内所有的元素」。比方说，顺序访问容器内的前 5 个元素，可以有两种做法： 获取容器内的所有元素，然后取出前 5 个； 从头开始，逐个迭代容器内的元素，迭代 5 个元素之后停止。 显而易见，如果容器内的元素数量非常多（比如有 10 ** 8 个），或者容器内的元素体积非常大，那么后一种方案能节省巨大的时间、空间开销。 现在假设，我们有一个函数，其产出（返回值）是一个列表。而若我们知道，调用者对该函数的返回值，只有逐个迭代这一种方式。那么，如果函数生产列表中的每一个元素都需要耗费非常多的时间，或者生成所有元素需要等待很长时间，则使用 yield 把函数变成一个生成器函数，每次只产生一个元素，就能节省很多开销了。 ","date":"2021-03-06","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/:4:0","tags":["python","Coding","yeild"],"title":"Python还债日记之迭代器/生成器/yeild","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Byeild%E5%85%B3%E9%94%AE%E5%AD%97/"},{"categories":["深度学习"],"content":" 记录学习Transformer过程中的一些个人理解与思考 ","date":"2021-01-27","objectID":"/transformer%E4%B9%8Bself-attention/:0:0","tags":["Transformer","DeepLearning"],"title":"Transformer之self-attention机制","uri":"/transformer%E4%B9%8Bself-attention/"},{"categories":["深度学习"],"content":"self-attention ","date":"2021-01-27","objectID":"/transformer%E4%B9%8Bself-attention/:1:0","tags":["Transformer","DeepLearning"],"title":"Transformer之self-attention机制","uri":"/transformer%E4%B9%8Bself-attention/"},{"categories":["深度学习"],"content":"1. 宏观理解 关于注意力机制，在此不做赘述，不过关于自注意力，可能还是先要从宏观上分析一下他是如何进行工作的 给定一个输入，可以是sequence或是图片或是点云，Transformer如何利用self-attention机制对输入进行深层次理解与学习？这其实就是self-attention的工作方式，总的来说，可以概括为 self-attention[自注意力层]是对输入信息做深层自我剖析，探究不同输入之间的相关性 在编码阶段，self-attention让每个当前向量“看”到其他位置向量的信息，进而编码成对应的特征 比如这张图片，在编码it时，self-attention就计算了it和其他单词向量之间的关系，进而让网络更好的编码it的特征 ","date":"2021-01-27","objectID":"/transformer%E4%B9%8Bself-attention/:1:1","tags":["Transformer","DeepLearning"],"title":"Transformer之self-attention机制","uri":"/transformer%E4%B9%8Bself-attention/"},{"categories":["深度学习"],"content":"2. 微观分析 下面从细节上分析self-attention机制，以问题的方式记录 输入输出？ 一般来说，self-attention的输入和输出一般都是特征张量，因为其主要作用是通过编码来对特征进行加权，除此之外还会涉及到Pos Encoding需要的位置信息等 如何对输入进行学习？ 这里其实self-attention可以抽象地表达输入信息，如下图 输入向量化（Embedding） 如果输入的是原始数据，那么需要将其向量化，进行 Embedding Vector 转换，其实就是转换成固定大小的特征向量，毕竟同一尺寸的特征对于网络比较友好 从三个角度学习输入的特征（Queries、Keys、Values） 在self-attention中，可以理解为将输入拆解成三个参数，分别是Q K V，这个拆解是指输入的特征经过一个共享权值的网络层学习三个参数矩阵的具体值，如下图 其中Q代表着query，K代表Key，这两个向量的作用是对每个输入的特征向量做加权，让当前这个输入向量可以看到其他位置的特征信息，具体的做法就是，每个当前位置的Q与其他所有位置的K依次进行点积运算，得到的结果我们认为一定程度上代表了两个位置之间的相关性 V的意义，我个人理解很大程度上是对输入的更鲁棒的表达，类似于卷积网络提取图片特征，这个V经过了矩阵Wv之后，其本身应该学习到了输入特征向量的一些高层次特征，这些特征较为鲁棒，所以可以更好的用来表达自身特征向量 计算self-attention的三步骤 那下面来说具体如何计算self-attention的，以及上面所有的Q、K、V是如何使用的 第一步，通过共享权值的参数矩阵W学习出三个矩阵Q、K、V 第二步，重复计算每个Q和所有K的内积，得到scaled inner product，并除以维度的开方以及做softmax归一化处理，这样就得到了每个向量的注意力加权得分，0-1之间 第三步，将每个向量的注意力加权得分与V进行点乘，也就是对每个向量进行注意力加权，在这个过程中，将Q和K计算得到的特征编码到了加权之后的V中 这里的自注意力，指的是，当前向量对全局的注意力，也可以理解为当前向量和全局所有向量的关联程度 self-attention与编码的关系 这里所谓的自注意力机制，就是在编码的过程中，增加全局线索，具体做法就是将当前向量和其他向量做计算，得到相关性，这个相关性经过正则化之后作为权重，分别乘上所有向量，最后将计算结果加和，其实上述过程就是在对当前向量编码的过程中，设定编码方式为计算当前向量与所有向量的相关度，然后加权求和，得到当前向量的特征编码。而体现全局线索的部分就是当前向量与所有向量计算相关性的操作 并行化加速的可能 矩阵运算 注意，上述说的计算self-attention过程中，都可以通过矩阵来对运算进行表达，这也实现了加速的目的，相比于RNN的序列化计算，Transformer使用的self-attention就会快得多 一些问题 为什么学习q k v的参数矩阵是权值共享的？能否单独计算？ 这里的权值共享，指的是所有的输入都经过同样的W（包括Wq Wk Wv）来学习q k v，而如果权值不共享的话，应该是每个输入单独学习一个权重矩阵 q k v的维度一定全部相同么？ 不是，是q和k计算relation之后得到的张量维度与v相同即可，因为relation function不仅有点乘这一种，也有相减 为什么q和k是做点乘的？这样可以很好的表达向量之间的相关性么？ 这种做法是通用的，此外，这种方式还有一种名字，叫做 scalar self-attention，这样计算的结果更多是对全局信息的一种表达，标量是对每个输入都一致的 还有一种方案叫做 vector self-attention，具体做法就是将q和k做类似减法计算，然后得到的是每个特征向量都单独的结果，向量是每个输入得到的加权都不同 为什么需要做softmax？可不可以替换其他？功能要求是什么？ 这里的softmax其实可以概括为 normalization function，主要作用就是归一化，不过softmax是非线性的，这样可以是网络对于复杂的非线性系统拥有更好的表达 最终self attention的权重表示什么？atte与v一定要相乘么？系数相加不行么？ 最终的self attention权重表示的意义其实更多的取决于如何计算q和k之间的关系，如果是计算点乘，最终得到的是一个标量，那么这个权重更多是倾向一些全局信息的表达，如果是得到一个向量，那么每个权重不一致，则会更好的表达输入特征向量之间的相关性 Pos Encoding 位置编码层是为了让网络在另一个维度对输入数据进行理解，比如空间位置或序列信息 位置编码的概念就是在把原始数据向量化后，输入网络之前，让特征向量级联上一个表示位置信息或者序列信息的向量，这样可以让网络学习到一些序列化的信息 举个例子，如果没有位置编码，那么网络则更像是在计算组合，他不会考虑位置上的不同，注意这个位置是广泛的，可以是空间、时间等，那么这样的结果就是，输入一个语句， 你借了我100块钱 那么这句话也可能被翻译成 我借了你100块钱 所以加上位置编码，就可以让网络理解上下文信息的顺序特征，这是很重要的 提高网络感知信息的维度 — Multi Head 所谓的Multi Head机制，其实就是将每个特征向量原本学习到一组q k v，扩展到了N组，这样子分别计算注意力权重，那么每个输入的特征向量其实就得到了N个不同的加权之后的特征，经过网络的训练可以让这N个不同特征关注不同的点，这样更符合我们人类的注意力机制的方案 注意： 各个head之间，学习q k v参数矩阵的W矩阵也不相同 假如有N个head，那么最终得到的输出特征，其维度由N个head级联组成的，需要先将N个head进行concat，然后使用维度变换矩阵对其做维度对齐。 Multi-head Self-attention的不同head分别关注了global和local的讯息 ","date":"2021-01-27","objectID":"/transformer%E4%B9%8Bself-attention/:1:2","tags":["Transformer","DeepLearning"],"title":"Transformer之self-attention机制","uri":"/transformer%E4%B9%8Bself-attention/"},{"categories":["深度学习"],"content":"参考 The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time. 本来想自己翻译了，不过找到了对应的翻译版，链接如下 The Illustrated Transformer[翻译] ","date":"2021-01-27","objectID":"/transformer%E4%B9%8Bself-attention/:2:0","tags":["Transformer","DeepLearning"],"title":"Transformer之self-attention机制","uri":"/transformer%E4%B9%8Bself-attention/"},{"categories":["深度学习"],"content":" 本文主要介绍学习目标跟踪算法时遇到的关于边界效应以及余弦窗平滑的相关知识 ","date":"2021-01-27","objectID":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/:0:0","tags":["Tracking","DeepLearning"],"title":"目标跟踪中的边界效应与余弦窗平滑","uri":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/"},{"categories":["深度学习"],"content":"1. 边界效应 ","date":"2021-01-27","objectID":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/:1:0","tags":["Tracking","DeepLearning"],"title":"目标跟踪中的边界效应与余弦窗平滑","uri":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/"},{"categories":["深度学习"],"content":"1.1 背景 在目标跟踪算法中，边界效应最早在的出现，是在基于相关滤波方法的目标跟踪算法中。 先简述相关滤波的目标跟踪算法，相关滤波(correlation filter)是一种模板类方法，采用在线模板匹配的方式，在线学习模板变化，但是相关滤波的缺点也很明显，对快速变形和快速运动情况的跟踪效果不好。 快速变形效果差是因为模板类方法的机制，快速形变的时候，对于目标模板的基于HOG的梯度计算很难跟上目标，目标快速变色也会导致模板无法准确适应的情况，此外，在线学习的模板更新策略与更新频率都会影响跟踪效果 而快速运动效果差则是因为所谓的边界效应，目标的快速运动会导致相邻两帧之间目标在图像中的像素距离过大，从到导致跟踪效果差甚至跟踪失败的现象 ","date":"2021-01-27","objectID":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/:1:1","tags":["Tracking","DeepLearning"],"title":"目标跟踪中的边界效应与余弦窗平滑","uri":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/"},{"categories":["深度学习"],"content":"1.2 定义 对于边界效应的定义，如下： 宏观上来看，目标在被跟踪过程中，在下一帧图像中的位置偏离了search window中心太远，比如非常靠近边缘、出去一半、全部出去，叫做边界效应 边界效应的产生原因，经查阅资料，源于在跟踪算法中引入了离散傅里叶变换，这极大地提高了算法的计算效率，不过也产生了副作用，就是边界效应 ","date":"2021-01-27","objectID":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/:1:2","tags":["Tracking","DeepLearning"],"title":"目标跟踪中的边界效应与余弦窗平滑","uri":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/"},{"categories":["深度学习"],"content":"1.3 总结 对于边界效应，其根本原因可以概括为三个字，大位移，其实实际应用中，这种情况都是经常遇到的，因为我们所说的位移是针对传感器坐标系下的，是相对量，并不一定是世界坐标系下，所以产生的原因可能有两点 处理频率低 包括传感器的采样频率以及算法的运行频率，我统称他们为处理频率，如果处理频率上不去，那么每次在新的搜索区域中寻找目标时，就会发现目标的位移大 实际运动快 另外一种原因就是在世界坐标系下，目标的确处于高速运动，相对于传感器来说，两帧之间位置变化较大 ","date":"2021-01-27","objectID":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/:1:3","tags":["Tracking","DeepLearning"],"title":"目标跟踪中的边界效应与余弦窗平滑","uri":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/"},{"categories":["深度学习"],"content":"1.4 解决方案 通常来说有两种经典的解决方案，分别是余弦窗机制以及增加搜索区域面积 增加搜索区域面积 这个很好理解，大的搜索区域可以很有效的解决边界效应，因为边界的概念是相对于搜索区域大小来定义的，但是缺陷是搜索区域的扩大同样也引入了更多的背景信息，容易造成跟踪模板的漂移，导致模板跟着背景走，一去不回头～ 余弦窗机制 这也是本文想着重记录的，余弦窗机制不仅仅是出现在基于相关滤波的目标算法中，基于深度学习孪生网络的目标跟踪器也有很多都用到了余弦窗来做平滑 但是这种机制自身也有一定的弊端，用的时候需要做取舍 ","date":"2021-01-27","objectID":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/:1:4","tags":["Tracking","DeepLearning"],"title":"目标跟踪中的边界效应与余弦窗平滑","uri":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/"},{"categories":["深度学习"],"content":"2. 余弦窗机制 ","date":"2021-01-27","objectID":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/:2:0","tags":["Tracking","DeepLearning"],"title":"目标跟踪中的边界效应与余弦窗平滑","uri":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/"},{"categories":["深度学习"],"content":"2.1 作用原理 余弦窗机制为什么能处理边界效应？ 在相关滤波算法中，余弦窗的机制作用在像素上：对搜索区域的像素做更改，使搜索区域边界的像素值接近0，这样可以消除边界的不连续性 而在基于深度学习的目标跟踪算法中，余弦窗的引入则是针对于特征学习到的score map，对得到的得分根据余弦窗进行重新加权，越靠近中心，认为得分越准确，这时余弦窗的作用其实说成对错误检测结果的抑制更合理一点，因为在 score map中，大位移还有一种情况就是目标检测错误，这样使用余弦窗机制可以很好的对其进行抑制和惩罚 ","date":"2021-01-27","objectID":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/:2:1","tags":["Tracking","DeepLearning"],"title":"目标跟踪中的边界效应与余弦窗平滑","uri":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/"},{"categories":["深度学习"],"content":"2.2 缺点 在相关滤波中，余弦窗直接让边界像素趋近于0，这样会导致背景信息的弱化，甚至前景信息的丢失。背景信息的弱化是指像素趋近0让模板不能学习背景的特征，前景目标的丢失是说，当目标产生大位移，运动到边界时，余弦窗会让目标仅存的像素也被过滤掉，就导致无法跟踪快速运动的目标 在孪生网络中，在score map上使用余弦窗，个人感觉更多的是对分数的加权，这样做的目的是保证搜索区域中间的目标拥有最高的优先级，但是同样，这并不是一个可以适应所有情况的方案，比如说一个目标快速运动经过了另外一个相似目标，那么跟踪器可能就跟踪错误了 ","date":"2021-01-27","objectID":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/:2:2","tags":["Tracking","DeepLearning"],"title":"目标跟踪中的边界效应与余弦窗平滑","uri":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/"},{"categories":["深度学习"],"content":"2.3 实现 深入了解余弦窗，我只找了其在深度学习中的应用，看的代码是SiamMask # 定义 if p.windowing == 'cosine': # 默认cosine window = np.outer(np.hanning(p.score_size), np.hanning(p.score_size)) # 求外积 \u003c(25, 25), float64\u003e # 调用，更新score map中的分数 pscore = pscore * (1 - p.window_influence) + window * p.window_influence # ndarray\u003c(3125,), float64\u003e 调用的是numpy中的汉宁窗(hanning)和计算外积(outer)的函数 简单解释就是，使用汉宁窗初始化两个向量分别作为长和宽方向的定义，这里的余弦窗其实是正方形，所以两个向量大小一致，类似这样 \u003e\u003e\u003e np.hanning(12) array([0. , 0.07937323, 0.29229249, 0.57115742, 0.82743037, 0.97974649, 0.97974649, 0.82743037, 0.57115742, 0.29229249, 0.07937323, 0. ]) 然后np.outer这个函数的作用就是计算两个向量的外积，结果是一个矩阵，大小等于向量大小的平方，类似这样 这样就得到了一个余弦窗，越靠近中心，其加权分数越大，将这个分数作用在得到的 score map 上，就可以起到对跟踪结果的惩罚和抑制作用了 ","date":"2021-01-27","objectID":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/:2:3","tags":["Tracking","DeepLearning"],"title":"目标跟踪中的边界效应与余弦窗平滑","uri":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/"},{"categories":["深度学习"],"content":"参考 https://zhuanlan.zhihu.com/p/26417182 https://gsy00517.github.io/computer-vision20200120120823/ https://zhuanlan.zhihu.com/p/59624151 https://zhuanlan.zhihu.com/p/66757733 ","date":"2021-01-27","objectID":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/:3:0","tags":["Tracking","DeepLearning"],"title":"目标跟踪中的边界效应与余弦窗平滑","uri":"/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E4%B8%AD%E7%9A%84%E8%BE%B9%E7%95%8C%E6%95%88%E5%BA%94%E4%B8%8E%E4%BD%99%E5%BC%A6%E7%AA%97/"},{"categories":["深度学习"],"content":"互相关和卷积的区别 在CNN中，互相关和卷积都是使用filter/kernel对一张图像进行操作 互相关是从上到下，从左到右 卷积是从下到上，从右到左 卷积等同于将卷积核沿着x轴y轴翻转后，再进行互相关操作 在CNN中，为了简化操作，通常直接使用互相关来代替卷积，因为对于网络来说，无论是否翻转，都只不过是网络要学习的参数，翻转与否其实并无影响，所以互相关和卷积在这种情况下是等同的 ","date":"2021-01-21","objectID":"/pytorch-conv1d/:1:0","tags":["Pytorch","DeepLearning","Convolution"],"title":"Pytorch中的Convolution layers","uri":"/pytorch-conv1d/"},{"categories":["深度学习"],"content":"Pytorch 中的ConvNd [官方文档](torch.nn.modules.conv — PyTorch 1.9.0 documentation) [中文文档](torch.nn · Pytorch 中文文档) Pytorch中的卷积层操作有三种，分别对应了一维，二维和三维，对于函数的参数以及相关说明，文档中都有详细的介绍，这里略过不提，本文更多的是对自己的理解以及感悟的记录，将会以问题的形式表达 ","date":"2021-01-21","objectID":"/pytorch-conv1d/:2:0","tags":["Pytorch","DeepLearning","Convolution"],"title":"Pytorch中的Convolution layers","uri":"/pytorch-conv1d/"},{"categories":["深度学习"],"content":"1. 卷积是如何实现维度变化的 无论卷积操作的维度是多少，通过卷积核之后，输入的特征都可以发生维度的变化，比如输入的是点云数据的张量，维度是[B, 3， N]，对应的一维卷积的卷积核是[Cout, 3, Size]，其中Cout就代表了输出的维度，Size就是卷积核的大小，因为是一维卷积核，所以大小维度是1[注意是维度，不代表大小直接为1] 关于卷积核尺寸的定义，我将相关参数分为两种，一种参数定义卷积核的数量，这些参数包括了卷积操作的输入维度，以及卷积操作的输出维度；另一种参数定义卷积核的大小，比如在一维卷积中，kernel size就是一个一维的数值，如果需要关注上下文信息，就将其大小设置为大于1，或者像PointNet网络中设定的那样，将一维卷积核的大小设置为1，只学习一个点的特征信息 那么最终，一个卷积核的shape应该是 [Cout， Cin， kernelSize]，具体来说，Cin*kernelSize大小的卷积核与输入的Cin维度的特征进行卷积，然后为了输出Cout维度的特征，需要重复Cout份，所以总的大小就是Cout*Cin*kernelSize 注：既然明确了卷积核的参数以及卷积核的shape，那么还有一点要知道，这些卷积参数都是需要经过网络学习的，那么对应的卷积操作的参数量计算，结果等同于上述计算的卷积核大小 ","date":"2021-01-21","objectID":"/pytorch-conv1d/:2:1","tags":["Pytorch","DeepLearning","Convolution"],"title":"Pytorch中的Convolution layers","uri":"/pytorch-conv1d/"},{"categories":["深度学习"],"content":"2. 卷积核的大小如何影响卷积效果的 首先说明，这个卷积核的大小指的是上述卷积核shape中的kernelSize 关于这个问题，是我在学习PointNet时想到的，因为点云数据索引的无序性，所以PointNet学习点云特征时，不能让网络学习到点与相邻点的局部信息，只能单独地学习每个点的特征，那么从感官上来看这样做是有问题的。后面的PointNet++用了那么多繁复的操作，其实最终目的也是为了让网络学习更多的局部感知信息而已 所以经过思考后，关于卷积核的尺寸大小如何影响卷积效果的，其最直观的答案就是，kernelSize设置不同大小尺寸时，会直接影响网络对于输入特征的感知能力，而这在深度学习领域有一个专有名词，叫做感受野（Receptive Field） 虽说卷积核的尺寸越大，越能感知更多的局部信息，但是对应的也会带来两个问题 背景噪声的加入 参数量的增加 所以实际设计网络结构时，还是尽可能地考虑周全 ","date":"2021-01-21","objectID":"/pytorch-conv1d/:2:2","tags":["Pytorch","DeepLearning","Convolution"],"title":"Pytorch中的Convolution layers","uri":"/pytorch-conv1d/"},{"categories":["深度学习"],"content":"3. 1*1卷积核的作用[Bottleneck] Bottleneck机制的产生，就是为了让CNN能够在少量参数的前提下，学习到深层次的特征 具体方案就是使用 1×1的卷积升维，卷积核是小-\u003e 大 -\u003e 小的结构 第一种的参数量为：256×3×3×256 = 589824 第二种的参数量为：256×1×1×64 + 64×3×3×64 + 64×1×1×256 = 69632 可见这种Bottleneck机制能有效降低CNN的参数量 参考：https://davex.pw/2018/02/01/guide-for-kernel/ ","date":"2021-01-21","objectID":"/pytorch-conv1d/:2:3","tags":["Pytorch","DeepLearning","Convolution"],"title":"Pytorch中的Convolution layers","uri":"/pytorch-conv1d/"},{"categories":["深度学习"],"content":"4. 空洞卷积核的机制 空洞卷积的原理就是通过对卷积核进行改变，将卷积核增加了扩张率（dilation rate）的概念，如下图，对卷积核每个卷积核之间加入了扩张距离，这样做的好处就是让网络在不增加参数量的情况下，提高感受野，下图的感受野从3*3变为了5×5 不过空洞卷积也有缺点： 不适用于精度较高的任务，比如像素级别的任务，因为计算卷积时，不是感受野中所有的像素都用来计算了，这样会损失信息，这也叫Gridding Effect网格效应 想不起来了，，等想起来再补充。。。 ","date":"2021-01-21","objectID":"/pytorch-conv1d/:2:4","tags":["Pytorch","DeepLearning","Convolution"],"title":"Pytorch中的Convolution layers","uri":"/pytorch-conv1d/"},{"categories":["深度学习"],"content":"5. 可变形卷积核的原理 接下来这个卷积核的设计思路是我认为比较合理的，因为卷积核的作用是改变维度，进而提高感受野，那么对于不同的任务来说，可能一味提高感受野并不是好事，因为感受野如果不能较好地覆盖前景目标，反而引入了太多的背景信息，那么就会让网络学习到错误的特征，所以如何让感受野可变形？似乎是一个很好的研究方向 微软亚洲研究院（MSRA）就做了相关的研究，让卷积核自己形变，通过参数学习来决定感受野的覆盖区域，这是更加智能的方式 图片目标跟踪算法Ocean中，也使用了这种可变形卷积核，来让网络更好地关注前景目标，也得到了不错的结果，感兴趣的小伙伴可以了解下 ","date":"2021-01-21","objectID":"/pytorch-conv1d/:2:5","tags":["Pytorch","DeepLearning","Convolution"],"title":"Pytorch中的Convolution layers","uri":"/pytorch-conv1d/"},{"categories":["编程算法"],"content":"python中的sort与sorted的区别 Python 列表有一个内置的 list.sort() 方法可以直接修改列表。还有一个 sorted() 内置函数，它会从一个可迭代对象构建一个新的排序列表 sort和sorted使用了Timsort排序算法，时间复杂度和空间复杂度如下 ","date":"2021-01-17","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Bsort%E5%92%8Csorted/:1:0","tags":["sort","Coding","Python"],"title":"Python还债日记之sort和sorted","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Bsort%E5%92%8Csorted/"},{"categories":["编程算法"],"content":"1. sort(*, key=None, reverse=False) 针对python中的列表进行操作 sort是对原列表进行修改，是一种原地操作，使用 \u003c 进行比较，默认按升序排序 key 指定带有一个参数的函数，用于从每个列表元素中提取比较键 (例如 key=str.lower)。 对应于列表中每一项的键会被计算一次，然后在整个排序过程中使用。 默认值 None 表示直接对列表项排序而不计算一个单独的键值 reverse 为一个布尔值。 如果设为 True，则每个列表元素将按反向顺序比较进行排序，也就是输出降序排序结果 ","date":"2021-01-17","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Bsort%E5%92%8Csorted/:1:1","tags":["sort","Coding","Python"],"title":"Python还债日记之sort和sorted","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Bsort%E5%92%8Csorted/"},{"categories":["编程算法"],"content":"2. sorted(iterable, ***, key=None, reverse=False) 根据 iterable 中的项返回一个新的已排序列表，相比于sort只能针对python的列表对象，sorted可以针对任何可迭代对象使用（字典、元组等） 默认输出升序排序结果 具有两个可选参数，它们都必须指定为关键字参数。 key 指定带有单个参数的函数，用于从 iterable 的每个元素中提取用于比较的键 (例如 key=str.lower)。 默认值为 None (直接比较元素)。 reverse 为一个布尔值。 如果设为 True，则每个列表元素将按反向顺序比较进行排序 ","date":"2021-01-17","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Bsort%E5%92%8Csorted/:1:2","tags":["sort","Coding","Python"],"title":"Python还债日记之sort和sorted","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8Bsort%E5%92%8Csorted/"},{"categories":["编程算法"],"content":"python中的广播机制 ","date":"2021-01-13","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6/:1:0","tags":["广播机制","Coding","Python"],"title":"Python还债日记之广播机制","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6/"},{"categories":["编程算法"],"content":"1. 定义 广播机制是对不同维度进行计算的方式，这种机制会执行维度进行自动对齐的操作，在python中，针对位运算（包括加减乘除），广播机制会自动将输入的矩阵或者张量维度进行计算，然后按照广播的方式，将维度对齐，这样可以有效地帮助代码变简洁 ","date":"2021-01-13","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6/:1:1","tags":["广播机制","Coding","Python"],"title":"Python还债日记之广播机制","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6/"},{"categories":["编程算法"],"content":"2. 举例分析 向量加张量 import numpy as np vect = np.array([1, 2, 3]) scalar = 1 print(vect + scalar) [2, 3, 4] 最终的输出结果相当于向量加上了一个经过广播之后的同维度的向量 矩阵加向量 import numpy as np a = np.array([[ 0, 0, 0], [10,10,10], [20,20,20], [30,30,30]]) b = np.array([1,2,3]) print(a + b) 输出是 [[ 1 2 3] [11 12 13] [21 22 23] [31 32 33]]  ","date":"2021-01-13","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6/:1:2","tags":["广播机制","Coding","Python"],"title":"Python还债日记之广播机制","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6/"},{"categories":["编程算法"],"content":"3. 机制总结 以输入两个不同维度的数组为例，两个数组的shape分别是a和b，那么广播机制的执行规则是 判断shape长度 如果两个数组shape的长度不一致，就说明数组的维度不统一，那么，按照shape最长的数组看齐，其他数组的shape不足的补1 (2, 3) + (3) -\u003e (2, 3) + (1, 3) 比较两数组各个维度的长度 当两数组的shape对齐之后，就逐维度比较两个数组的长度大小，应该满足以下条件： 同一维度，两数组的长度相同 同一维度，两数组的长度有一个是1 如果不满足，则两数组不能做shape广播 当某一维度上的长度是1，那么就将这个维度上的值复制N份，这个N是另外一个数组的对应维度的长度，然后按位运算 ","date":"2021-01-13","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6/:1:3","tags":["广播机制","Coding","Python"],"title":"Python还债日记之广播机制","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6/"},{"categories":["深度学习"],"content":"Pytorch中的 nn 与 nn.functional 这两者其实本质上功能是一致的，都是用于开发者调用pytorch中的接口以搭建自己的网络 有一点不同的是，nn继承于nn.Module，是对nn.functional中定义的函数的类封装，所以nn.functional更加灵活，更加底层 Attributes torch.nn.Xxx torch.nn.functional.xxx 类型 class function 自身属性 继承nn.Module相关属性 / 调用方式 先实例化，再调用实例化对象 直接传参 支持nn.Sequential 是 否 dropout兼容性 自动关闭dropout 需手动传参关闭 weight管理 自动 手动定义相关权重 官方文档中有写到，需要学习参数的网路结构，最好使用 nn.Xxx的方式定义，便于管理权重参数，其他像maxpool, loss func, activation func等不需要学习参数的结构，可以直接使用 nn.functional.xxx调用底层函数，使用更加灵活方便 ","date":"2021-01-13","objectID":"/pytorch-nn%E4%B8%8Efunctional%E7%9A%84%E5%8C%BA%E5%88%AB/:1:0","tags":["Pytorch","DeepLearning"],"title":"Pytorch-nn与functional的区别","uri":"/pytorch-nn%E4%B8%8Efunctional%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["深度学习"],"content":"Pytorch 矩阵乘法 关于广播机制，参考 torch.mul torch.mul(input, other, *, out=None) 按位相乘，对维度的要求是，两个张量尽量维度对齐，或者是可以遵循广播机制 比如： \u003e\u003e\u003e a = torch.randn(4, 1) \u003e\u003e\u003e a tensor([[ 1.1207], [-0.3137], [ 0.0700], [ 0.8378]]) \u003e\u003e\u003e b = torch.randn(1, 4) \u003e\u003e\u003e b tensor([[ 0.5146, 0.1216, -0.5244, 2.2382]]) \u003e\u003e\u003e torch.mul(a, b) tensor([[ 0.5767, 0.1363, -0.5877, 2.5083], [-0.1614, -0.0382, 0.1645, -0.7021], [ 0.0360, 0.0085, -0.0367, 0.1567], [ 0.4312, 0.1019, -0.4394, 1.8753]]) torch.mm torch.mm(input, mat2, *, out=None) → Tensor 矩阵相乘，，注意只支持二维的张量 这个函数不支持广播机制，也就是说，必须完全按照矩阵相乘的顺序输入 torch.matmul torch.mm(input, mat2, *, out=None) → Tensor 也是矩阵相乘，不过与 mm不同，这个函数支持广播机制 也就是说输入的两个张量维度不一定需要完全按照矩阵乘法顺序输入 比如，输入的张量是 (j×1×n×m) ，另外一个张量是 (k×m×p)，则会自动按照维度，广播到 (j×k×n×m) 和 (j×k×m×p)，然后计算矩阵相乘，得到 (j×k×n×p) ","date":"2021-01-13","objectID":"/pytorch%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95/:0:1","tags":["Pytorch","DeepLearning"],"title":"Pytorch中的矩阵乘法","uri":"/pytorch%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95/"},{"categories":["必备工具"],"content":"Gitbook简介 gitbook是github与markdown的结合体，我们可以通过markdown笔记记录书籍内容，然后发布到gitbook上，使用操作和流程与github类似，详细了解见官网以及Git ","date":"2021-01-11","objectID":"/gitbook%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/:1:0","tags":["gitbook","Tools"],"title":"Gitbook使用笔记","uri":"/gitbook%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/"},{"categories":["必备工具"],"content":"Gitbook安装及使用 ","date":"2021-01-11","objectID":"/gitbook%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/:2:0","tags":["gitbook","Tools"],"title":"Gitbook使用笔记","uri":"/gitbook%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/"},{"categories":["必备工具"],"content":"1. 安装 npm install -g gitbook-cli gitbook init # then system will download gitbook automatically 详见 ","date":"2021-01-11","objectID":"/gitbook%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/:2:1","tags":["gitbook","Tools"],"title":"Gitbook使用笔记","uri":"/gitbook%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/"},{"categories":["必备工具"],"content":"2. 创建书籍 初始化一个Gitbook cd到要创建书籍的目录下，比如 ~/books，然后运行 $ gitbook init 终端会输出以下命令，并创建两个文件 warn no summary file in this book info: create README.md info: create SUMMARY.md info: initialization is finished 编写README.md和SUMMARY.md 这时文件夹下的目录为 $ ls README.md SUMMARY.md README.md是对创建书籍的介绍，这里面的内容会在整个gitbook的简介中出现 SUMMARY.md是整个书籍的目录结构，这个文件的编写需要按照对应的格式，以标题的形式，每一个标题对应一个.md文件的路径，类似这样 # Summary * [Introduction](README.md) ----- * [Detection](detection/README.md) * [PointPillars](detection/pointpillars.md) * [Tracking](tracking/README.md) * [SC3D](tracking/sc3d.md) * [Segmentation](seg/README.md) * [SOLO](seg/solo.md) * [PointCloud](pointcloud/README.md) * [PV-CNN](pointcloud/pvcnn.md) 我们可以按照自己对书籍的设想，编写对应的目录大纲 当做完更改之后，再次执行git init，就会根据SUMMARY.md中编写的目录自动生成对应文件 编译 仍然在~/books目录下，执行 $ gitbook build ---------------------------------------------------- info: 7 plugins are installed info: 6 explicitly listed info: loading plugin \"highlight\"... OK info: loading plugin \"search\"... OK info: loading plugin \"lunr\"... OK info: loading plugin \"sharing\"... OK info: loading plugin \"fontsettings\"... OK info: loading plugin \"theme-default\"... OK info: found 9 pages info: found 0 asset files info: \u003e\u003e generation finished with success in 0.5s ! 此时目录下会生成对应的书籍编译文件_book $ tree . -L 2 ------------------- . ├── _book │ ├── detection │ ├── gitbook │ ├── index.html │ ├── pointcloud │ ├── search_index.json │ ├── seg │ └── tracking ├── detection │ ├── pointpillars.md │ └── README.md ├── pointcloud │ ├── pvcnn.md │ └── README.md ├── README.md ├── seg │ ├── README.md │ └── solo.md ├── SUMMARY.md └── tracking ├── README.md └── sc3d.md 10 directories, 12 files 编译得到的_book目录就是对已有的书籍内容做了转换，变成了html网页文件，如果你想将gitbook链接到个人博客，只需要上传这个目录下的文件即可，具体操作见下文 本地运行 仍然在~/books目录下，执行 $ gitbook serve # 这个命令会自动执行 gitbook build命令 --------------------------------- Live reload server started on port: 35729 Press CTRL+C to quit ... info: 7 plugins are installed info: loading plugin \"livereload\"... OK info: loading plugin \"highlight\"... OK info: loading plugin \"search\"... OK info: loading plugin \"lunr\"... OK info: loading plugin \"sharing\"... OK info: loading plugin \"fontsettings\"... OK info: loading plugin \"theme-default\"... OK info: found 9 pages info: found 0 asset files info: \u003e\u003e generation finished with success in 0.6s ! Starting server ... Serving book on http://localhost:4000 这时打开浏览器，输入http://localhost:4000，即可查看本地版的gitbook OK，到这里关于gitbook的简单使用就介绍完了，下面记录下如何在个人主页上使用gitbook ","date":"2021-01-11","objectID":"/gitbook%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/:2:2","tags":["gitbook","Tools"],"title":"Gitbook使用笔记","uri":"/gitbook%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/"},{"categories":["必备工具"],"content":"将GitBook链接到个人博客 简单记录下 个人使用的是 hexo 框架以及 fluid 主题搭建的个人博客 使用gitbook的初衷就是，我想在个人博客上链接一个地址，这个网页记录一些比如力扣刷题笔记等自己学习的内容，所以就简单了解了一下gitbook OK，那现在我默认已经拥有了自己的博客，并且已经按照上述流程初步体验了gitbook的使用，并且拥有了自己的第一个gitbook，如果你想把他链接到个人博客上，应该分以下三步： 将gitbook原始内容上传至github远程仓库 这里指的是自己编写的markdown笔记等 在github新建一个仓库，这个仓库的名字会是你博客跳转到gitbook网页的后缀 在gitbook本地，初始化仓库，远程仓库设定为刚刚建立的仓库地址 新建.gitignore文件，里面的内容设置为 *~ _book 上传当前文件到远程仓库的main分支 编译gitbook，将生成的_book中的内容上传到新的分支，叫做gh-pages gitbook build mkdir book_build cp -r _book/* book_build cd book_build git init git remote add origin xxx git checkout -b gh-pages git add . git commit -m \"first pub\" git push origin gh-pages 这样就将编译得到的_book下面的静态网页文件上传到了远程仓库的gh-pages分支下 登录github，找到仓库-\u003esetting-\u003eoptions-\u003eGithub pages，设置gh-pages为要展示的分支，保存，Over！ 设置个人博客中，对应的链接为 your-blog-address/xxx/，其中xxx既是远程仓库的名字，也是你的gitbook的名字 结果展示 leetcode· GitBook ","date":"2021-01-11","objectID":"/gitbook%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/:3:0","tags":["gitbook","Tools"],"title":"Gitbook使用笔记","uri":"/gitbook%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/"},{"categories":["深度学习"],"content":"常见名词 device device一般指GPU端，也叫设备端，一般以 __device__ 前缀修饰的函数，函数的调用以及执行都需要在设备端进行 host host指CPU，也叫主机端，以 __host__ 前缀修饰的函数，调用和执行都在主机端进行 kernel \u0026 kernel func 全称是数据并行处理函数，一般也被成为核函数，个人理解，核函数负责主机与设备的交互，一般而言，核函数以 __global__ 前缀修饰，代表着其可以从主机端调用，在设备端执行，这就完成了数据从主机端到设备端的传输 通常，我们使用以下形式，在主机端调用核函数 kernel\u003c\u003c\u003cDg, Db, Ns, S\u003e\u003e\u003e(param list); kernel指核函数的名字，最后一部分就是核函数计算时需要传入的参数，«\u003c … »\u003e 中的参数就是对grid，block以及共享内存等CUDA参数的设定，具体表示会在后面说明 SM \u0026 SP SM指的是 Streaming MultiProcessing SP指的是 Streaming Processing SM和SP都是硬件层次的术语 一块GPU上面，有非常多的SM，以Tesla P100 GPU举例，其基于Pascal架构的版本包含56个SMs 一个SM包含多个SP，这里的SP其实和我们常说的CUDA core是等同的 每一个SM有自己的指令缓存，L1缓存，共享内存 每个SM通过执行block来进行GPU的同步计算，但是每个SM每次只能执行一个block grid \u0026 block \u0026 thread 这三者是CUDA编程时经常会遇到的概念，从上而下的层级依次是 grid → block → thread 为了更加清晰地理解这些层级关系，自下而上依次介绍如下： thread thread是GPU工作的最小执行单元，是程序员可以控制的最细粒度的并行单位。每一个thread在运算单元上就对应一个sp，所以大家会常常会笼统的把sp数量等同于thread的并行数量，从而量化不同GPU的性能 关于thread，还有一个概念，在GPU中，thread通常是一组一组执行的，一般来说每组的thread数量为32，这32个thread也被称为warp(线程束)，同一个warp中的thread执行的指令都是相同的，只是处理不同的数据。除此之外，对于warp的分组，一般来说都是SM自动进行的，每个warp中的thread，其id都是连续的 block block是CUDA执行代码时的基础单位，一个block由多个thread组成，具体参数是上述内核启动函数中传递的参数，也就是 «\u003c »\u003e中的 Db 参数，是一个Dim3类型的数据，具体包括x，y，z三个参数，分别对应行、列以及高度方向上的thread数量，这只是理想的参数，实际上，线程数还受到硬件计算能力的限制，不同计算能力的显卡，其允许的最大线程数量也不同，如下图 不同计算能力的显卡对应的最大允许Grid、block以及thread运行数量 Grid Grid是由若干个block组成的，一般而言，一个kernel的程序就对应一个grid去执行 一个grid对应的参数有三个，同样在核函数中«\u003c »\u003e可以设置，对应第一个参数Dg，具体有x，y，z三个方向，不过z方向的数量恒定为1，所以一个grid中包括的block数量就是 Dg.x × Dg.y × 1 总结 总体来看，一个GPU由SM构成，而每个SM就是运行blocks中指令的硬件载体 软件方面，当我们在CUDA编程时，编写一个形如kernel\u003c\u003c\u003cDg, Db, Ns, S\u003e\u003e\u003e(param list); 的核函数时，其在GPU中就会对应一个grid，而通过Dg, Db分配每个grid中包含多少个blocks以及每个block包含多少个threads， 最终，每个block会对应若干个由threads组成的warp，而硬件方面，每个SM就会运行对应block 中的每个warp，这就是整体的机制，为了方便理解，我画了一张草图来表示几者之间的关系 其实，仔细思考一下，对于编程人员来说，程序并行化的关键就在于设计一个方案，使得一个SM内的各种硬件单元都能有效利用，比如如何分配每个block中的线程数，让每个warp中尽可能都包含32个线程，进而合理利用资源，得到最理想的吞吐 ","date":"2021-01-10","objectID":"/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/:1:0","tags":["CUDA名词","DeepLearning"],"title":"cuda常见名词解释","uri":"/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/"},{"categories":["深度学习"],"content":"关于 ","date":"2021-01-10","objectID":"/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/:2:0","tags":["CUDA名词","DeepLearning"],"title":"cuda常见名词解释","uri":"/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/"},{"categories":["深度学习"],"content":"编程时实际线程数的计算 由于每个block里面的线程，在各自block内部都是有自己的线程id的，那么实际编程时如何计算对应每个block中的线程编号呢？ 如上图所示，以一个维度上的grid、block以及thread三者关系为例 实际线程编号 = 当前block编号 × block在对应维度上的尺寸 + 当前block中的thread编号 代码如下： __global__ void add(int n, float *x, float *y) { int index = blockIdx.x * blockDim.x + threadIdx.x; int stride = blockDim.x * gridDim.x; for (int i = index; i \u003c n; i += stride) y[i] = x[i] + y[i]; } ","date":"2021-01-10","objectID":"/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/:2:1","tags":["CUDA名词","DeepLearning"],"title":"cuda常见名词解释","uri":"/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/"},{"categories":["深度学习"],"content":"算法测试耗时 分别测试了一个线程、一个block以及多个block下的算法耗时，可以看到非常明显的加速！ ","date":"2021-01-10","objectID":"/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/:2:2","tags":["CUDA名词","DeepLearning"],"title":"cuda常见名词解释","uri":"/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/"},{"categories":["深度学习"],"content":"参考 认识什么是 host code device code 以及 kernel An Easy Introduction to CUDA C and C++ | NVIDIA Developer Blog 其他基础概念了解，块、网格等 An Even Easier Introduction to CUDA | NVIDIA Developer Blog ","date":"2021-01-10","objectID":"/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/:3:0","tags":["CUDA名词","DeepLearning"],"title":"cuda常见名词解释","uri":"/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/"},{"categories":["深度学习"],"content":"官网文档 [Pytorch 1.7] Custom C++ and CUDA Extensions - PyTorch Tutorials 1.7.1 documentation Custom C++ and CUDA Extensions - PyTorch Tutorials 1.7.1 documentation CN ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:1:0","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["深度学习"],"content":"自定义扩展的必要性 Pytorch虽然已经使用了NVIDIA cuDNN、Intel MKL和NNPACK这些底层来加快训练速度，但是在某些情况下，比如我们要实现一些特定算法，光靠组合Pytorch已有的操作是不够的。这是因为Pytorch虽然在特定操作上经过了很好的优化，但却并不见得适合我们自定义的操作，所以，作为一名程序员，应该了解如何将自己的网络或者操作以底层C++的代码实现，这是很重要的 除此之外，如果pytorch代码需要与C++代码进行交互，也需要自己编写对应的C++扩展 ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:2:0","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["深度学习"],"content":"操作步骤 ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:3:0","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["深度学习"],"content":"1. 如何用C++实现我们的扩展/操作？ 头文件包括：#include \u003ctorch/extension.h\u003e 以及定义对应的函数名 #include \u003ctorch/extension.h\u003e //这一句是无论要实现任何op都必须添加的 #include \u003cvector\u003e //前向传播 torch::Tensor my_op_forward(const torch::Tensor\u0026 x, const torch::Tensor\u0026 y); //反向传播 std::vector\u003ctorch::Tensor\u003e my_op_backward(const torch::Tensor\u0026 gradOutput); 源文件包括：网络的定义，包括前向传播、反向传播以及pybind11将c++代码绑定到python的部分 #include \"my_op.h\" torch::Tensor my_op_forward(const torch::Tensor\u0026 x, const torch::Tensor\u0026 y) { AT_ASSERTM(x.sizes() == y.sizes(), \"x must be the same size as y\"); torch::Tensor z = torch::zeros(x.sizes()); z = 3 * x - y; return z; } std::vector\u003ctorch::Tensor\u003e my_op_backward(const torch::Tensor\u0026 gradOutput) { torch::Tensor gradOutputX = 3 * gradOutput * torch::ones(gradOutput.sizes()); torch::Tensor gradOutputY = -1 * gradOutput * torch::ones(gradOutput.sizes()); return {gradOutputX, gradOutputY}; } // pybind11 绑定 PYBIND11_MODULE(**TORCH_EXTENSION_NAME**, m) { m.def(\"forward\", \u0026my_op_forward, \"MY_OP forward\"); m.def(\"backward\", \u0026my_op_backward, \"MY_OP backward\"); } pybind11是python中用来和c++11通信的库 TORCH_EXTENSION_NAME不需要指定，这个定义在运行 setup.py 脚本文件时，对应的扩展名会传给这个定义，这样避免两者匹配不上 这里网络的定义可以调用pytorch/extension 的库，也就是ATen，也可以通过自定义的cuda kernels实现 ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:3:1","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["深度学习"],"content":"2. 如何编译C++代码为python可以识别的文件？ 对应两种方案，setuptools 或者 torch.utils.cpp_extension.load() 这里详细介绍前者 编写对应的 setup.py，构建pytorch的c++扩展，利用python的 setuptools 来编译并加载C++代码，这样，执行setup.py from setuptools import setup import os import glob from torch.utils.cpp_extension import BuildExtension, CppExtension # 头文件目录 include_dirs = os.path.dirname(os.path.abspath(__file__)) # 源代码目录 source_file = glob.glob(os.path.join(working_dirs, 'src', '*.cpp')) setup( name='test_cpp', # 模块名称 与.cpp中的TORCH_EXTENSION_NAME对应 ext_modules=[CppExtension('test_cpp', sources=source_file, include_dirs=[include_dirs])], cmdclass={ 'build_ext': BuildExtension } ) 在终端执行 python setup.py install 这一步其实是包含了build+install执行的是先编译链接动态链接库，然后将构建好的文件以package的形式安装存放再当前开发环境的package的集中存放处，这样就相当于生成了一个完整的package了。和其他的如numpy，torch这些package没什么两样。 执行后，目录下会生成三个目录build/ dist/ ***.egg-info/ ，除此之外，一个名子类似 ***-0.0.0-py3.6-linux-x86_64.egg 的文件也会出现在当前python的环境中site-package ，具体的编译输出如下： output running install running bdist_egg running egg_info writing lltm.egg-info/PKG-INFO writing dependency_links to lltm.egg-info/dependency_links.txt writing top-level names to lltm.egg-info/top_level.txt reading manifest file 'lltm.egg-info/SOURCES.txt' writing manifest file 'lltm.egg-info/SOURCES.txt' installing library code to build/bdist.linux-x86_64/egg running install_lib running build_ext building 'lltm' extension gcc -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I~/local/miniconda/lib/python3.6/site-packages/torch/lib/include -I~/local/miniconda/lib/python3.6/site-packages/torch/lib/include/TH -I~/local/miniconda/lib/python3.6/site-packages/torch/lib/include/THC -I~/local/miniconda/include/python3.6m -c lltm.cpp -o build/temp.linux-x86_64-3.6/lltm.o -DTORCH_EXTENSION_NAME=lltm -std=c++11 cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++ g++ -pthread -shared -B ~/local/miniconda/compiler_compat -L~/local/miniconda/lib -Wl,-rpath=~/local/miniconda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/lltm.o -o build/lib.linux-x86_64-3.6/lltm.cpython-36m-x86_64-linux-gnu.so creating build/bdist.linux-x86_64/egg copying build/lib.linux-x86_64-3.6/lltm_cuda.cpython-36m-x86_64-linux-gnu.so -\u003e build/bdist.linux-x86_64/egg copying build/lib.linux-x86_64-3.6/lltm.cpython-36m-x86_64-linux-gnu.so -\u003e build/bdist.linux-x86_64/egg creating stub loader for lltm.cpython-36m-x86_64-linux-gnu.so byte-compiling build/bdist.linux-x86_64/egg/lltm.py to lltm.cpython-36.pyc creating build/bdist.linux-x86_64/egg/EGG-INFO copying lltm.egg-info/PKG-INFO -\u003e build/bdist.linux-x86_64/egg/EGG-INFO copying lltm.egg-info/SOURCES.txt -\u003e build/bdist.linux-x86_64/egg/EGG-INFO copying lltm.egg-info/dependency_links.txt -\u003e build/bdist.linux-x86_64/egg/EGG-INFO copying lltm.egg-info/top_level.txt -\u003e build/bdist.linux-x86_64/egg/EGG-INFO writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt zip_safe flag not set; analyzing archive contents... __pycache__.lltm.cpython-36: module references __file__ creating 'dist/lltm-0.0.0-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it removing 'build/bdist.linux-x86_64/egg' (and everything under it) Processing lltm-0.0.0-py3.6-linux-x86_64.egg removing '~/local/miniconda/lib/python3.6/site-packages/lltm-0.0.0-py3.6-linux-x86_64.egg' (and everything under it) creating ~/local/miniconda/lib/python3.6/site-packages/lltm-0.0.0-py3.6-linux-x86_64.egg Extracting lltm-0.0.0-py3.6-linux-x86_64.egg to ~/local/miniconda/lib/python3.6/site-packages lltm 0.0.0 is already the active version in easy-install.pth Installed ~/local/miniconda/lib/python3.6/site-packages/lltm-0.0.0-py3.6-linux-x86_64.egg Processing dependencies for lltm==0.0.0 Finished processing dependencies for lltm==0.0.0 此外，使用 pip list 或者 conda list 查看包列表时，可以找到对应的包已经安装了，并且有对应的版本信息以及来源等 ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:3:2","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["深度学习"],"content":"3. 如何通过python调用编译好的扩展/操作？ 在上述操作完成后，虽然python/conda环境下已经有了相对应的库，但通过python进行import 是会报错的，如下 undefined symbol: _ZTIN3c1021AutogradMetaInterfaceE 原因是编译好的包还需要进一步封装才能在python中调用，具体做法如下： 在setup.py 相同路径下新建一个py文件，内容为： from torch.autograd import Function import torch import test_cpp class _TestFunction(Function): @staticmethod def forward(ctx, x, y): \"\"\" It must accept a context ctx as the first argument, followed by any number of arguments (tensors or other types). The context can be used to store tensors that can be then retrieved during the backward pass.\"\"\" return test_cpp.forward(x, y) @staticmethod def backward(ctx, gradOutput): gradX, gradY = test_cpp.backward(gradOutput) return gradX, gradY # 封装成一个模块（Module） class Test(torch.nn.Module): def __init__(self): super(Test, self).__init__() def forward(self, inputA, inputB): return **_TestFunction.apply**(inputA, inputB) 可以看到，主要就是继承pytorch中的父类，新建对应的类，进而做了一些接口上的封装，具体就是使用 torch.autograd.Function 来将这个扩展写成一个函数，方便在构建网络的时候调用。最后就在合适的地方使用Function.apply(*args) ，就完成了一个自定义扩展了！ ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:3:3","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["深度学习"],"content":"注意 ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:4:0","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["深度学习"],"content":"1. 关于C++底层代码的编写，有两种方案 第一种形式，用pytorch/extension 的库，也就是ATen，加速效果尚好，需要以类似at::sigmoid的形式将pytorch的接口API复现一遍 Pytorch学习 (二十一) ——自定义C++/ATen扩展_Hungryof的专栏-CSDN博客 效果展示 python Forward: 187.719 us | Backward 410.815 us extension Forward: 149.802 us | Backward 393.458 us 第二种形式，使用自定义的cuda kernels来进一步加速，详见 Custom C++ and CUDA Extensions Custom C++ and CUDA Extensions - PyTorch Tutorials 1.7.1 documentation ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:4:1","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["深度学习"],"content":"2. 关于 setup.py python库打包分发的详细攻略（setup.py编写）见 程序包的打包和分发 ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:4:2","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["深度学习"],"content":"3. 关于扩展包的封装 注意一定要有前向传播和反向传播的定义 实现torch.autograd.Function 子类时，注意其前向传播和反向传播，都需要有ctx参数 大体上来说就是，这个 ctx 变量会在前向传播时，保存一些涉及到计算梯度的信息，然后在反向传播时辅助计算梯度，如 class Sigmoid(Function): @staticmethod def forward(ctx, x): output = 1 / (1 + torch.exp(-x)) ctx.**save_for_backward**(output) return output @staticmethod def backward(ctx, grad_output): output, = ctx.**saved_tensors** grad_x = output * (1 - output) * grad_output return grad_x 前向传播的输入参数和反向传播的输出参数数量必须一致 如果有些变量不需要求导，就直接返回None即可 ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:4:3","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["深度学习"],"content":"4. 关于梯度计算的验证 pytorch提供了torch.autograd.gradcheck() 函数来检测计算的梯度是否合理 如上述的sigmoid梯度计算，可以通过如下代码检验 # tensor([-0.4646, -0.4403, 1.2525, -0.5953], requires_grad=True) test_input = torch.randn(4, requires_grad=True) torch.autograd.gradcheck(Sigmoid.apply, (test_input,), eps=1e-3) # pass torch.autograd.gradcheck(torch.sigmoid, (test_input,), eps=1e-3) # pass torch.autograd.gradcheck(Sigmoid.apply, (test_input,), eps=1e-4) # fail torch.autograd.gradcheck(torch.sigmoid, (test_input,), eps=1e-4) # fail 我们发现：eps 为 1e-3 时，我们编写的 Sigmoid 和 torch 自带的 builtin Sigmoid 都可以通过梯度检查，但 eps 下降至 1e-4 时，两者反而都无法通过。而一般直觉下，计算数值梯度时， eps 越小，求得的值应该更接近于真实的梯度。这里的反常现象，是由于机器精度带来的误差所致：test_input的类型为torch.float32，因此在 eps 过小的情况下，产生了较大的精度误差（计算数值梯度时，eps 作为被除数），因而与真实精度间产生了较大的 gap。将test_input换为float64的 tensor 后，不再出现这一现象。这点同时提醒我们，在编写backward时，要考虑的数值计算的一些性质，尽可能保留更精确的结果 test_input = torch.randn(4, requires_grad=True, **dtype=torch.float64**) # tensor([-0.4646, -0.4403, 1.2525, -0.5953], dtype=torch.float64, requires_grad=True) torch.autograd.gradcheck(Sigmoid.apply, (test_input,), eps=1e-4) # pass torch.autograd.gradcheck(torch.sigmoid, (test_input,), eps=1e-4) # pass torch.autograd.gradcheck(Sigmoid.apply, (test_input,), eps=1e-6) # pass torch.autograd.gradcheck(torch.sigmoid, (test_input,), eps=1e-6) # pass 具体介绍见 PyTorch 源码解读之 torch.autograd ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:4:4","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["深度学习"],"content":"5. 关于运行设备 由于Pytorch的C++库 ATen可以同时适用于CPU和GPU，所以只需要传给封装好的函数对应cuda形式的张量，就可以调用GPU加速运算了 ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:4:5","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["深度学习"],"content":"6. 关于torch.utils.cpp_extension.load() 实时编译扩展库 这种方式调用pytorch中的api，是一种动态编译和加载扩展的方式 代码如下 from torch.utils.cpp_extension import load lltm_cpp = load(name=\"lltm_cpp\", sources=[\"lltm.cpp\"]) Custom C++ and CUDA Extensions - PyTorch Tutorials 1.7.1 documentation ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:4:6","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["深度学习"],"content":"参考 https://zhuanlan.zhihu.com/p/100459760 ","date":"2021-01-06","objectID":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/:5:0","tags":["Pytorch","DeepLearning","C++-Extension"],"title":"自定义C++/CUDA扩展","uri":"/%E8%87%AA%E5%AE%9A%E4%B9%89c-cuda-extensions/"},{"categories":["编程算法"],"content":" 前文链接： Python还债日记之对象(一) ","date":"2021-01-02","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/:0:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(二)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/"},{"categories":["编程算法"],"content":"1. 对象的操作之对比 python中有两种对变量的比较方式，分别是 == 以及调用 is 关键词，不同点在于： == 只比较两个变量的值是否相等，相等则返回True is 则即比较两个变量值，又比较两个变量地址，都相等才返回True is等同于调用id判断地址是否相等，再和操作==判断值是否相等相与 ","date":"2021-01-02","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/:1:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(二)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/"},{"categories":["编程算法"],"content":"2. 对象的操作之赋值 个人理解，在python中，赋值就是将对象的地址通过引用的方式传递给变量，同时对象的引用次数加1 赋值的内在操作是地址的传递，这个地址指对象个体的地址，而不是子对象地址 赋值操作具有以下几点特征： 赋值与被赋值的两个对象，在python中可以认为是完全一样的，用一个变量给另一个变量赋值，其实就是给当前内存中的对象增加一个“标签”而已 \u003e\u003e\u003e a = (11) \u003e\u003e\u003e print(id(a)) 10914816 \u003e\u003e\u003e b = a \u003e\u003e\u003e print(id(b)) 10914816 \u003e\u003e\u003e b is a True 对于可变对象，如List，赋值时不需要重新开辟空间（因为可变对象是可变的，赋值时相当于给对象添加了一个新的标签） 对于不可变对象，如Tuple、Set等，在赋值时需要开辟新的空间（因为需要破坏原有的引用，将变量的引用指向新的对象）但是python中的小对象整数池、短字符串缓冲区需要特殊考虑 对于可变对象，b是a的赋值，那么改变b的值，或者改变b的值，都会更新另外一方的值 ","date":"2021-01-02","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/:2:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(二)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/"},{"categories":["编程算法"],"content":"3. 对象的操作之拷贝 拷贝操作有两种，在python中，只拷贝浅层对象的操作叫做浅拷贝，递归拷贝所有对象的操作叫做深拷贝 ","date":"2021-01-02","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/:3:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(二)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/"},{"categories":["编程算法"],"content":"3.1 浅拷贝 python中的浅拷贝操作包括：copy 模块的 copy 函数 ，对象的 copy 函数 ，工厂方法，切片等 对于不可变对象，浅拷贝操作是传递引用，相当于赋值 对于可变对象，浅拷贝操作是对浅层对象进行拷贝，子对象不变 这里的浅层对象，对于字典、列表等类型来说，指的就是最外层的对象，也就是列表或者字典本身。可变对象的浅拷贝过程，实际上是在堆区分配了一块新内存，但是这块新内存内部的子对象，依旧是指向原内存中的位置的。 举例说明： 不可变对象的浅拷贝 \u003e\u003e\u003e a = 555 \u003e\u003e\u003e b = a \u003e\u003e\u003e id(a), id(b) (140441428658224, 140441428658224) 因为是赋值的过程，所以内存地址一致，这时如果改变b，相当于一次新的赋值，a不会一起改变 可变对象的浅拷贝 \u003e\u003e\u003e listA = [1, 'a', [1, 2]] \u003e\u003e\u003e listB = listA.copy() \u003e\u003e\u003e print(listA, listB) [1, 'a', [1, 2]] [1, 'a', [1, 2]] \u003e\u003e\u003e id(listA), id(listB) (140441428382344, 140441428382408) \u003e\u003e\u003e id(listA[0]), id(listB[0]) (10914496, 10914496) 因为是拷贝后的变量listB是新开辟的内存，所以listA与listB内存地址不一致 这时如果改变listB，情况分为两种： 添加、删除或改动不可变对象，listA都不会随着改变 改动可变对象，listA会一起改变，比如在listB中第二个位置，向列表[1, 2]中添加一个元素，那么listA也会改变 ","date":"2021-01-02","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/:3:1","tags":["python","Coding","对象"],"title":"Python还债日记之对象(二)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/"},{"categories":["编程算法"],"content":"3.2 深拷贝 Python中的深拷贝操作，只有copy模块的 deepcopy 函数 深拷贝也可以理解成递归拷贝，在Python中，深拷贝对于子对象中的可变对象进行复制，而不可变对象则沿用之前的引用。 深拷贝的最终结果就是，即使改变原来的变量，新变量也不会改变，二者互不影响 \u003e\u003e\u003e import copy \u003e\u003e\u003e a = [1, 'a', [1, 2]] \u003e\u003e\u003e b = copy.deepcopy(a) \u003e\u003e\u003e print(a, b) [1, 'a', [1, 2]] [1, 'a', [1, 2]] \u003e\u003e\u003e b[2].append(0) \u003e\u003e\u003e print(a, b) [1, 'a', [1, 2]] [1, 'a', [1, 2, 0]] ","date":"2021-01-02","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/:3:2","tags":["python","Coding","对象"],"title":"Python还债日记之对象(二)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/"},{"categories":["编程算法"],"content":"4. 传值还是传引用？ 在函数传参时，我们都知道基本的参数传递机制有两种，传值以及传引用。我们先梳理一下传值以及传引用的异同，然后再分析python中是传值还是传引用。 首先回顾一下形参与实参的区别，形参是指被调用的函数的形式参数，其作为函数内部的局部变量。实参是指调用函数时，实际传递的参数。函数会在其对应的堆栈中开辟一块空间，来存放传递进来的实参的值。在这个过程中，值传递的特点是，对于形参的任何操作，都不会改变传递进来的实参的值。而引用传递，传递的是实参的引用，也可以理解为地址，即形参和实参指向同一个地址，这时改变形参，实参的值也会发生改变。 对于python中，前面我们分析了，由于其动态语言的特性，python中的变量都是引用，所以调用函数时，传递的都是引用！但是如果我们从改变形参实参是否发生改变的角度来分析，python中存在可变和不可变对象，所以对于不可变对象，形参改变，相当于重新开辟了空间以及再次进行引用的传递，并不会改变实参，相当于传值。对于可变对象，形参改变，指向的原对象也会改变，所以相当于传引用！ 总结一下： 从传递参数自身的性质来分析，python属于传引用 从形参与实参的关系来分析，python中不可变对象是传值，可变对象是传引用 ","date":"2021-01-02","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/:4:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(二)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/"},{"categories":["编程算法"],"content":"5. 总结 不可变对象在赋值时会开辟新空间 可变对象进行赋值前后，改变一个，另外一个也会改变 深浅拷贝对于不可变对象进行拷贝时，不开辟新空间，相当于赋值操作 浅拷贝拷贝的是浅层对象，深拷贝才会递归拷贝所有子对象（只针对可变对象才进行新建操作，直到最后所有对象都是不可变为止） python默认使用的是浅拷贝，因为其速度快、占用空间小、效率高 python中的传值还是传引用，要辩解地分析，可变与不可变对象，其传递过程的本质不同。 ","date":"2021-01-02","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/:5:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(二)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/"},{"categories":["编程算法"],"content":"6. 参考 https://mp.weixin.qq.com/s/VVKq40A4H6u4gFC1yoMB_w Python FAQ1：传值，还是传引用？ ","date":"2021-01-02","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/:6:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(二)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%BA%8C/"},{"categories":["编程算法"],"content":"1. 关于python中的对象 Python中万物皆对象 这是一个很通俗的说法，但却十分准确，python用对象的概念来解释程序中的元素，比如整数、字符串、元组等。甚至，表示对象类型的方法type也是一个对象。 ","date":"2021-01-01","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/:1:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(一)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/"},{"categories":["编程算法"],"content":"2. 对象、引用与变量 对象在创建时，Python解释器会为其分配内存空间，如果对象的值被传递给了一个变量，那么该变量就会通过引用的方式使用该对象，这时也可以称为，变量是对对象的引用。 ","date":"2021-01-01","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/:2:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(一)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/"},{"categories":["编程算法"],"content":"3. 对象的内存地址 其实在python中，变量的地位很尴尬，因为python动态语言的特性以及万物皆对象的特性，导致变量往往都是对对象的引用。这时变量与对象可以被理解成两部分，在存储时，二者也是分开的。变量代表着对象的地址，存储在栈区，而对象的实际内容存储在堆区。我们可以通过id()来获取对象或者说变量在堆区中的内存地址。也可以理解成返回当前对象在其生命周期内独一无二的标识符。 下图可以很好地说明在python中对象与变量的存储方式，以及堆区和栈区的内存分配。 栈区： 栈区存放真实的对象，当新对象创建时，堆区中就会被开辟出一块新的内存地址分配给这个新的对象。 此外，python还为一些特殊的数据独立分配了特定的空间，分别是小对象整数池、匿名列表、字典对象缓冲区以及短字符串缓冲区。这样做的原因在后文会详细说明，总结来说就是，为不可变对象（小整数、字符串）以及匿名对象（未赋值的字典和列表）提供一个固定的地址。 栈区： 栈区存放的是前面说的，地位很尴尬的变量，下图可以看到，变量A、B、C、D其实表示的是堆区对象的引用，其本身存放的也不是对象的值，而是对象在堆区的地址。可以通过id方法获取变量指向对象的地址 栈区和堆区之间，从对象指向变量的，就是引用 注意： 变量在栈中的地址与变量自身存储的地址是不同的，注意区分 可以思考下，变量与对象之间的关系是一一对应的么？ ","date":"2021-01-01","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/:3:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(一)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/"},{"categories":["编程算法"],"content":"4. 对象的类型 python中的对象都存储在堆区，但是其类型却不尽相同，根据是否可变，我们将对象分为可变对象和不可变对象。 注意：这里的可变与不可变，指的是变量指向的内存地址是否可以改变，如果指向一个对象地址的变量可以被修改，那么该对象就是可变的 ","date":"2021-01-01","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/:4:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(一)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/"},{"categories":["编程算法"],"content":"4.1 不可变对象 不可变对象，就是无法修改的对象，我们无法在内存中直接修改这个变量。必须断开原来的引用，才可以使这个变量拥有新的值。 所以在python中，当我们尝试修改不可变类型的值，比如初始化a = 5，然后再改变a的值，a = 4，这时，由于指向对象5的地址是不可变的，所以对象5到a的引用会断开，然后一个新的对象4的引用会分配给该变量。这个过程前后，变量a虽然没有改变变量名称，但是其指向的对象地址发生了变化，如果调用id()方法也可以证明这一点。 \u003e\u003e\u003e a = 5 \u003e\u003e\u003e id(a), id(5) 10914624, 10914624 \u003e\u003e\u003e a = 4 \u003e\u003e\u003e id(a), id(4) 10914592, 10914592 在Python中， 常见的不可变对象有： int float bool tuple string 再强调一遍，以上五种类型之所以被称为不可变对象，是因为一旦变量与对象通过引用绑定之后，再想修改变量的值，只能通过解除引用、重新引用的方式。所以我们可以发现，对于不可变对象，如果变量的值不同，其对应对象一定不同，同一个变量修改内容后，其指向的对象也一定是改变了的。 ","date":"2021-01-01","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/:4:1","tags":["python","Coding","对象"],"title":"Python还债日记之对象(一)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/"},{"categories":["编程算法"],"content":"4.2 特殊不可变对象 如果两个变量的值相同，那么他们在堆中的地址一定一样么？答案是不一定 再放一下关于对象存储在堆区中的图 python中关于对象的存储，有几处特殊的空间，这里只说两处，分别是短字符串缓冲区以及小对象整数池。二者的作用是，当字符串的长度较短或者是整数的数值较小时，python会将值相同的变量分配相同的引用，换句话说，值相同的变量指向相同的对象。 小对象整数池的作用范围是(-5, 256)，在这范围内的整数，只要值相同，堆中的内存地址也相同 \u003e\u003e\u003e a = 5 \u003e\u003e\u003e b = 5 \u003e\u003e\u003e id(a), id(b) 10914624, 10914624 \u003e\u003e\u003e a = 555 \u003e\u003e\u003e b = 555 \u003e\u003e\u003e id(a), id(b) 140122211533680, 140122211533712 短字符串指的是没有空格的字符串，不带空格的字符串，只要内容相同，其在堆中的地址就一致 \u003e\u003e\u003e a = 'dddddddddddddddddddddddddddddddddd' \u003e\u003e\u003e b = 'dddddddddddddddddddddddddddddddddd' \u003e\u003e\u003e id(a), id(b) 140599787760344, 140599787760344 \u003e\u003e\u003e a = 'a b' \u003e\u003e\u003e b = 'a b' \u003e\u003e\u003e id(a), id(b) 140599787781456, 140599787781400 ","date":"2021-01-01","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/:4:2","tags":["python","Coding","对象"],"title":"Python还债日记之对象(一)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/"},{"categories":["编程算法"],"content":"4.3 可变对象 明白了不可变对象的定义之后，可变对象的定义也就很清楚了，对于一个变量和其绑定的对象，如果是可变的，那么修改变量可以通过直接改变变量指向的堆中的内存地址来实现，不需要破坏对象与变量之间的引用。 在Python中，常见的可变对象有： list dict set 对于这三种可变对象，不管值是否相同，不同变量对应堆中的内存地址一定不同，同一变量对应的内存地址一定不变。 \u003e\u003e\u003e a = [1] \u003e\u003e\u003e b = [1] \u003e\u003e\u003e id(a) 140176052670856 \u003e\u003e\u003e id(b) 140176052699720 ","date":"2021-01-01","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/:4:3","tags":["python","Coding","对象"],"title":"Python还债日记之对象(一)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/"},{"categories":["编程算法"],"content":"4.4 特殊可变对象 依旧是这张图 对于可变对象，python中也有一些特殊的情况，比如匿名的可变对象。所以python同样给匿名的列表和字典对象准备了特殊待遇，对于这两类匿名对象，其在堆中的内存地址是一样的。（注，匿名表示的就是没有被赋值的对象，也可以理解为对象没有被变量引用） \u003e\u003e\u003e id([1, 2, 3]), id([1, 2, 3]) 139883205481032, 139883205481032 \u003e\u003e\u003e id({'a': 1}), id({'a': 1}) 139883230991992, 139883230991992 ","date":"2021-01-01","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/:4:4","tags":["python","Coding","对象"],"title":"Python还债日记之对象(一)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/"},{"categories":["编程算法"],"content":"5. 总结 本文内容总结如下： Python是一门动态语言 Python中万物皆对象 Python中变量存储的是对象的引用 Python中对象可以分为可变对象与不可变对象 对于不可变对象，小整数、短字符串以及布尔值这三类，只要值相同，那么变量指向的地址就相同，其余类型则值相同、地址也不同 对于可变对象，单个变量的值无论怎么改变，其内存地址都不变，但是多个变量的值就算相同，其内存地址也不同 ","date":"2021-01-01","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/:5:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(一)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/"},{"categories":["编程算法"],"content":"6. 参考 python3中各类变量的内存堆栈分配和函数传参区别实例详解 Python内存管理中的堆和栈以及id，is，== 的区别和使用 ","date":"2021-01-01","objectID":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/:6:0","tags":["python","Coding","对象"],"title":"Python还债日记之对象(一)","uri":"/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1%E4%B8%80/"},{"categories":["系统装机"],"content":" nvidia-docker2已经弃用，现在都是装nvidia-container-toolkit 清除旧版本 sudo apt-get remove docker docker-engine docker-ce docker.io sudo rm -rf /var/lib/docker dpkg -l | grep docker sudo apt-get purge docker-ce 更新apt-get sudo apt-get update 安装添加使用 HTTPS 传输的软件包 sudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common 添加软件源的GPG密钥—清华源 curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository \"deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs)stable\" 更新apt-get，安装docker sudo apt-get update sudo apt-get install docker-ce 查看docker版本 docker version 这里docker安装初步完成，可以使用docker hello-world测试，如果出现权限问题报错，可以尝试如下方法： # 添加一个docker属组（如果没有） sudo groupadd docker # 将用户加入该group中，退出并重新登陆 sudo gpasswd -a ${USER} docker # 重启docker服务 sudo service docker restart # 切换当前会话到新group或重启会话 newgrp - docker 接下来安装深度学习相关的环境，首先安装docker-nvidia 参考官网git # Add the package repositories distribution=$(. /etc/os-release;echo $ID$VERSION_ID) curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list sudo apt-get update \u0026\u0026 sudo apt-get install -y nvidia-container-toolkit sudo systemctl restart docker 安装nvidia-container-runtime 参考官网git sudo apt-get install nvidia-container-runtime sudo mkdir -p /etc/systemd/system/docker.service.d sudo tee /etc/systemd/system/docker.service.d/override.conf \u003c\u003cEOF [Service] ExecStart= ExecStart=/usr/bin/dockerd --host=fd:// --add-runtime=nvidia=/usr/bin/nvidia-container-runtime EOF sudo systemctl daemon-reload sudo systemctl restart docker sudo tee /etc/docker/daemon.json \u003c\u003cEOF { \"runtimes\": { \"nvidia\": { \"path\": \"/usr/bin/nvidia-container-runtime\", \"runtimeArgs\": [] } } } EOF sudo pkill -SIGHUP dockerd sudo dockerd --add-runtime=nvidia=/usr/bin/nvidia-container-runtime [...] 修改镜像和容器的存放路径 指定镜像和容器存放路径的参数是–graph=/var/lib/docker，我们只需要修改配置文件指定启动参数即可。Docker 的配置文件可以设置大部分的后台进程参数，在各个操作系统中的存放位置不一致，在 Ubuntu 中的位置是：/etc/default/docker，在 CentOS 中的位置是：/etc/sysconfig/docker 打开/etc/default/docker sudo gedit /etc/default/docker # 如果是 CentOS 则添加下面这行： OPTIONS=--graph=\"/root/data/docker\" --selinux-enabled -H fd:// # 如果是 Ubuntu 则添加下面这行（因为 Ubuntu 默认没开启 selinux）： OPTIONS=--graph=\"/root/data/docker\" -H fd:// # 或者 DOCKER_OPTS=\"-g /root/data/docker\" 最后重新启动，service docker restart 通过docker info 查看 Docker 的路径是否改成 /root/data/docker 如果没有生效，按如下操作 mkdir -p /etc/systemd/system/docker.service.d cat /etc/systemd/system/docker.service.d/Using_Environment_File.conf 如果没有该文件则自行创建，添加以下内容 [Service] EnvironmentFile=-/etc/default/docker ExecStart= ExecStart=/usr/bin/docker daemon -H fd:// $DOCKER_OPTS 载入配置重启服务 systemctl daemon-reload service docker restart 修改为阿里的镜像仓库 # 这里我在注册阿里云之后，将镜像仓库更改为阿里的云仓库，使用如下命令 sudo tee /etc/docker/daemon.json \u003c\u003c-'EOF' \u003e { \u003e \"registry-mirrors\": [\"https://b68wbkqs.mirror.aliyuncs.com\"] \u003e } \u003e EOF ","date":"2020-09-26","objectID":"/%E5%AE%89%E8%A3%85docker/:0:0","tags":["docker"],"title":"docker安装记录","uri":"/%E5%AE%89%E8%A3%85docker/"},{"categories":["深度学习"],"content":" 《Leveraging_Shape_Completion_for_3D_Siamese_Tracking》论文\u0026代码阅读 作者：Silvio Giancola, Jesus Zarzar*, and Bernard Ghanem* 机构：King Abdullah University of Science and Technology (KAUST) 论文水平：CVPR19 关键词：Shape Completion \u0026\u0026 Siamese Tracker \u0026\u0026 Model Update ","date":"2020-06-26","objectID":"/sc3d/:0:0","tags":["Tracking","DeepLearning"],"title":"SC3D论文\u0026代码阅读","uri":"/sc3d/"},{"categories":["深度学习"],"content":"论文摘要 本文提出了一种基于形状补全网络以及孪生网络的单目标跟踪器，借鉴了《***Learning representations and generative models for 3d point clouds 》***这篇论文的思想，将形状补全网络中的自编码器融入到孪生网络的框架中，使用自编码器的编码结构作为孪生网络的特征提取网络，通过编码之后解码这一过程将形状补全损失加入进来，训练编码器网络，使其编码的特征带有形状信息，更好的用于孪生网络的匹配。 代码 视频 ","date":"2020-06-26","objectID":"/sc3d/:1:0","tags":["Tracking","DeepLearning"],"title":"SC3D论文\u0026代码阅读","uri":"/sc3d/"},{"categories":["深度学习"],"content":"论文解读 ","date":"2020-06-26","objectID":"/sc3d/:2:0","tags":["Tracking","DeepLearning"],"title":"SC3D论文\u0026代码阅读","uri":"/sc3d/"},{"categories":["深度学习"],"content":"1. 网络框架 如图所示，整体的网络架构分为两部分， 分别是自编码器网络和孪生网络，自编码器就是将输入编码再解码得到形状更加丰富的点云, 孪生网络就是使用编码器的输出向量计算相似度. 网络的具体描述如下: 自编码器网络是借鉴形状补全网络的思想，对输入的一组模板点云(Model Shape)以及一组搜索点云(Candidate Shapes)进行编码(Φ)和解码(Ψ)，二者组成了自编码器。实际上，代码中作者只用了三层一维卷积作为编码器，将输入的(B, 3, 2048)维度的点云编码为(1, 128)维度的向量形式的潜在表述，进而通过两层的全连接层，将(1, 128)的向量输出为(1, 6144), 进而reshape为(3, 2048)作为解码器的输出。使用自编码器的作用在于，通过训练，构建形状补全损失(Shape Completion Loss)，进而让网络学习如何通过自编码来得到相对于输入点云的更好的形状表述，同时让编码器编码得到的向量拥有点云的几何形状信息， 也让解码器解码得到的点云对应的 bbox 更加精准。 编码器产生的带有形状信息的向量也对后面的孪生网络计算相似度有帮助。 孪生网络在本文中由两个编码器网络组成，输入的两组点云通过相同的编码器网络，输出两个代表着潜在几何信息的向量，对这两个向量进行相似度度量，就可以得到相似度最大的 Candidate pc，本文使用的是余弦相似度，孪生网络对应的跟踪损失是均方差损失(MSE Loss)。 这里还有一点要说明的是，因为本论文的主要目的是做跟踪，所以作者强调网络的主要结构是孪生网络，自编码网络只是帮助孪生网络的相似度计算更加精准。 ","date":"2020-06-26","objectID":"/sc3d/:2:1","tags":["Tracking","DeepLearning"],"title":"SC3D论文\u0026代码阅读","uri":"/sc3d/"},{"categories":["深度学习"],"content":"2. 模型的训练 Example of model completion 输入输出分别是什么? 在训练阶段，网络的两个输入维度都是(1, 3, 2048)，经过 model 得到的输出是 当前搜索点云与模板点云的相似度: 其实也就是孪生网络的输出, 用来计算相似度损失 自编码之后的点云: 自编码器的输出, 输出维度也是(3, 2048), 可以用来计算形状补全损 输入的模板点云与搜索点云如何确定? Model Shape 是一个特定的 track_id 对应的所有帧的点云级联而成，级联之后还需要下采样到2048个点，以和模型的输入尺寸对齐，进而作为这一次训练的模板点云。 Candidate Shapes 则是在某一帧的真值框附近根据 Kalman filter 采样生成的一定数量的候选框内的点云，比如当前帧是1，采样数量是125，那么输入给 data_loader 的参数就会是 0-124 之间， 如果输入57，代表的就是在第一帧点云真值框附近，采样得到的第58个框，框中对应的点云作为这一次训练的搜索点云。 👉🏿 Loss是如何定义的? 在SC3D中, 总体的loss包括两部分, 第一个就是计算编码向量之间的相似度, 进而求得的相似度损失，这里其实就是典型的孪生网络结构，用两个编码器作为特征提取的网络，计算得到的向量之间的相似度，值得一提的是，本文在训练阶段使用的模板点云是一个序列所有帧级联之后下采样得到的点云，这样得到的点云形状信息更加完整，相比于以往的使用孪生网络跟踪的方法，这种方式可以尝试下，个人感觉应该能一定程度上解决三维点云感知中点云稀疏性带来的问题。(因为相当于训练时模板信息较为丰富，特征较为完整，进而提高搜索点云与模板点云之间的相似度) 第二个损失是算模型的形状完成损失，作者想让自编码器网络具有能够补全输入点云的形状的能力, 那么就需要在训练阶段通过监督信号不断纠正网络的学习结果, 让网络能够学习到足够匹配的参数, 进而达到形状补全的目的, 所以这里作者加了一个形状补全损失, 用来让模型拥有补全形状的能力。 在做 loss 回传时，取两种损失的加权和，如下： loss = loss1 + lambda_completion * loss2 ","date":"2020-06-26","objectID":"/sc3d/:2:2","tags":["Tracking","DeepLearning"],"title":"SC3D论文\u0026代码阅读","uri":"/sc3d/"},{"categories":["深度学习"],"content":"4. 模型的测试 输入输出分别是什么? 与训练不同，测试阶段模型的输入是一组数据，前文也提到了测试数据集的构建以及搜索框的生成策略，测试阶段是将生成的一组 Candidate PCs 级联到一起，Model PC则是根据不同的策略更新之后，与 Candidate PCs 的维度对齐(其实就是将 Model PC 重复了若干次)，所以将这两组数据一起输入给网络。 输出得到的相似度得分同样是一组，在这一组得分中选择分数最高的，根据对应的id找到在 Candidate Boxes 中的Bbox， 作为当前帧的搜索结果，这样就完成了一次测试的过程。 输入的模板点云与搜索点云如何确定? 在测试阶段，第一帧的 Model Shape 是由真值得到的，并且只有一帧的数据，在后续帧中不断融合新的信息，这里的数据融合分为两种思路，要么融合点云，要么融合编码之后的向量，作者提出融合 latent vector 会降低内存的消耗，但是论文给出的测试数据显然融合点云更为精准。对于融合之后如何更新模板点云，可以选定第一帧、选定前一帧或者选定前面所有帧进行级联，如果选择融合向量，同样有不同的融合方案，详见代码 Candidate Shapes 的选择同样也有几种不同的方案，因为作者提出的更新搜索空间的方式，是基于某一帧的bbox，在其周围根据不同的方式(KalmanFilteringr / GaussianMixtureModel / ParticleFiltering / ExhaustiveSearch) 生成若干个 *Candidate boxes，*而这个bbox的选取也有三种方式，分别是取前一帧的跟踪结果，前一帧的真值以及当前帧的真值来计算 *Candidate boxes，*详见代码 测试结果如何得到？ 得到相似度向量，取得分最高的 id，就可以找到在搜索点云中对应的 id，这样就可以把这个 id 对应的 bbox 作为最终的跟踪结果。 ","date":"2020-06-26","objectID":"/sc3d/:2:3","tags":["Tracking","DeepLearning"],"title":"SC3D论文\u0026代码阅读","uri":"/sc3d/"},{"categories":["深度学习"],"content":"代码阅读 ","date":"2020-06-26","objectID":"/sc3d/:3:0","tags":["Tracking","DeepLearning"],"title":"SC3D论文\u0026代码阅读","uri":"/sc3d/"},{"categories":["深度学习"],"content":"1. class kittiDataset() getSceneID(self, split): 针对 Kitti 数据集的 tracking下的序列，将 train下的 00-16 作为了训练集， 17-18作为验证集，19-20作为测试集 getListOfAnno(self, sceneID, category_name=“Car”): 获取 scene 列表，然后遍历每一个 scene，得到对应的label 先通过 pandas 读取label，存为 Dataframe格式 label_file = os.path.join(self.KITTI_label, scene + \".txt\") #读取标签txt文件 df = pd.read_csv( label_file, sep=' ', names=[ \"frame\", \"track_id\", \"type\", \"truncated\", \"occluded\", \"alpha\", \"bbox_left\", \"bbox_top\", \"bbox_right\", \"bbox_bottom\", \"height\", \"width\", \"length\", \"x\", \"y\", \"z\", \"rotation_y\" ]) 筛选出当前跟踪的类别 df = df[df[\"type\"] == category_name] # 筛选出类别是car的标签 在label中插入 scene df.insert(loc=0, column=\"scene\", value=scene) # 在标签中插入一列表示这是哪个场景 遍历 Dataframe 中的每一个 id，将所有帧的label 根据不同的 track_id 进行存储 for track_id in df.track_id.unique(): # 找到所有属于当前id的数据,保留下来 df_tracklet = df[df[\"track_id\"] == track_id] # 因为行标签(行号)在前面的筛选中错乱了,这里重置一下,避免不必要的错误 # drop=True: 把原来的索引index列去掉，丢掉。 # drop=False: 保留原来的索引（以前的可能是乱的） df_tracklet = df_tracklet.reset_index(drop=True) # 使用df_tracklet.iterrows() 来进行迭代的生成, 返回值是对应的行号以及标签,这里舍弃行号,只保留了标签信息 tracklet_anno = [anno for index, anno in df_tracklet.iterrows()] # 再存进列表中 list_of_tracklet_anno.append(tracklet_anno) 注意：这里遍历结束之后,因为循环时是取 df.track_id.unique() 中的元素, 其没有固定的排列顺序,所以得到的 list_of_tracklet_anno 的索引,与track_id没什么关系 getBBandPC(self, anno): 根据传入的label标签，得到calib文件，以及对应的 transf_mat 根据 anno 和 transf_mat 读取对应的点云以及 box getPCandBBfromPandas(self, anno, calib): 根据 label 以及 transf_mat 矩阵（传入的calib实际上就是 transf_mat 矩阵）得到整帧点云和box 这里将点云和box抽象成了两个类，将读取到的数据以这两个类的形式存储，便于后面处理 PointCloud 类 通过点云数据创建，点云的shape是（4，n）注意这里直接将点云进行了transform，坐标系变换为相机坐标系 velodyne_path = os.path.join(self.KITTI_velo, anno[\"scene\"], '%06d.bin'%(anno[\"frame\"])) #f'{box[\"frame\"]:06}.bin') #从点云的.bin文件中读取点云数据并且转换为4*x的矩阵，且去掉最后的一行的点云的密度表示数据 PC = PointCloud( np.fromfile(velodyne_path, dtype=np.float32).reshape(-1, 4).T) #将点云转换到相机坐标系下　因为label中的坐标和h,w,l在相机坐标系下的 PC.transform(calib) Box 类 通过（center，size，orientation）创建，这里将读取到 yaw角转换成了四元数 center = [anno[\"x\"], anno[\"y\"] - anno[\"height\"] / 2, anno[\"z\"]] size = [anno[\"width\"], anno[\"length\"], anno[\"height\"]] #下面这个函数是将roy角转换成四元数吧 orientation = Quaternion( axis=[0, 1, 0], radians=anno[\"rotation_y\"]) * Quaternion( axis=[1, 0, 0], radians=np.pi / 2) # 用中心点坐标和w,h,l以及旋转角来初始化BOX这个类 BB = Box(center, size, orientation) 注意：kitti数据集的坐标系定义为 y轴向下为正，并且center是底面的中心（向下为正，所以也就是上面的中心） 这里计算center的时候，计算的是box的中心，所以y方向坐标减去了半个高度，也是方便后续corners的计算 Box类中存放了四元数作为角度，也可以调用类中的属性 rotation_matrix 返回对应的角度 Box类中也有返回 corners 坐标的方法，返回（3，8）的坐标值 这里的corners方法，分为以下三步 根据长宽高，建立一个坐标在原点的 box 根据 rotation_matrix 将box旋转对应的角度 根据 center 的坐标将box平移至对应位置，这样就得到了最终的带有角度的corners Box类中还有一些操作，旋转、坐标系变换、平移等 ","date":"2020-06-26","objectID":"/sc3d/:3:1","tags":["Tracking","DeepLearning"],"title":"SC3D论文\u0026代码阅读","uri":"/sc3d/"},{"categories":["深度学习"],"content":"2. class SiameseDataset(Dataset) list_of_tracklet_anno 装有所有 scene 下的每个track_id 的 label list_of_anno 获取所有标签，不考虑track_id：根据得到的 self**.list_of_tracklet_anno， 不论 id， 把每一帧的数据顺序放入一个列表中，得到 self.list_of_anno， 这里的 self.list_of_anno 就是把 list_of_tracklet_anno 的 shape 从(track_id, frames) 变成 (track_idframes*, ) ","date":"2020-06-26","objectID":"/sc3d/:3:2","tags":["Tracking","DeepLearning"],"title":"SC3D论文\u0026代码阅读","uri":"/sc3d/"},{"categories":["深度学习"],"content":"3. class SiameseTrain(SiameseDataset) SiameseTrain class SiameseTrain(SiameseDataset): \"\"\" 用来训练SC3D的数据集, 几个重要函数说明如下: __init__ : 初始化各种参数,并且获得list_of_BBs以及list_of_PCs,注意这里的list_of_PCs指的是bbox中的点云,不是整帧点云 __getitem__ : 调用getitem, 这里就是根据传入的index获得对应的训练数据并返回 __len__ : 获取数据集的长度, 这里将实际的长度乘了一个数字, 这个数字是在每一帧的搜索区域周围生成候选区域的数量 几个重要数据说明如下: num_candidates_perframe: [Int]在当前搜索点云框周围生成的候选框的数量 list_of_anno: [List] 存放label的列表, 里面有 track_id*frames 个数据, 按顺序从第一个序列的第一个track_id开始,存放每一帧的label model_PC: [List] 存放模板点云的列表, 里面有 track_id 个PointCloud类的点云数据,将每一个id的所有帧级联在一起作为模板 list_of_PCs: [List] 存放搜索点云的列表, 里面有 track_id*frames 个点云数据, 这里的不是整帧点云,是bbox内的点云 list_of_BBs: [List] 存放label的列表, 里面有 track_id*frames 个label数据,对应label文件中的一行label数据 \"\"\" def __init__(self, model, path, output, split=\"\", category_name=\"Car\", regress=\"GAUSSIAN\", sigma_Gaussian=1, offset_BB=0, scale_BB=1.0): super().__init__( model=model, path=path, split=split, category_name=category_name, regress=regress, offset_BB=offset_BB, scale_BB=scale_BB) self.sigma_Gaussian = sigma_Gaussian self.offset_BB = offset_BB self.scale_BB = scale_BB self.num_candidates_perframe = 147 logging.info(\"preloading PC...\") self.list_of_PCs = [None] * len(self.list_of_anno) self.list_of_BBs = [None] * len(self.list_of_anno) # 遍历,找到每一帧对应的label for index in tqdm(range(len(self.list_of_anno))): anno = self.list_of_anno[index] # NOTE 获取对应的点云和bbox信息,注意这里的点云是整帧点云! PC, box = self.getBBandPC(anno) # 将得到的点云处理,通过bbox,裁剪出在bbox里面的点,这里扩充了点云的边界 new_PC = utils.cropPC(PC, box, offset=10) # NOTE 将所有帧中的bbox以及bbox中的点云存成列表,这里的所有帧指的是不考虑track_id的情况,全部的点云帧 self.list_of_PCs[index] = new_PC self.list_of_BBs[index] = box logging.info(\"PC preloaded!\") logging.info(\"preloading Model..\") # 将一个track_id轨迹中的所有帧的点云汇集到一个bbox下，作为模板点云， 也就是这里的 self.model_PC self.model_PC = [None] * len(self.list_of_tracklet_anno) # 遍历每一个track_id 这里的 len(self.list_of_tracklet_anno) 就是track_id的种类数量 for i in tqdm(range(len(self.list_of_tracklet_anno))): list_of_anno = self.list_of_tracklet_anno[i] PCs = [] BBs = [] cnt = 0 # 遍历同一个track_id下的每一帧 for anno in list_of_anno: #　获取整帧点云以及bbox信息 this_PC, this_BB = self.getBBandPC(anno) PCs.append(this_PC) BBs.append(this_BB) # NOTE model_idx相当于是track_id, 但是不同, 其代表着排序之后的索引,每一个索引对应一个track_id, 但是具体对应哪个id, 随机 anno[\"model_idx\"] = i # reletive_idx相当于是对每一帧进行编号,一个轨迹序列的开始到结束 anno[\"relative_idx\"] = cnt cnt += 1 # 通过这个函数获取模板点云, 模板点云是将同一个track_id的所有点云帧的bbox中的点云级联在一起的 self.model_PC[i] = utils.getModelAndSave(PCs, BBs, offset=self.offset_BB, scale=self.scale_BB, save=True, path=os.path.join(output, category_name), name=category_name + str(i)) logging.info(\"Model preloaded!\") def __getitem__(self, index): return self.getitem(index) def getAnnotationIndex(self, index): # 每一个anno对应num_candidates_perframe个index, 所以需要除以num_candidates_perframe return int(index / self.num_candidates_perframe) def getSearchSpaceIndex(self, index): # 计算搜索空间的id,其实这个id没什么实际意义,如果非零, 那么代表当前这一批的搜索空间的序号 return int(index % self.num_candidates_perframe) def getPCandBBfromIndex(self, anno_idx): this_PC = self.list_of_PCs[anno_idx] this_BB = self.list_of_BBs[anno_idx] return this_PC, this_BB # NOTE 这里传入的index, 实际上取决于构建的数据集的长度,在这个数据集类中,__len__对应的长度是将所有点云帧的长度乘以了 num_candidates_perframe # NOTE num_candidates_perframe的含义就是 \"要生成的候选区域的数量\", 而传入的index就是按照点云帧长度乘以num_candidates_perframe来计算的 # NOTE 所以在通过index计算对应的label以及搜索空间的索引时,需要将index的数值除以 num_candidates_perframe def getitem(self, index): \"\"\"根据index的传入,计算并得到 当前的点云(this_pc)\\候选区域的点云(sample_pc)\\上一帧的点云(gt_pc)\\一整个序列的点云(model_pc) 几个重要的变量说明如下: anno_idx: 搜索点云的id, 通过传入的index计算得到, 用来得到搜索点云的label以及bbox等信息 sample_idx: 搜索空间的id, 用来计算sample_offsets,如果不是0,就需要通过滤波方法计算sample_offsets sample_offsets: 在搜索点云的周围采样一定数量的bbox, 这个offset相当于是一个偏置, 可以根据offset的值来计算当前搜索点云框周围的候选框 \"\"\" # 得到id anno_idx = self.getAnnotationIndex(index) sample_idx = self.getSearchSpaceIndex(index) # 计算得到sample_offsets if sample_idx == 0: sample_offsets = np.zeros(3) else: # PROBLEM 这里如何得到采样偏置的?具体没太看懂 gaussian = KalmanFiltering(bnd=[1, 1, 5]) sample_offsets = gaussian.sample(1)[0] # 搜索点云的label this","date":"2020-06-26","objectID":"/sc3d/:3:3","tags":["Tracking","DeepLearning"],"title":"SC3D论文\u0026代码阅读","uri":"/sc3d/"},{"categories":["深度学习"],"content":"4. class SiameseTest(SiameseDataset) SiameseTest class SiameseTest(SiameseDataset): def __init__(self, model, path, split=\"\", #\"Test\" category_name=\"Car\", regress=\"GAUSSIAN\", offset_BB=0, scale_BB=1.0): # offset_BB = 0 scale_BB = 1.25 super().__init__( model=model, path=path, split=split, category_name=category_name, regress=regress, offset_BB=offset_BB, scale_BB=scale_BB) self.split = split self.offset_BB = offset_BB self.scale_BB = scale_BB def getitem(self, index): list_of_anno = self.list_of_tracklet_anno[index] PCs = [] BBs = [] for anno in list_of_anno: # this_PC里面是当前帧的所有点云转换到相机坐标系下的点云数据 # this_BB是一个字典　里面的键对对应着中心点，whl,以及四元数角 this_PC, this_BB = self.getBBandPC(anno) PCs.append(this_PC) BBs.append(this_BB) return PCs, BBs, list_of_anno def __len__(self): # 返回label中要跟踪的车辆的个数 return len(self.list_of_tracklet_anno) 测试数据集的构建同样基于上面得到的 SiameseDataset 类，创建 SiameseTest 测试阶段输入的index与训练不同,这里只需要输入一个index, 这个index代表着 list_of_tracklet_anno 中的索引 ","date":"2020-06-26","objectID":"/sc3d/:3:4","tags":["Tracking","DeepLearning"],"title":"SC3D论文\u0026代码阅读","uri":"/sc3d/"},{"categories":["深度学习"],"content":"5. 其他 测试阶段 传入的参数 number_candidate 只在测试阶段起作用, 但是经过打印输出, 无论输出的数值是多少, 产生的都是 147个搜索框! 所以测试阶段的网络输入的两个点云, 其shape 都是 (147, 3, 2048) ","date":"2020-06-26","objectID":"/sc3d/:3:5","tags":["Tracking","DeepLearning"],"title":"SC3D论文\u0026代码阅读","uri":"/sc3d/"},{"categories":["必备工具"],"content":"git常用命令 全局配置 # 配置用户名 git config --global user.name \"your_user_name\" # 配置用户邮箱 git config --global user.email \"your_email_address\" # 查看当前git状态 git status # 查看git日志 git log 版本控制 #　回退到上一个版本 git reset --hard HEAD^ #　回退到上上个版本 git reset --hard HEAD^^ #　查看相对日志，这个是相对于clone仓库之后的，就是说如果你从网上克隆一个仓库，那么reflog应该是空的 git reflog # 查看所有日志，也包括克隆仓库的以前代码版本信息 git log #　回退到任意版本 git reset --hard 版本号 分支操作 # 查看分支 git branch # 创建分支 git branch name # 跳转分支 git checkout name # 创建并跳转分支 git checkout –b name # 合并某分支到当前分支 git merge name # 删除分支 git branch –d name # 重命名本地分支 git branch -m oldName newName # 重命名本地分支后，如果想删除远程分支，那么 git push --delete origin oldName 更多 ","date":"2020-05-26","objectID":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:0:1","tags":["Git","Tools"],"title":"git学习记录","uri":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["必备工具"],"content":"创建git仓库的几种方式 通过本地空文件创建，使用以下命令 git init 通过克隆远程仓库到本地，使用以下命令 git clone your_repos_address 通过pull远程仓库到本地，使用以下命令 git init git remote add origin your_repos_address git pull origin your_branch_name ","date":"2020-05-26","objectID":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:0:2","tags":["Git","Tools"],"title":"git学习记录","uri":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["必备工具"],"content":"提交本地仓库到远程仓库的方式 git add -A git commit -m \"your_commit_message\" git remote add origin your_repos_address git push origin your_branch_name 如果push报错，可能需要先pull，在进行push 提交时注意要提交的分支以及本地当前所在的分支是否一致，若不一致，需要切换到对应分支 ","date":"2020-05-26","objectID":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:0:3","tags":["Git","Tools"],"title":"git学习记录","uri":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["必备工具"],"content":"删除远程分支的方式 # 首先切换到要删除的分支，若本地没有对应分支，则创建 git checkout your_branch_name git branch -r -d origin/branch-name git push origin :branch-name ","date":"2020-05-26","objectID":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:0:4","tags":["Git","Tools"],"title":"git学习记录","uri":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["必备工具"],"content":"自动保存账户密码 有两种方式设置 第一种是设置当前git仓库的配置文件，这样只对当前仓库有效 git config -e 第二种是设置全局git配置文件，对所有仓库均有效 git config --global -e 无论哪一种，在打开的配置文件中，添加上以下命令 [credential] helper = store 保存后，重启终端，输入一次密码后就会自动保存，以后就不需要再输入密码啦～ ","date":"2020-05-26","objectID":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:0:5","tags":["Git","Tools"],"title":"git学习记录","uri":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["必备工具"],"content":"常见错误记录 RPC failed 如果在 git commit 时出现以下错误，可以尝试重新清空 git 全局配置 error: RPC failed; curl 56 GnuTLS recv error (-12): A TLS fatal alert has been received. 使用 git config --global -e 来查看全局配置文件 使用 git config -e 来查看当前仓库的配置文件 ","date":"2020-05-26","objectID":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:0:6","tags":["Git","Tools"],"title":"git学习记录","uri":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["必备工具"],"content":"2021.8.13之后不可以使用password执行git操作 大概意思是，原有的git pull或者git push 操作时，使用的用户名+密码的方式，改成了用户名+token，所以需要我们做一些改动 生成token Settings =\u003e Developer Settings  Personal Access Token  Generate New Token  Fillup the form Generate token Copy the generated Token, it will be something like ghp_sFhFsSHhTzMDreGRLjmks4Tzuzgthdvfsrta 配置git 自动缓存 注意，这里如果使用 cache 的话，过段时间会自动忘记的，默认是15分钟，所以为了方便，可以存储密码到本地，将cache改为store，这个看自己选择了 “store” 模式可以接受一个 --file \u003cpath\u003e 参数，可以自定义存放密码的文件路径（默认是 ~/.git-credentials ） “cache” 模式有 --timeout \u003cseconds\u003e 参数，可以设置后台进程的存活时间（默认是 “900”，也就是 15 分钟） $ git config --global user.name \"\" $ git config --global user.email \"\" $ git config -l $ git config --global credential.helper cache # 设置自动缓存 再次上传，第一次输入token 后续git就会自己记住的 ","date":"2020-05-26","objectID":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:0:7","tags":["Git","Tools"],"title":"git学习记录","uri":"/git%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":["深度学习"],"content":" 本文要完成的工作是将KITTI数据集中的点云信息投影到图像中，以达到信息融合的目的.　使用KITTI中的经过时钟同步和校准后的数据文件 raw_data 来进行投影变换。其主要操作就是坐标系之间的变换。 ","date":"2020-03-22","objectID":"/kitti%E6%95%B0%E6%8D%AE%E9%9B%86%E7%82%B9%E4%BA%91%E6%8A%95%E5%BD%B1%E5%88%B0%E5%9B%BE%E5%83%8F/:0:0","tags":["KITTI","DeepLearning","点云投影"],"title":"KITTI数据集点云图像的投影","uri":"/kitti%E6%95%B0%E6%8D%AE%E9%9B%86%E7%82%B9%E4%BA%91%E6%8A%95%E5%BD%B1%E5%88%B0%E5%9B%BE%E5%83%8F/"},{"categories":["深度学习"],"content":"1. KITTI数据集介绍 kitti的数据采集平台，配置有四个摄像机和一个激光雷达，四个摄像机中有两个灰度摄像机，两个彩色摄像机 从图中可看出，关于相机坐标系(camera)的方向与雷达坐标系(velodyne)的方向规定 camera: x = right, y = down, z = forward velodyne: x = forward, y = left, z = up 那么velodyne所采集到的点云数据中，各点的x轴坐标，即为所需的深度信息。 更多详细的简介网络上都能搜索到，这里只列举了与当前目的相关的必要信息。 ","date":"2020-03-22","objectID":"/kitti%E6%95%B0%E6%8D%AE%E9%9B%86%E7%82%B9%E4%BA%91%E6%8A%95%E5%BD%B1%E5%88%B0%E5%9B%BE%E5%83%8F/:0:1","tags":["KITTI","DeepLearning","点云投影"],"title":"KITTI数据集点云图像的投影","uri":"/kitti%E6%95%B0%E6%8D%AE%E9%9B%86%E7%82%B9%E4%BA%91%E6%8A%95%E5%BD%B1%E5%88%B0%E5%9B%BE%E5%83%8F/"},{"categories":["深度学习"],"content":"2. KITTI数据集中的raw_data raw_data对于每个序列都提供了同步且校准后的数据、标定数据。 同步且校准后的数据： ./imageXX 包含有各个摄像机采集到的图像序列 ‘image_00’: left rectified grayscale image sequence ‘image_01’: right rectified grayscale image sequence ‘image_02’: left rectified color image sequence ‘image_03’: right rectified color image sequence ./velodyne_points 包含有雷达扫描到的数据，点云形式，每个点以 (x,y,z,i) 格式存储，i为反射值 雷达采集数据时，是绕着竖直轴旋转扫描，只有当雷达旋转到与相机的朝向一致时会触发相机采集图像。不过在这里无需关注这一点，直接使用给出的同步且校准后的数据即可，它已将雷达数据与相机数据对齐，也就是可以认为同一文件名对应的图像数据与雷达点云数据属于同一个场景。 标定数据： ./cam_to_cam 包含有各个摄像机的标定参数 ./velo_to_cam 包含有雷达到摄像机的变换参数 对于raw_data，kitti还提供了样例工具，方便读取各种数据文件并输出，参见官网raw_data下载页的development kit ","date":"2020-03-22","objectID":"/kitti%E6%95%B0%E6%8D%AE%E9%9B%86%E7%82%B9%E4%BA%91%E6%8A%95%E5%BD%B1%E5%88%B0%E5%9B%BE%E5%83%8F/:0:2","tags":["KITTI","DeepLearning","点云投影"],"title":"KITTI数据集点云图像的投影","uri":"/kitti%E6%95%B0%E6%8D%AE%E9%9B%86%E7%82%B9%E4%BA%91%E6%8A%95%E5%BD%B1%E5%88%B0%E5%9B%BE%E5%83%8F/"},{"categories":["深度学习"],"content":"3. 利用kitti提供的devkit以及相应数据集的calib文件 解读calib文件夹 cam_to_cam，包含各相机的标定参数 S_xx: 1x2 矫正前xx号相机的图片尺寸 K_xx: 3x3 矫正前xx号相机的标定参数 D_xx: 1x5 矫正前xx号相机的畸变系数 R_xx: 3x3 外参，xx号相机的旋转矩阵 T_xx: 3x1 外参，xx号相机的平移矩阵 S_rect_xx: 1x2 矫正后XX号相机的图片尺寸 R_rect_xx: 3x3 旋转矩阵，用于矫正xx号相机，使得图像平面共面(原话是make image planes co-planar)。 P_rect_0x: 3x4 投影矩阵，用于从矫正后的0号相机坐标系 投影到 X号相机的图像平面。 这里只用到最后两个矩阵R_rect和P_rect velo_to_cam，从雷达坐标系到0号相机坐标系的转换 R: 3x3 旋转矩阵 T: 3x1 平移矩阵 delta_f 和delta_c 已被弃用 由此可以得出从雷达坐标系变换到xx号相机的图像坐标系的公式： 设X为雷达坐标系中的齐次坐标 X = [x y z 1]'，对应于xx号相机的图像坐标系的齐次坐标Y = [u v 1]'，则： Y = P_rect_xx * R_rect_00 * (R|T)_velo_to_cam * X (R|T) ： 雷达坐标系 -\u003e 0号相机坐标系 R_rect_00： 0号相机坐标系 -\u003e 矫正后的0号相机坐标系 P_rect_0x： 矫正后的0号相机坐标系 -\u003e 0号相机的图像平面 解读devkit 官网提供的样例代码中 run_demoVelodyne.m 实现了将雷达点云投影到相机图像 大致说一下步骤： 从所给路径中读取标定文件，获取具体矩阵数值 根据上述公式，计算投影矩阵 P_velo_to_img，即 Y = P_velo_to_img * X 从所给路径中读取相机图片，并加载雷达的点云数据。由于只做展示用，为了加快运行速度，对于雷达点云，每隔5个点只保留1个点 移除那些距离雷达5米之内(雷达的x方向)的点 (猜测这些点落在相机和雷达之间，故不会出现在图像平面上) 作投影计算，得到投影到二维图像上的点 在图像上画出投影后的点，按照深度(雷达点的x方向值)确定颜色，彩色则是暖色越近，冷色越远；灰度则是深色越近，浅色越远。 ","date":"2020-03-22","objectID":"/kitti%E6%95%B0%E6%8D%AE%E9%9B%86%E7%82%B9%E4%BA%91%E6%8A%95%E5%BD%B1%E5%88%B0%E5%9B%BE%E5%83%8F/:0:3","tags":["KITTI","DeepLearning","点云投影"],"title":"KITTI数据集点云图像的投影","uri":"/kitti%E6%95%B0%E6%8D%AE%E9%9B%86%E7%82%B9%E4%BA%91%E6%8A%95%E5%BD%B1%E5%88%B0%E5%9B%BE%E5%83%8F/"},{"categories":["编程算法"],"content":"1. python与ros兼容性问题 如果使用了conda环境或者是系统本身的python环境，但是在运行某一条命令时，显示在某一个路径下找不到固定的模块，类似 (python3) $ CUDA_VISIBLE_DEVICES=0 python -u train.py --work-path ./experiments/cifar10/lenet Traceback (most recent call last): File \"train.py\", line 9, in \u003cmodule\u003e import yaml File \"/opt/ros/kinetic/lib/python2.7/dist-packages/yaml/__init__.py\", line 1, in \u003cmodule\u003e from error import * ModuleNotFoundError: No module named 'error' 使用pip list查找之后，发现对应的yaml包是有安装的 这种问题的原因就是：在sys的路径中，混入了ros的python路径，导致找不到对应的包，所以我们可以在对应的python文件最上面，加入以下代码： import sys ros_path = '/opt/ros/kinetic/lib/python2.7/dist-packages' if ros_path in sys.path: sys.path.remove(ros_path) ","date":"2020-03-06","objectID":"/python%E4%B8%8Eros%E5%85%BC%E5%AE%B9%E6%80%A7%E9%97%AE%E9%A2%98/:1:0","tags":["python","ros"],"title":"Python与ros兼容问题记录","uri":"/python%E4%B8%8Eros%E5%85%BC%E5%AE%B9%E6%80%A7%E9%97%AE%E9%A2%98/"},{"categories":["编程算法"],"content":"2. python3、ros以及cv_bridge的兼容性问题 在使用python3以及ros中的cv包的时候，想要通过python3来创建一个节点接收话题形式的图像信息，然而在消息回调中如果想要通过cv_bridge来将消息格式进行转换，则会报错，形式如下： [ERROR] [1520780674.845066]: bad callback: \u003cbound method ViewsBuffer.update of \u003c__main__.ViewsBuffer object at 0x7f5f45a07f28\u003e\u003e Traceback (most recent call last): File \"/opt/ros/kinetic/lib/python2.7/dist-packages/rospy/topics.py\", line 750, in _invoke_callback cb(msg) File \"test.py\", line 48, in update im = self.bridge.imgmsg_to_cv2(im, \"bgr8\") File \"/opt/ros/kinetic/lib/python2.7/dist-packages/cv_bridge/core.py\", line 163, in imgmsg_to_cv2 dtype, n_channels = self.encoding_to_dtype_with_channels(img_msg.encoding) File \"/opt/ros/kinetic/lib/python2.7/dist-packages/cv_bridge/core.py\", line 99, in encoding_to_dtype_with_channels return self.cvtype2_to_dtype_with_channels(self.encoding_to_cvtype2(encoding)) File \"/opt/ros/kinetic/lib/python2.7/dist-packages/cv_bridge/core.py\", line 91, in encoding_to_cvtype2 from cv_bridge.boost.cv_bridge_boost import getCvType ImportError: dynamic module does not define module export function (PyInit_cv_bridge_boost) 这里我尝试了stackflow中给出的解决方案，如下： # `python-catkin-tools` is needed for catkin tool # `python3-dev` and `python3-catkin-pkg-modules` is needed to build cv_bridge # `python3-numpy` and `python3-yaml` is cv_bridge dependencies # `ros-kinetic-cv-bridge` is needed to install a lot of cv_bridge deps. Probaply you already have it installed. sudo apt-get install python-catkin-tools python3-dev python3-catkin-pkg-modules python3-numpy python3-yaml ros-kinetic-cv-bridge # Create catkin workspace mkdir catkin_workspace cd catkin_workspace catkin init # Instruct catkin to set cmake variables catkin config -DPYTHON_EXECUTABLE=/usr/bin/python3 -DPYTHON_INCLUDE_DIR=/usr/include/python3.5m -DPYTHON_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.5m.so # Instruct catkin to install built packages into install place. It is $CATKIN_WORKSPACE/install folder catkin config --install catkin config --space-suffix _cb # Clone cv_bridge src git clone https://github.com/ros-perception/vision_opencv.git src/vision_opencv # Find version of cv_bridge in your repository apt-cache show ros-kinetic-cv-bridge | grep Version Version: 1.12.8-0xenial-20180416-143935-0800 # Checkout right version in git repo. In our case it is 1.12.8 cd src/vision_opencv/ git checkout 1.12.8 cd ../../ # Build catkin build cv_bridge # Extend environment with new package source install/setup.bash --extend 还有一种方案,需要替换系统中的libboost_python到指定的环境下，因为我使用的是connda 环境，所以测试之后并不好用。 最终方案 使用ubuntu16.04 以及系统环境中的python3 解决思路：下载cv_bridge的源码到对应的ros工作空间中,　然后使用catkin config进行单独编译，其余的package可以使用catkin_make进行编译，仅需在catkin config时配置新的编译输出文件夹即可。 解决详细步骤如下： 首先更改系统的~/.bashrc文件，取消conda的环境变量配置，并且设置python为python3 #__conda_setup=\"$('/home/echo/anaconda2/bin/conda' 'shell.bash' 'hook' 2\u003e /dev/null)\" #if [ $? -eq 0 ]; then # eval \"$__conda_setup\" #else # if [ -f \"/home/echo/anaconda2/etc/profile.d/conda.sh\" ]; then # . \"/home/echo/anaconda2/etc/profile.d/conda.sh\" # else # export PATH=\"/home/echo/anaconda2/bin:$PATH\" # fi #fi #unset __conda_setup alias python=python3 #切换系统默认的python3.5　屏蔽以后默认为python2.7 安装对应的python3和ros功用的依赖，具体参考 接下来catkin config 配置cv_bridge # `python-catkin-tools` is needed for catkin tool # `python3-dev` and `python3-catkin-pkg-modules` is needed to build cv_bridge # `python3-numpy` and `python3-yaml` is cv_bridge dependencies # `ros-kinetic-cv-bridge` is needed to install a lot of cv_bridge deps. Probaply you already have it installed. sudo apt-get install python-catkin-tools python3-dev python3-catkin-pkg-modules python3-numpy python3-yaml ros-kinetic-cv-bridge # Create catkin workspace mkdir catkin_workspace cd catkin_workspace catkin init # Instruct catkin to set cmake variables catkin config -DPYTHON_EXECUTABLE=/usr/bin/python3 -DPYTHON_INCLUDE_DIR=/usr/include/python3.5m -DPYTHON_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.5m.so # Instruct catkin to install built packages into install place. It is $CATKIN_WORKSPACE/install fol","date":"2020-03-06","objectID":"/python%E4%B8%8Eros%E5%85%BC%E5%AE%B9%E6%80%A7%E9%97%AE%E9%A2%98/:2:0","tags":["python","ros"],"title":"Python与ros兼容问题记录","uri":"/python%E4%B8%8Eros%E5%85%BC%E5%AE%B9%E6%80%A7%E9%97%AE%E9%A2%98/"},{"categories":null,"content":" Hi，这里是jiayao的博客，我是一名普通的程序员，热衷于各种科技内容的探索以及尝试，目前处于研究生阶段，研究内容侧重于深度学习与移动机器人感知。 关于本博客，我的定位是用来展示思考以及总结的内容，包括学习和平时的生活，虽然大多是来源于自己的所思所感，但我也十分希望它们能给屏幕前的你提供一些帮助。对于博客内容，也欢迎大家转载，不过前提是注明出处及作者。后续可能也会考虑加入RSS订阅的功能，看心情~ 关于我本人，除了本博客外，你还可以通过Email以及github联系到我，如有机会，非常开心能和各位交流~ ","date":"2020-02-14","objectID":"/about/:0:0","tags":null,"title":"关于","uri":"/about/"},{"categories":["编程算法"],"content":"使用python中的time模块计算代码运行时间 在计算算法的耗时性时，需要通过一些方法计算代码实际运行的时间，在python中time模块集成了一些方法，可以很方便的计算耗时。 ","date":"2020-01-11","objectID":"/python%E4%B8%AD%E7%9A%84time%E6%A8%A1%E5%9D%97/:1:0","tags":["Python"],"title":"python中的time模块","uri":"/python%E4%B8%AD%E7%9A%84time%E6%A8%A1%E5%9D%97/"},{"categories":["编程算法"],"content":"几种函数简介 time模块提供各种与时间相关的功能，如当前时间、时间戳等，下面只说明用来计算代码运行时间的几种常用函数，python环境为python3 time.time() 返回当前时间的时间戳(1970元年后的浮点秒数)，这个函数容易收到系统时间的影响，所以一般计算代码耗时都不会选择time函数。 time.perf_counter() 返回计时器的精准时间(系统的运行时间)，包含整个系统的睡眠时间．这里的睡眠时间指的是人工使用类似 time.sleep() 的额外时间。 使用时需计算两次之间差值。计算耗时时，如果没有人为的睡眠时间，可以使用这个函数。 time.process_time() 返回当前进程执行CPU的时间总和，不包含睡眠时间．使用时需计算两次之间差值作为代码运行时间。 ","date":"2020-01-11","objectID":"/python%E4%B8%AD%E7%9A%84time%E6%A8%A1%E5%9D%97/:1:1","tags":["Python"],"title":"python中的time模块","uri":"/python%E4%B8%AD%E7%9A%84time%E6%A8%A1%E5%9D%97/"},{"categories":["编程算法"],"content":"代码测试 from time import time, perf_counter, process_time, sleep class TimeDemo: def __init__(self): pass def test_time(self): time0 = time() for i in range(10000000): i = 0 sleep(2) time1 = time() print(\"time function : {0}\".format(time1 - time0)) def test_perf_cnt(self): time0 = perf_counter() for i in range(10000000): i = 0 sleep(2) time1 = perf_counter() print(\"perf_counter function : {0}\".format(time1 - time0)) def test_process_time(self): time0 = process_time() for i in range(10000000): i = 0 sleep(2) time1 = process_time() print(\"process_time function : {0}\".format(time1 - time0)) if __name__ == '__main__': timedemo = TimeDemo() timedemo.test_time() timedemo.test_perf_cnt() timedemo.test_process_time() ","date":"2020-01-11","objectID":"/python%E4%B8%AD%E7%9A%84time%E6%A8%A1%E5%9D%97/:1:2","tags":["Python"],"title":"python中的time模块","uri":"/python%E4%B8%AD%E7%9A%84time%E6%A8%A1%E5%9D%97/"},{"categories":null,"content":"==⚠ Switch to EXCALIDRAW VIEW in the MORE OPTIONS menu of this document. ⚠== Text Elements input1 ^fDU40BcG input2 ^NJ72W2MV backbone ^yv5YgAhc backbone ^qioVtaq7 Matching ^apXl2V0u similarity map ^TuJO8GcA scene flow estimator ^gmmcwo5p tracker ^yc903fwU semantic corresponding ^yBNnaJyc template ^nvyuv3AJ search ^onoUVSye %% Drawing { \"type\": \"excalidraw\", \"version\": 2, \"source\": \"https://excalidraw.com\", \"elements\": [ { \"type\": \"rectangle\", \"version\": 130, \"versionNonce\": 166362809, \"isDeleted\": false, \"id\": \"66U6IrccEEF-o6QvE_w8t\", \"fillStyle\": \"hachure\", \"strokeWidth\": 1, \"strokeStyle\": \"solid\", \"roughness\": 1, \"opacity\": 100, \"angle\": 0, \"x\": -376, \"y\": -50, \"strokeColor\": \"#000000\", \"backgroundColor\": \"transparent\", \"width\": 171, \"height\": 51, \"seed\": 1274428537, \"groupIds\": [], \"strokeSharpness\": \"sharp\", \"boundElements\": [ { \"id\": \"O5vzV978n8F3_ApiB4IQk\", \"type\": \"arrow\" }, { \"type\": \"text\", \"id\": \"fDU40BcG\" } ], \"updated\": 1642313157103 }, { \"type\": \"rectangle\", \"version\": 193, \"versionNonce\": 320594551, \"isDeleted\": false, \"id\": \"_9Gc7OiLNhcw4IQ0bOIC6\", \"fillStyle\": \"hachure\", \"strokeWidth\": 1, \"strokeStyle\": \"solid\", \"roughness\": 1, \"opacity\": 100, \"angle\": 0, \"x\": -374.5, \"y\": 49.5, \"strokeColor\": \"#000000\", \"backgroundColor\": \"transparent\", \"width\": 171, \"height\": 51, \"seed\": 1186501625, \"groupIds\": [], \"strokeSharpness\": \"sharp\", \"boundElements\": [ { \"id\": \"CLTxyS-dO7tfy7NnwjVxD\", \"type\": \"arrow\" }, { \"type\": \"text\", \"id\": \"NJ72W2MV\" }, { \"id\": \"ZRtOkUVRplBMYYJt08Ypv\", \"type\": \"arrow\" } ], \"updated\": 1642313157103 }, { \"type\": \"rectangle\", \"version\": 267, \"versionNonce\": 903998809, \"isDeleted\": false, \"id\": \"bso05_TXyROoyH9W4EGx7\", \"fillStyle\": \"hachure\", \"strokeWidth\": 1, \"strokeStyle\": \"solid\", \"roughness\": 1, \"opacity\": 100, \"angle\": 0, \"x\": -102.5, \"y\": -47.5, \"strokeColor\": \"#000000\", \"backgroundColor\": \"transparent\", \"width\": 171, \"height\": 51, \"seed\": 1054175225, \"groupIds\": [], \"strokeSharpness\": \"sharp\", \"boundElements\": [ { \"id\": \"O5vzV978n8F3_ApiB4IQk\", \"type\": \"arrow\" }, { \"id\": \"CLTxyS-dO7tfy7NnwjVxD\", \"type\": \"arrow\" }, { \"id\": \"trm98k4u_OLplHHasM7xX\", \"type\": \"arrow\" }, { \"type\": \"text\", \"id\": \"qioVtaq7\" } ], \"updated\": 1642313157103 }, { \"type\": \"arrow\", \"version\": 402, \"versionNonce\": 834483623, \"isDeleted\": false, \"id\": \"O5vzV978n8F3_ApiB4IQk\", \"fillStyle\": \"hachure\", \"strokeWidth\": 1, \"strokeStyle\": \"solid\", \"roughness\": 1, \"opacity\": 100, \"angle\": 0, \"x\": -192.04723847694692, \"y\": -15.692603683294012, \"strokeColor\": \"#000000\", \"backgroundColor\": \"transparent\", \"width\": 78.30422846078864, \"height\": 1.1923505212674588, \"seed\": 1004126615, \"groupIds\": [], \"strokeSharpness\": \"round\", \"boundElements\": [], \"updated\": 1642287877285, \"startBinding\": { \"elementId\": \"66U6IrccEEF-o6QvE_w8t\", \"gap\": 12.952761523053084, \"focus\": 0.38454524962052505 }, \"endBinding\": { \"elementId\": \"bso05_TXyROoyH9W4EGx7\", \"gap\": 11.243010016158252, \"focus\": -0.13588298490134978 }, \"lastCommittedPoint\": null, \"startArrowhead\": null, \"endArrowhead\": \"arrow\", \"points\": [ [ 0, 0 ], [ 78.30422846078864, -1.1923505212674588 ] ] }, { \"type\": \"arrow\", \"version\": 342, \"versionNonce\": 988007751, \"isDeleted\": false, \"id\": \"trm98k4u_OLplHHasM7xX\", \"fillStyle\": \"hachure\", \"strokeWidth\": 1, \"strokeStyle\": \"solid\", \"roughness\": 1, \"opacity\": 100, \"angle\": 0, \"x\": 77.64894897130611, \"y\": -20.807633981453424, \"strokeColor\": \"#000000\", \"backgroundColor\": \"transparent\", \"width\": 54.35186296079709, \"height\": 19.807929881047155, \"seed\": 1555041463, \"groupIds\": [], \"strokeSharpness\": \"round\", \"boundElements\": [], \"updated\": 1642287877291, \"startBinding\": { \"elementId\": \"bso05_TXyROoyH9W4EGx7\", \"gap\": 9.148948971306112, \"focus\": -0.5877456544479325 }, \"endBinding\": { \"elementId\": \"_Au4dCWwCulk8UgiV6_zS\", \"gap\": 15.867871587938623, \"focus\": 0.026250426884594915 }, \"lastCommittedPoint\": null, \"startArrowhead\": null, \"endArrowhead\": \"arrow\", \"points\": [ [ 0, 0 ], [ 54.35186296079709, 19.807929881047155 ] ] }, { \"type\": \"text\", \"version\": 76, \"versio","date":"0001-01-01","objectID":"/matching-based-pipeline.excalidraw/:0:0","tags":null,"title":"","uri":"/matching-based-pipeline.excalidraw/"},{"categories":null,"content":"工具 ","date":"0001-01-01","objectID":"/collections/:1:0","tags":null,"title":"工具\u0026资源收集","uri":"/collections/"},{"categories":null,"content":"在线工具 Convertio 各种格式转换都可以在这上面找到 Remove.bg 移除图片背景的神器，使用时尽量选取前景背景相差明显的图片，毕竟要对AI宽容一点 Draw.io 在线画流程图 ProcessOn 在线画流程图，个人感觉比draw.io更美观 QuickRef.ME 编程\u0026IDE速查表 ProtonMail 匿名邮箱 voxelize-image 图像体素化 Tables Grnerator 在线生成各种表格源码，包括Latex、HTML以及Markdown，极其强大 Tables Convert 在线转换各种表格， 包括csv、json、latex、html、excel等 ","date":"0001-01-01","objectID":"/collections/:1:1","tags":null,"title":"工具\u0026资源收集","uri":"/collections/"},{"categories":null,"content":"chrome插件 GitZip for github github下载助手，可以下载单独文件 Enhanced GitHub github功能拓展，可以显示仓库大小等，也可以辅助下载 Proxy SwitchyOmega 好用的代理管理工具 ImageAssistant 网页图片抓取 Web Clipper 屏幕截图 HTML5 Outliner 网页目录提取、跳转等 Find Code for Research Papers 代码搜索工具，在arxiv等论文网站上可以显示对应论文是否有代码，并提供链接 ","date":"0001-01-01","objectID":"/collections/:1:2","tags":null,"title":"工具\u0026资源收集","uri":"/collections/"},{"categories":["思考总结"],"content":"辛丑岁末，壬寅之初，转眼间春节已过，元宵将至，而这篇本该年底做好的总结又被我的拖延症耽搁了很久，今天终于有时间坐下来好好地回忆下，属于我的，辛丑牛年。 古人言，三十而立，而在过去的一年里，我度过了我的二十五岁，距离而立之年又进了一步。之所以想要写这篇文章，一是为了培养自己总结的习惯，二是过去的这一年的确有很多事情，算得上记忆深刻，匆匆一年，颇有感触。关于内容方面，不善言辞的我酝酿了很久，最终还是觉得想到哪里写哪里吧，或许，我也可以称之为，碎碎念。最近也的确是在努力回顾过往的这一年中发生的大事，比如秋招，比如实习，比如感情，但有些依旧在脑海记忆中飘忽不定，有些则是挥散不掉。所以关于本文，我不想以事件向叙述，更多地是想记录的是一些心路历程，或者是个人感触，或者是，心境的变化~ ","date":"0001-01-01","objectID":"/2021-%E8%BE%9B%E4%B8%91%E7%89%9B%E5%B9%B4/:0:0","tags":["年度总结"],"title":"辛丑牛年的自己","uri":"/2021-%E8%BE%9B%E4%B8%91%E7%89%9B%E5%B9%B4/"},{"categories":["思考总结"],"content":"认知低谷 对于目前没有读博想法的我，转眼之间，求学之路即将结束，年底和朋友相聚时还在感慨，恍惚间高中毕业到现在已经快7年了，而大学毕业也已近3年。回首三年的研究生生涯，也算是一路跌跌撞撞走到现在吧，过去的一年也算得上是收获的一年，虽然一直觉得自己的能力还比较差，但还是比较幸运地通过了秋招，也有机会去心仪的公司实习了一段时间，带来的外在收获倒是次要的，对我最大的帮助是让我见到了更多优秀的人，从而进一步认识到了自己的不足。正如达克效应（D-K effect）所描述的第三个阶段 — 认知低谷。 达克效应是一种认知偏差现象，指的是能力欠缺的人在自己欠缺能力的基础上得出自己认为正确但其实错误的结论，行为者无法正确认识到自身的不足，辨别错误行为。这些能力欠缺者们沉浸在自我营造的虚幻的优势之中，常常高估自己的能力水平，却无法客观评价他人的能力。达克效应可以分为五个阶段，分别是：自我膨胀 -\u003e 迅速清醒 -\u003e 认知低谷 -\u003e 重拾自信 -\u003e 逐渐成长。 对于我个人而言，仍然有很多要学习的知识，行业信息，专业知识，生活琐碎，等等。希望新的一年可以学到更多的知识，加油=.= ","date":"0001-01-01","objectID":"/2021-%E8%BE%9B%E4%B8%91%E7%89%9B%E5%B9%B4/:1:0","tags":["年度总结"],"title":"辛丑牛年的自己","uri":"/2021-%E8%BE%9B%E4%B8%91%E7%89%9B%E5%B9%B4/"},{"categories":["思考总结"],"content":"不要以未发生的事作为选择的筹码 前段时间自己在校外实习，先不说工作情况，每个月的工资就着实让我经济上相对独立了很多，也入手了一些之前心心念念期望已久的好物。但是当时有一些设备买的时候是考虑回学校之后应该还可以拿到一些奖学金，包括课题组的一些奖金，索性就是提前预支一些，早买早享受嘛，便签了一部分某东白条。然而事情却并没有如期发展，回校之后奖学金并没有评选，课题组的奖金导师也只字不提，导致本就艰难的生活更加拮据。现在想想，确实是不应该，而且很多时候自己都有这种心理。以花呗为例，可能现在很多人在做事时会有一种透支的观念，觉得自己未来有能力做到，于是未来的成果变成了现在的成果。往大说买房买车，往小说生活琐碎，均可提前预支。我现在就还深受这种想法的荼毒，现在回想，这样做的后果只能是未来的自己越发负重前行。所以如果可能，尽量不要习惯以未发生的事情作为当下做选择的筹码。当然了，具体情况具体分析，事件发生的概率也有很大关系。 ","date":"0001-01-01","objectID":"/2021-%E8%BE%9B%E4%B8%91%E7%89%9B%E5%B9%B4/:2:0","tags":["年度总结"],"title":"辛丑牛年的自己","uri":"/2021-%E8%BE%9B%E4%B8%91%E7%89%9B%E5%B9%B4/"},{"categories":["思考总结"],"content":"接受自己内心的选择 随着年纪越来越大，接触的事情也越来越多，也会面临更多的选择。以上帝视角来看，我们总是回想以现在的自己回到之前的年纪，总会想之前的自己做的差强人意。而以当事人的视角来看，每次面临重大选择时，我们或许会受限于自己的认知不足，比如高考，比如就业秋招，也许会受到周围环境的影响，比如家里的看法，比如大环境下的趋势。但是我想说的是，我们还是要学会接受自己内心的选择。当然了，有时候选择是一个天秤，而自己内心的独白与外在的影响是左右托盘上的砝码，孰重孰轻，还需我们自己考量。 其实想一想，自己的经历中，大多重要的选择都受限于认知不足。高考填报志愿时，自己完全没有概念，甚至很多专业听名字都不知道是做什么的，当时家中一位长辈帮忙选择了机械工程的专业，说是这个专业以后的选择会多一些，不过其实当我接触所学专业之后，也谈不上讨厌，但是的确是很难提起学习的兴趣。而秋招找工作也是同理，有时候我甚至会觉得这是一个悖论，往往面临选择时我们需要一些指导我们做选择的依凭，但这些依凭却需要我们做了选择之后才能获得，这时我们能做的，除了通过社交渠道咨询之外，更多的是要遵循内心的决定，往往最初的选择就是自己想要的。总之，做了选择之后，如果短期内得不到结果好坏的反馈，那就坚定的走下去吧，路是否适合自己，走过才知道。 哦对，还有一句话我觉得很棒，也写在这里你我共勉： 人生不得行胸臆，纵年百岁犹为夭 —- 明末文人袁中郎 ","date":"0001-01-01","objectID":"/2021-%E8%BE%9B%E4%B8%91%E7%89%9B%E5%B9%B4/:3:0","tags":["年度总结"],"title":"辛丑牛年的自己","uri":"/2021-%E8%BE%9B%E4%B8%91%E7%89%9B%E5%B9%B4/"},{"categories":["思考总结"],"content":"拒绝感性 我是一个什么样的的人？内心坚定？感性或理性？从我对自己的认知与批判来看，过往的经历我大多会以一种感性的思维来做决定和做事，可能这是天性使然。 诚然，一腔热血地去做事固然可以让我们更加投入和忘我，但也容易变成一腔孤勇，最后只剩自己的执拗在作祟。所以啊，不要再被自己的感性大脑左右，新的一年，不妨尝试抛弃不切实际的想法，多做定期的规划，让自己忙起来，很多思考了很久的决定，学会选择遵守，而不是被临时的冲动违背，也希望自己回想起这篇碎碎念的时候能够形成对自己的约束。 ","date":"0001-01-01","objectID":"/2021-%E8%BE%9B%E4%B8%91%E7%89%9B%E5%B9%B4/:4:0","tags":["年度总结"],"title":"辛丑牛年的自己","uri":"/2021-%E8%BE%9B%E4%B8%91%E7%89%9B%E5%B9%B4/"},{"categories":["思考总结"],"content":"结束语 说了这么多，最后的最后，愿新年，胜旧年。辛丑牛年已过！求学生涯也即将结束，接下来迎接自己的，应该是打工人的酸甜苦辣，希望新的一年自己可以变得更好，但求心安，不留遗憾！ ","date":"0001-01-01","objectID":"/2021-%E8%BE%9B%E4%B8%91%E7%89%9B%E5%B9%B4/:5:0","tags":["年度总结"],"title":"辛丑牛年的自己","uri":"/2021-%E8%BE%9B%E4%B8%91%E7%89%9B%E5%B9%B4/"},{"categories":null,"content":"Lidar-based 3D Object Tracking ","date":"0001-01-01","objectID":"/projects/:1:0","tags":null,"title":"项目","uri":"/projects/"},{"categories":null,"content":"Transformer \u0026 Tracking [conference paper]. [code]. [Youtube]. [Bilibili] [1] J. Shan, S. Zhou, Z. Fang and Y. Cui, “PTT: Point-Track-Transformer Module for 3D Single Object Tracking in Point Clouds,” 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2021, pp. 1310-1316, doi: 10.1109/IROS51168.2021.9636821. [2] J. S. Jiayao, S. Zhou, Y. Cui and Z. Fang, “Real-time 3D Single Object Tracking with Transformer,” in IEEE Transactions on Multimedia, doi: 10.1109/TMM.2022.3146714. ","date":"0001-01-01","objectID":"/projects/:1:1","tags":null,"title":"项目","uri":"/projects/"}]