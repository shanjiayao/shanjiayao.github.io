<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>自定义C++/CUDA扩展 | Echo's Blogs</title><meta name="keywords" content="Pytorch-C++-Extension"><meta name="author" content="Echo"><meta name="copyright" content="Echo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta property="og:type" content="article">
<meta property="og:title" content="自定义C++&#x2F;CUDA扩展">
<meta property="og:url" content="http://example.com/2021/01/06/DeepLearning/CUDA/%E8%87%AA%E5%AE%9A%E4%B9%89C++%20CUDA%20extensions/index.html">
<meta property="og:site_name" content="Echo&#39;s Blogs">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg">
<meta property="article:published_time" content="2021-01-06T08:10:19.000Z">
<meta property="article:modified_time" content="2021-07-05T01:38:34.878Z">
<meta property="article:author" content="Echo">
<meta property="article:tag" content="Pytorch-C++-Extension">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><link rel="shortcut icon" href="/img/favicon.jpg"><link rel="canonical" href="http://example.com/2021/01/06/DeepLearning/CUDA/%E8%87%AA%E5%AE%9A%E4%B9%89C++%20CUDA%20extensions/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '自定义C++/CUDA扩展',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-07-05 09:38:34'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/favicon.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">37</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">24</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Echo's Blogs</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">自定义C++/CUDA扩展</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-01-06T08:10:19.000Z" title="发表于 2021-01-06 16:10:19">2021-01-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-07-05T01:38:34.878Z" title="更新于 2021-07-05 09:38:34">2021-07-05</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/DeepLearning/">DeepLearning</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="自定义C++/CUDA扩展"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><hr>
<span id="more"></span>

<h2 id="官网文档-Pytorch-1-7"><a href="#官网文档-Pytorch-1-7" class="headerlink" title="官网文档 [Pytorch 1.7]"></a>官网文档 [Pytorch 1.7]</h2><p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/advanced/cpp_extension.html">Custom C++ and CUDA Extensions - PyTorch Tutorials 1.7.1 documentation</a></p>
<p><a target="_blank" rel="noopener" href="https://pytorch.apachecn.org/docs/1.0/cpp_extension.html">Custom C++ and CUDA Extensions - PyTorch Tutorials 1.7.1 documentation CN</a></p>
<h2 id="自定义扩展的必要性"><a href="#自定义扩展的必要性" class="headerlink" title="自定义扩展的必要性"></a>自定义扩展的必要性</h2><p>Pytorch虽然已经使用了NVIDIA cuDNN、Intel MKL和NNPACK这些底层来加快训练速度，但是在某些情况下，比如我们要实现一些特定算法，光靠组合Pytorch已有的操作是不够的。这是因为Pytorch虽然在特定操作上经过了很好的优化，但却并不见得适合我们自定义的操作，所以，作为一名程序员，应该了解如何将自己的网络或者操作以底层C++的代码实现，这是很重要的</p>
<p>除此之外，如果pytorch代码需要与C++代码进行交互，也需要自己编写对应的C++扩展</p>
<h2 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a>操作步骤</h2><h3 id="1-如何用C-实现我们的扩展-操作？"><a href="#1-如何用C-实现我们的扩展-操作？" class="headerlink" title="1. 如何用C++实现我们的扩展/操作？"></a>1. <strong>如何用C++实现我们的扩展/操作？</strong></h3><p>头文件包括：<code>#include &lt;torch/extension.h&gt;</code>  以及定义对应的函数名</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;torch/extension.h&gt; //这一句是无论要实现任何op都必须添加的</span></span><br><span class="line"><span class="comment">#include &lt;vector&gt;</span></span><br><span class="line"></span><br><span class="line">//前向传播</span><br><span class="line">torch::Tensor my_op_forward(const torch::Tensor&amp; x, const torch::Tensor&amp; y);</span><br><span class="line">//反向传播</span><br><span class="line">std::vector&lt;torch::Tensor&gt; my_op_backward(const torch::Tensor&amp; gradOutput);</span><br></pre></td></tr></table></figure>

<p>源文件包括：网络的定义，包括前向传播、反向传播以及pybind11将c++代码绑定到python的部分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &quot;my_op.h&quot;</span></span><br><span class="line"></span><br><span class="line">torch::Tensor my_op_forward(const torch::Tensor&amp; x,                             const torch::Tensor&amp; y) &#123;     </span><br><span class="line">     AT_ASSERTM(x.sizes() == y.sizes(), <span class="string">&quot;x must be the same size as y&quot;</span>);</span><br><span class="line">     torch::Tensor z = torch::zeros(x.sizes());</span><br><span class="line">     z = <span class="number">3</span> * x - y;</span><br><span class="line">     <span class="keyword">return</span> z; &#125; </span><br><span class="line"></span><br><span class="line">std::vector&lt;torch::Tensor&gt; my_op_backward(const torch::Tensor&amp; gradOutput) &#123;</span><br><span class="line">     torch::Tensor gradOutputX = <span class="number">3</span> * gradOutput * torch::ones(gradOutput.sizes());</span><br><span class="line">     torch::Tensor gradOutputY = -<span class="number">1</span> * gradOutput * torch::ones(gradOutput.sizes());</span><br><span class="line">     <span class="keyword">return</span> &#123;gradOutputX, gradOutputY&#125;; &#125; </span><br><span class="line"></span><br><span class="line">// pybind11 绑定 </span><br><span class="line">PYBIND11_MODULE(**TORCH_EXTENSION_NAME**, m) &#123;</span><br><span class="line">     m.<span class="keyword">def</span>(<span class="string">&quot;forward&quot;</span>, &amp;my_op_forward, <span class="string">&quot;MY_OP forward&quot;</span>);</span><br><span class="line">     m.<span class="keyword">def</span>(<span class="string">&quot;backward&quot;</span>, &amp;my_op_backward, <span class="string">&quot;MY_OP backward&quot;</span>); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol>
<li><code>pybind11</code>是python中用来和c++11通信的库</li>
<li>TORCH_EXTENSION_NAME不需要指定，这个定义在运行 setup.py 脚本文件时，对应的扩展名会传给这个定义，这样避免两者匹配不上</li>
<li>这里网络的定义可以调用<code>pytorch/extension</code> 的库，也就是ATen，也可以通过自定义的<code>cuda kernels</code>实现</li>
</ol>
<h3 id="2-如何编译C-代码为python可以识别的文件？"><a href="#2-如何编译C-代码为python可以识别的文件？" class="headerlink" title="2. 如何编译C++代码为python可以识别的文件？"></a>2. <strong>如何编译C++代码为python可以识别的文件？</strong></h3><blockquote>
<p>对应两种方案，<code>setuptools</code> 或者 <code>torch.utils.cpp_extension.load()</code> 这里详细介绍前者</p>
</blockquote>
<p>编写对应的 setup.py，构建pytorch的c++扩展，利用python的 <code>setuptools</code> 来编译并加载C++代码，这样，执行setup.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> setuptools <span class="keyword">import</span> setup</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">from</span> torch.utils.cpp_extension <span class="keyword">import</span> BuildExtension, CppExtension</span><br><span class="line"></span><br><span class="line"><span class="comment"># 头文件目录</span></span><br><span class="line">include_dirs = os.path.dirname(os.path.abspath(__file__))</span><br><span class="line"><span class="comment"># 源代码目录 </span></span><br><span class="line">source_file = glob.glob(os.path.join(working_dirs, <span class="string">&#x27;src&#x27;</span>, <span class="string">&#x27;*.cpp&#x27;</span>))</span><br><span class="line"></span><br><span class="line">setup(</span><br><span class="line">    name=<span class="string">&#x27;test_cpp&#x27;</span>,  <span class="comment"># 模块名称 与.cpp中的TORCH_EXTENSION_NAME对应</span></span><br><span class="line">    ext_modules=[CppExtension(<span class="string">&#x27;test_cpp&#x27;</span>, sources=source_file, include_dirs=[include_dirs])],</span><br><span class="line">    cmdclass=&#123;</span><br><span class="line">        <span class="string">&#x27;build_ext&#x27;</span>: BuildExtension</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>在终端执行</p>
<p><code>python setup.py install</code></p>
<p>这一步其实是包含了build+install执行的是先编译链接动态链接库，然后将构建好的文件以package的形式安装存放再当前开发环境的package的集中存放处，这样就相当于生成了一个完整的package了。和其他的如numpy，torch这些package没什么两样。</p>
<p>执行后，目录下会生成三个目录<code>build/</code> <code>dist/</code> <code>***.egg-info/</code> ，除此之外，一个名子类似 ***-0.0.0-py3.6-linux-x86_64.egg 的文件也会出现在当前python的环境中<code>site-package</code> ，具体的编译输出如下：</p>
<ul>
<li>output<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">running install</span><br><span class="line">running bdist_egg</span><br><span class="line">running egg_info</span><br><span class="line">writing lltm.egg-info/PKG-INFO</span><br><span class="line">writing dependency_links to lltm.egg-info/dependency_links.txt</span><br><span class="line">writing top-level names to lltm.egg-info/top_level.txt</span><br><span class="line">reading manifest file <span class="string">&#x27;lltm.egg-info/SOURCES.txt&#x27;</span></span><br><span class="line">writing manifest file <span class="string">&#x27;lltm.egg-info/SOURCES.txt&#x27;</span></span><br><span class="line">installing library code to build/bdist.linux-x86_64/egg</span><br><span class="line">running install_lib</span><br><span class="line">running build_ext</span><br><span class="line">building <span class="string">&#x27;lltm&#x27;</span> extension</span><br><span class="line">gcc -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I~/local/miniconda/lib/python3<span class="number">.6</span>/site-packages/torch/lib/include -I~/local/miniconda/lib/python3<span class="number">.6</span>/site-packages/torch/lib/include/TH -I~/local/miniconda/lib/python3<span class="number">.6</span>/site-packages/torch/lib/include/THC -I~/local/miniconda/include/python3<span class="number">.6</span>m -c lltm.cpp -o build/temp.linux-x86_64-<span class="number">3.6</span>/lltm.o -DTORCH_EXTENSION_NAME=lltm -std=c++<span class="number">11</span></span><br><span class="line">cc1plus: warning: command line option ‘-Wstrict-prototypes’ <span class="keyword">is</span> valid <span class="keyword">for</span> C/ObjC but <span class="keyword">not</span> <span class="keyword">for</span> C++</span><br><span class="line">g++ -pthread -shared -B ~/local/miniconda/compiler_compat -L~/local/miniconda/lib -Wl,-rpath=~/local/miniconda/lib -Wl,--no-<span class="keyword">as</span>-needed -Wl,--sysroot=/ build/temp.linux-x86_64-<span class="number">3.6</span>/lltm.o -o build/lib.linux-x86_64-<span class="number">3.6</span>/lltm.cpython-36m-x86_64-linux-gnu.so</span><br><span class="line">creating build/bdist.linux-x86_64/egg</span><br><span class="line">copying build/lib.linux-x86_64-<span class="number">3.6</span>/lltm_cuda.cpython-36m-x86_64-linux-gnu.so -&gt; build/bdist.linux-x86_64/egg</span><br><span class="line">copying build/lib.linux-x86_64-<span class="number">3.6</span>/lltm.cpython-36m-x86_64-linux-gnu.so -&gt; build/bdist.linux-x86_64/egg</span><br><span class="line">creating stub loader <span class="keyword">for</span> lltm.cpython-36m-x86_64-linux-gnu.so</span><br><span class="line">byte-compiling build/bdist.linux-x86_64/egg/lltm.py to lltm.cpython-<span class="number">36.</span>pyc</span><br><span class="line">creating build/bdist.linux-x86_64/egg/EGG-INFO</span><br><span class="line">copying lltm.egg-info/PKG-INFO -&gt; build/bdist.linux-x86_64/egg/EGG-INFO</span><br><span class="line">copying lltm.egg-info/SOURCES.txt -&gt; build/bdist.linux-x86_64/egg/EGG-INFO</span><br><span class="line">copying lltm.egg-info/dependency_links.txt -&gt; build/bdist.linux-x86_64/egg/EGG-INFO</span><br><span class="line">copying lltm.egg-info/top_level.txt -&gt; build/bdist.linux-x86_64/egg/EGG-INFO</span><br><span class="line">writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt</span><br><span class="line">zip_safe flag <span class="keyword">not</span> <span class="built_in">set</span>; analyzing archive contents...</span><br><span class="line">__pycache__.lltm.cpython-<span class="number">36</span>: module references __file__</span><br><span class="line">creating <span class="string">&#x27;dist/lltm-0.0.0-py3.6-linux-x86_64.egg&#x27;</span> <span class="keyword">and</span> adding <span class="string">&#x27;build/bdist.linux-x86_64/egg&#x27;</span> to it</span><br><span class="line">removing <span class="string">&#x27;build/bdist.linux-x86_64/egg&#x27;</span> (<span class="keyword">and</span> everything under it)</span><br><span class="line">Processing lltm-<span class="number">0.0</span><span class="number">.0</span>-py3<span class="number">.6</span>-linux-x86_64.egg</span><br><span class="line">removing <span class="string">&#x27;~/local/miniconda/lib/python3.6/site-packages/lltm-0.0.0-py3.6-linux-x86_64.egg&#x27;</span> (<span class="keyword">and</span> everything under it)</span><br><span class="line">creating ~/local/miniconda/lib/python3<span class="number">.6</span>/site-packages/lltm-<span class="number">0.0</span><span class="number">.0</span>-py3<span class="number">.6</span>-linux-x86_64.egg</span><br><span class="line">Extracting lltm-<span class="number">0.0</span><span class="number">.0</span>-py3<span class="number">.6</span>-linux-x86_64.egg to ~/local/miniconda/lib/python3<span class="number">.6</span>/site-packages</span><br><span class="line">lltm <span class="number">0.0</span><span class="number">.0</span> <span class="keyword">is</span> already the active version <span class="keyword">in</span> easy-install.pth</span><br><span class="line">  </span><br><span class="line">Installed ~/local/miniconda/lib/python3<span class="number">.6</span>/site-packages/lltm-<span class="number">0.0</span><span class="number">.0</span>-py3<span class="number">.6</span>-linux-x86_64.egg</span><br><span class="line">Processing dependencies <span class="keyword">for</span> lltm==<span class="number">0.0</span><span class="number">.0</span></span><br><span class="line">Finished processing dependencies <span class="keyword">for</span> lltm==<span class="number">0.0</span><span class="number">.0</span></span><br></pre></td></tr></table></figure></li>
</ul>
<p>此外，使用 <code>pip list</code> 或者 <code>conda list</code> 查看包列表时，可以找到对应的包已经安装了，并且有对应的版本信息以及来源等</p>
<h3 id="3-如何通过python调用编译好的扩展-操作？"><a href="#3-如何通过python调用编译好的扩展-操作？" class="headerlink" title="3. 如何通过python调用编译好的扩展/操作？"></a>3. <strong>如何通过python调用编译好的扩展/操作？</strong></h3><p> 在上述操作完成后，虽然python/conda环境下已经有了相对应的库，但通过python进行import 是会报错的，如下</p>
<blockquote>
<p>undefined symbol: _ZTIN3c1021AutogradMetaInterfaceE</p>
</blockquote>
<p>原因是编译好的包还需要进一步封装才能在python中调用，具体做法如下：</p>
<ul>
<li>在setup.py 相同路径下新建一个py文件，内容为：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Function</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> test_cpp</span><br><span class="line">  </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_TestFunction</span>(<span class="params">Function</span>):</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">ctx, x, y</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        It must accept a context ctx as the first argument, followed by any</span></span><br><span class="line"><span class="string">        number of arguments (tensors or other types).</span></span><br><span class="line"><span class="string">        The context can be used to store tensors that can be then retrieved</span></span><br><span class="line"><span class="string">        during the backward pass.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> test_cpp.forward(x, y)</span><br><span class="line">  </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">ctx, gradOutput</span>):</span></span><br><span class="line">        gradX, gradY = test_cpp.backward(gradOutput)</span><br><span class="line">        <span class="keyword">return</span> gradX, gradY</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 封装成一个模块（Module）</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Test, self).__init__()</span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, inputA, inputB</span>):</span></span><br><span class="line">        <span class="keyword">return</span> **_TestFunction.apply**(inputA, inputB)</span><br></pre></td></tr></table></figure>

  可以看到，主要就是继承pytorch中的父类，新建对应的类，进而做了一些接口上的封装，具体就是使用 <code>torch.autograd.Function</code> 来将这个扩展写成一个函数，方便在构建网络的时候调用。最后就在合适的地方使用<code>Function.apply(*args)</code> ，就完成了一个自定义扩展了！</li>
</ul>
<h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><h3 id="1-关于C-底层代码的编写，有两种方案"><a href="#1-关于C-底层代码的编写，有两种方案" class="headerlink" title="1. 关于C++底层代码的编写，有两种方案"></a>1. 关于C++底层代码的编写，有两种方案</h3><p><strong>第一种形式</strong>，用<code>pytorch/extension</code> 的库，也就是ATen，加速效果尚好，需要以类似<code>at::sigmoid</code>的形式将pytorch的接口API复现一遍</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/hungryof/article/details/88857607">Pytorch学习 (二十一) ——自定义C++/ATen扩展_Hungryof的专栏-CSDN博客</a></p>
<p>效果展示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python     Forward: <span class="number">187.719</span> us | Backward <span class="number">410.815</span> us</span><br><span class="line">extension  Forward: <span class="number">149.802</span> us | Backward <span class="number">393.458</span> us</span><br></pre></td></tr></table></figure>

<p><strong>第二种形式</strong>，使用自定义的<code>cuda kernels</code>来进一步加速，详见</p>
<p><a target="_blank" rel="noopener" href="https://pytorch.apachecn.org/docs/1.0/cpp_extension.html">Custom C++ and CUDA Extensions</a></p>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/advanced/cpp_extension.html#writing-a-mixed-c-cuda-extension">Custom C++ and CUDA Extensions - PyTorch Tutorials 1.7.1 documentation</a></p>
<h3 id="2-关于-setup-py"><a href="#2-关于-setup-py" class="headerlink" title="2. 关于 setup.py"></a>2. 关于 <code>setup.py</code></h3><p>python库打包分发的详细攻略（setup.py编写）见 <a target="_blank" rel="noopener" href="https://blog.konghy.cn/2018/04/29/setup-dot-py/">程序包的打包和分发</a> </p>
<h3 id="3-关于扩展包的封装"><a href="#3-关于扩展包的封装" class="headerlink" title="3. 关于扩展包的封装"></a>3. 关于扩展包的封装</h3><ul>
<li><p>注意一定要有前向传播和反向传播的定义</p>
</li>
<li><p>实现<code>torch.autograd.Function</code> 子类时，注意其前向传播和反向传播，都需要有<code>ctx</code>参数</p>
<p>  大体上来说就是，这个 ctx 变量会在前向传播时，保存一些涉及到计算梯度的信息，然后在反向传播时辅助计算梯度，如</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sigmoid</span>(<span class="params">Function</span>):</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">ctx, x</span>):</span> </span><br><span class="line">        output = <span class="number">1</span> / (<span class="number">1</span> + torch.exp(-x))</span><br><span class="line">        ctx.**save_for_backward**(output)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">ctx, grad_output</span>):</span> </span><br><span class="line">        output,  = ctx.**saved_tensors**</span><br><span class="line">        grad_x = output * (<span class="number">1</span> - output) * grad_output</span><br><span class="line">        <span class="keyword">return</span> grad_x</span><br></pre></td></tr></table></figure></li>
<li><p>前向传播的输入参数和反向传播的输出参数<strong>数量必须一致</strong></p>
<p>  如果有些变量不需要求导，就直接返回None即可</p>
</li>
</ul>
<h3 id="4-关于梯度计算的验证"><a href="#4-关于梯度计算的验证" class="headerlink" title="4. 关于梯度计算的验证"></a>4. 关于梯度计算的验证</h3><p>pytorch提供了<code>torch.autograd.gradcheck()</code> 函数来检测计算的梯度是否合理</p>
<p>如上述的sigmoid梯度计算，可以通过如下代码检验</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tensor([-0.4646, -0.4403,  1.2525, -0.5953], requires_grad=True)</span></span><br><span class="line">test_input = torch.randn(<span class="number">4</span>, requires_grad=<span class="literal">True</span>)     </span><br><span class="line">torch.autograd.gradcheck(Sigmoid.apply, (test_input,), eps=<span class="number">1e-3</span>)    <span class="comment"># pass</span></span><br><span class="line">torch.autograd.gradcheck(torch.sigmoid, (test_input,), eps=<span class="number">1e-3</span>)    <span class="comment"># pass</span></span><br><span class="line">torch.autograd.gradcheck(Sigmoid.apply, (test_input,), eps=<span class="number">1e-4</span>)    <span class="comment"># fail</span></span><br><span class="line">torch.autograd.gradcheck(torch.sigmoid, (test_input,), eps=<span class="number">1e-4</span>)    <span class="comment"># fail</span></span><br></pre></td></tr></table></figure>

<p>我们发现：eps 为 1e-3 时，我们编写的 Sigmoid 和 torch 自带的 builtin Sigmoid 都可以通过梯度检查，但 eps 下降至 1e-4 时，两者反而都无法通过。而一般直觉下，计算数值梯度时， eps 越小，求得的值应该更接近于真实的梯度。这里的反常现象，是由于机器精度带来的误差所致：test_input的类型为torch.float32，因此在 eps 过小的情况下，产生了较大的精度误差（计算数值梯度时，eps 作为被除数），因而与真实精度间产生了较大的 gap。将test_input换为float64的 tensor 后，不再出现这一现象。这点同时提醒我们，在编写backward时，要考虑的数值计算的一些性质，尽可能保留更精确的结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">test_input = torch.randn(<span class="number">4</span>, requires_grad=<span class="literal">True</span>, **dtype=torch.float64**)    <span class="comment"># tensor([-0.4646, -0.4403,  1.2525, -0.5953], dtype=torch.float64, requires_grad=True)</span></span><br><span class="line">torch.autograd.gradcheck(Sigmoid.apply, (test_input,), eps=<span class="number">1e-4</span>)    <span class="comment"># pass</span></span><br><span class="line">torch.autograd.gradcheck(torch.sigmoid, (test_input,), eps=<span class="number">1e-4</span>)    <span class="comment"># pass</span></span><br><span class="line">torch.autograd.gradcheck(Sigmoid.apply, (test_input,), eps=<span class="number">1e-6</span>)    <span class="comment"># pass</span></span><br><span class="line">torch.autograd.gradcheck(torch.sigmoid, (test_input,), eps=<span class="number">1e-6</span>)    <span class="comment"># pass</span></span><br></pre></td></tr></table></figure>

<p>具体介绍见</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/321449610">PyTorch 源码解读之 torch.autograd</a></p>
<h3 id="5-关于运行设备"><a href="#5-关于运行设备" class="headerlink" title="5. 关于运行设备"></a>5. 关于运行设备</h3><p>由于Pytorch的C++库 ATen可以同时适用于CPU和GPU，所以只需要传给封装好的函数对应cuda形式的张量，就可以调用GPU加速运算了</p>
<h3 id="6-关于torch-utils-cpp-extension-load-实时编译扩展库"><a href="#6-关于torch-utils-cpp-extension-load-实时编译扩展库" class="headerlink" title="6. 关于torch.utils.cpp_extension.load() 实时编译扩展库"></a>6. 关于<code>torch.utils.cpp_extension.load()</code> 实时编译扩展库</h3><p>这种方式调用pytorch中的api，是一种动态编译和加载扩展的方式</p>
<p>代码如下</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from torch.utils.cpp_extension <span class="keyword">import</span> load</span><br><span class="line">lltm_cpp = <span class="built_in">load</span>(name=<span class="string">&quot;lltm_cpp&quot;</span>, sources=[<span class="string">&quot;lltm.cpp&quot;</span>])</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/advanced/cpp_extension.html#jit-compiling-extensions">Custom C++ and CUDA Extensions - PyTorch Tutorials 1.7.1 documentation</a></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/100459760">https://zhuanlan.zhihu.com/p/100459760</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Echo</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2021/01/06/DeepLearning/CUDA/%E8%87%AA%E5%AE%9A%E4%B9%89C++%20CUDA%20extensions/">http://example.com/2021/01/06/DeepLearning/CUDA/自定义C++ CUDA extensions/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">Echo's Blogs</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Pytorch-C-Extension/">Pytorch-C++-Extension</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/01/10/DeepLearning/CUDA/cuda%E4%B9%8B%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/"><img class="prev-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">cuda常见名词解释</div></div></a></div><div class="next-post pull-right"><a href="/2021/01/02/Coding/Python/python%E8%BF%98%E5%80%BA%E6%97%A5%E8%AE%B0%E4%B9%8B%E5%AF%B9%E8%B1%A1(%E4%BA%8C)/"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Python还债日记之对象(二)</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div id="comment-switch"><span class="first-comment">G</span><span class="switch-btn"></span><span class="second-comment">i</span></div></div><div class="comment-wrap"><div></div><div></div><div></div><div></div><div></div><div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%98%E7%BD%91%E6%96%87%E6%A1%A3-Pytorch-1-7"><span class="toc-text">官网文档 [Pytorch 1.7]</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E6%89%A9%E5%B1%95%E7%9A%84%E5%BF%85%E8%A6%81%E6%80%A7"><span class="toc-text">自定义扩展的必要性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%E6%AD%A5%E9%AA%A4"><span class="toc-text">操作步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%A6%82%E4%BD%95%E7%94%A8C-%E5%AE%9E%E7%8E%B0%E6%88%91%E4%BB%AC%E7%9A%84%E6%89%A9%E5%B1%95-%E6%93%8D%E4%BD%9C%EF%BC%9F"><span class="toc-text">1. 如何用C++实现我们的扩展&#x2F;操作？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%A6%82%E4%BD%95%E7%BC%96%E8%AF%91C-%E4%BB%A3%E7%A0%81%E4%B8%BApython%E5%8F%AF%E4%BB%A5%E8%AF%86%E5%88%AB%E7%9A%84%E6%96%87%E4%BB%B6%EF%BC%9F"><span class="toc-text">2. 如何编译C++代码为python可以识别的文件？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87python%E8%B0%83%E7%94%A8%E7%BC%96%E8%AF%91%E5%A5%BD%E7%9A%84%E6%89%A9%E5%B1%95-%E6%93%8D%E4%BD%9C%EF%BC%9F"><span class="toc-text">3. 如何通过python调用编译好的扩展&#x2F;操作？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F"><span class="toc-text">注意</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%85%B3%E4%BA%8EC-%E5%BA%95%E5%B1%82%E4%BB%A3%E7%A0%81%E7%9A%84%E7%BC%96%E5%86%99%EF%BC%8C%E6%9C%89%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%A1%88"><span class="toc-text">1. 关于C++底层代码的编写，有两种方案</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%85%B3%E4%BA%8E-setup-py"><span class="toc-text">2. 关于 setup.py</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%85%B3%E4%BA%8E%E6%89%A9%E5%B1%95%E5%8C%85%E7%9A%84%E5%B0%81%E8%A3%85"><span class="toc-text">3. 关于扩展包的封装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%85%B3%E4%BA%8E%E6%A2%AF%E5%BA%A6%E8%AE%A1%E7%AE%97%E7%9A%84%E9%AA%8C%E8%AF%81"><span class="toc-text">4. 关于梯度计算的验证</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E5%85%B3%E4%BA%8E%E8%BF%90%E8%A1%8C%E8%AE%BE%E5%A4%87"><span class="toc-text">5. 关于运行设备</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E5%85%B3%E4%BA%8Etorch-utils-cpp-extension-load-%E5%AE%9E%E6%97%B6%E7%BC%96%E8%AF%91%E6%89%A9%E5%B1%95%E5%BA%93"><span class="toc-text">6. 关于torch.utils.cpp_extension.load() 实时编译扩展库</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83"><span class="toc-text">参考</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2021 By Echo</div><div class="footer_custom_text">年龄是时间的箭头，裹挟着我们，在匆匆的人世间，匆匆前行</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="translateLink" type="button" title="简繁转换">簡</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>